{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fjK5Yrklj8PE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from scipy.ndimage import rotate, shift, zoom\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.base import clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YimrUUegj9FK",
        "outputId": "e0901819-92db-4bc0-81a2-3d86e3aff04e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mohamedgamal07/reduced-mnist?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.62M/9.62M [00:00<00:00, 90.0MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/mohamedgamal07/reduced-mnist/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mohamedgamal07/reduced-mnist\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gOdnaV9wj8PG"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# Data Loading Functions\n",
        "# --------------------------\n",
        "def load_data(train_dir, test_dir):\n",
        "    \"\"\"Load MNIST data from directories\"\"\"\n",
        "    # Load training data\n",
        "    images, labels = [], []\n",
        "    for label in sorted(os.listdir(train_dir)):\n",
        "        label_dir = os.path.join(train_dir, label)\n",
        "        if os.path.isdir(label_dir):\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                img_path = os.path.join(label_dir, img_name)\n",
        "                with Image.open(img_path) as img:\n",
        "                    img_array = np.array(img.convert('L'), dtype=np.float32) / 255.0\n",
        "                    images.append(img_array)\n",
        "                    labels.append(int(label))\n",
        "\n",
        "    # Load test data\n",
        "    test_images, test_labels = [], []\n",
        "    for label in sorted(os.listdir(test_dir)):\n",
        "        label_dir = os.path.join(test_dir, label)\n",
        "        if os.path.isdir(label_dir):\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                img_path = os.path.join(label_dir, img_name)\n",
        "                with Image.open(img_path) as img:\n",
        "                    img_array = np.array(img.convert('L'), dtype=np.float32) / 255.0\n",
        "                    test_images.append(img_array)\n",
        "                    test_labels.append(int(label))\n",
        "\n",
        "    return (\n",
        "        np.array(images), np.array(labels),\n",
        "        np.array(test_images), np.array(test_labels)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TOVN8Vd-j8PJ"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# Data Preparation Functions\n",
        "# --------------------------\n",
        "def create_subset(images, labels, n_per_class=40):\n",
        "    \"\"\"Create balanced subset with n_per_class samples per class\"\"\"\n",
        "    subset_images, subset_labels = [], []\n",
        "    for class_label in range(10):\n",
        "        class_indices = np.where(labels == class_label)[0]\n",
        "        selected = np.random.choice(class_indices, n_per_class, replace=False)\n",
        "        subset_images.extend(images[selected])\n",
        "        subset_labels.extend(labels[selected])\n",
        "    return (\n",
        "        np.array(subset_images),\n",
        "        np.array(subset_labels),\n",
        "        np.concatenate([np.where(labels == c)[0][:n_per_class] for c in range(10)])\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "012mzfXqj8PK"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# Augmentation Functions\n",
        "# --------------------------\n",
        "def random_rotation(image):\n",
        "    angle = np.random.uniform(-5, 5)\n",
        "    return rotate(image, angle=angle, reshape=False, mode='nearest')\n",
        "\n",
        "def random_translation(image):\n",
        "    dx, dy = np.random.randint(-2, 3, size=2)\n",
        "    return shift(image, (dy, dx), mode='constant', cval=0.0)\n",
        "\n",
        "def random_noise(image):\n",
        "    sigma = np.random.uniform(0.02, 0.08)\n",
        "    noise = np.random.normal(0, sigma, image.shape)\n",
        "    return np.clip(image + noise, 0, 1)\n",
        "\n",
        "def random_scaling(image):\n",
        "    scale = np.random.uniform(0.9, 1.1)\n",
        "    scaled = zoom(image, scale, mode='nearest')\n",
        "    h, w = scaled.shape\n",
        "    if scale >= 1:\n",
        "        start_h, start_w = (h-28)//2, (w-28)//2\n",
        "        return scaled[start_h:start_h+28, start_w:start_w+28]\n",
        "    else:\n",
        "        pad_h = (28 - h) // 2\n",
        "        pad_w = (28 - w) // 2\n",
        "        return np.pad(scaled, ((pad_h, 28-h-pad_h), (pad_w, 28-w-pad_w)), mode='constant')\n",
        "\n",
        "def augment_data(images, labels, n_augment=5):\n",
        "    \"\"\"Generate augmented versions of input images\"\"\"\n",
        "    augmented_images, augmented_labels = [], []\n",
        "    for img, lbl in zip(images, labels):\n",
        "        augmented_images.append(img)\n",
        "        augmented_labels.append(lbl)\n",
        "        for _ in range(n_augment):\n",
        "            aug_img = img.copy()\n",
        "            if np.random.rand() > 0.5: aug_img = random_rotation(aug_img)\n",
        "            if np.random.rand() > 0.5: aug_img = random_translation(aug_img)\n",
        "            if np.random.rand() > 0.5: aug_img = random_scaling(aug_img)\n",
        "            aug_img = random_noise(aug_img)\n",
        "            augmented_images.append(aug_img)\n",
        "            augmented_labels.append(lbl)\n",
        "    return np.array(augmented_images), np.array(augmented_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3y0TwY_q7Bf"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# Model Training Functions (with regularization)\n",
        "# --------------------------\n",
        "def train_svm(X_train, y_train, sample_weights=None, C=0.01, class_weight=None):\n",
        "    \"\"\"Train SVM with sample weighting\"\"\"\n",
        "    return SVC(\n",
        "        kernel='linear',\n",
        "        C=C,\n",
        "        class_weight=class_weight,\n",
        "        probability=True,\n",
        "        random_state=42\n",
        "    ).fit(X_train, y_train, sample_weight=sample_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EDYFg7gsj8PN"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# Enhanced Pseudo-labeling\n",
        "# --------------------------\n",
        "def get_high_confidence_samples(model, X_full, mask, confidence_threshold=0.9, margin_threshold=0.2):\n",
        "    \"\"\"Get samples with both high confidence and clear margin\"\"\"\n",
        "    unlabeled_indices = np.where(~mask)[0]\n",
        "    if len(unlabeled_indices) == 0:\n",
        "        return np.array([]), np.array([]), np.array([]), np.array([])\n",
        "\n",
        "    X_unlabeled = X_full[unlabeled_indices]\n",
        "    probs = model.predict_proba(X_unlabeled)\n",
        "\n",
        "    # Calculate confidence and margin\n",
        "    sorted_probs = np.sort(probs, axis=1)\n",
        "    confidence = sorted_probs[:, -1]  # Highest probability\n",
        "    margin = sorted_probs[:, -1] - sorted_probs[:, -2]  # Difference between top two\n",
        "\n",
        "    # Combined selection criteria\n",
        "    combined_mask = (confidence >= confidence_threshold) & (margin >= margin_threshold)\n",
        "\n",
        "    return (\n",
        "        unlabeled_indices[combined_mask],  # Original indices\n",
        "        X_unlabeled[combined_mask],        # Data\n",
        "        np.argmax(probs[combined_mask], axis=1),  # Pseudo-labels\n",
        "        confidence[combined_mask]          # Confidence scores\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6fGexWMbrWDo"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "def iterative_training_pipeline(confidence_threshold=0.9,\n",
        "                               margin_threshold=0.2,\n",
        "                               patience=3,\n",
        "                               max_iterations=30):\n",
        "    # ----------------------------\n",
        "    # Data Loading and Preparation\n",
        "    # ----------------------------\n",
        "    train_dir = \"/root/.cache/kagglehub/datasets/mohamedgamal07/reduced-mnist/versions/1/Reduced MNIST Data/Reduced Trainging data\"\n",
        "    test_dir  = \"/root/.cache/kagglehub/datasets/mohamedgamal07/reduced-mnist/versions/1/Reduced MNIST Data/Reduced Testing data\"\n",
        "    # Assume load_data returns: X_train_full, y_train_full, X_test, y_test\n",
        "    X_train_full, y_train_full, X_test, y_test = load_data(train_dir, test_dir)\n",
        "\n",
        "    # Flatten test set for evaluation\n",
        "    X_test_flat = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Initial Labeled Subset & Unlabeled Pool\n",
        "    # ----------------------------\n",
        "    # Create an initial labeled subset (e.g., 40 examples per class)\n",
        "    X_subset, y_subset, subset_indices = create_subset(X_train_full, y_train_full)\n",
        "\n",
        "    # Remove the initial subset from training data to form the unlabeled pool\n",
        "    X_unlabeled = np.delete(X_train_full, subset_indices, axis=0)\n",
        "    y_unlabeled = np.delete(y_train_full, subset_indices, axis=0)\n",
        "\n",
        "    # Flatten initial subset and unlabeled pool for training\n",
        "    X_subset_flat = X_subset.reshape(len(X_subset), -1)\n",
        "    X_unlabeled_flat = X_unlabeled.reshape(len(X_unlabeled), -1)\n",
        "\n",
        "    # Data augmentation on the initial labeled subset\n",
        "    X_augmented, y_augmented = augment_data(X_subset, y_subset)\n",
        "    X_augmented_flat = X_augmented.reshape(len(X_augmented), -1)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Initialize Pseudo-labeled Storage\n",
        "    # ----------------------------\n",
        "    num_features = X_subset_flat.shape[1]\n",
        "    X_pseudo = np.zeros((0, num_features))\n",
        "    y_pseudo = np.zeros(0, dtype=int)\n",
        "    weights = np.zeros(0)\n",
        "\n",
        "    # For early stopping, we track the best test accuracy (using the test set)\n",
        "    best_test_acc = 0.0\n",
        "    best_model = None\n",
        "    patience_counter = 0\n",
        "    iteration = 0\n",
        "\n",
        "    # Timing:\n",
        "    # Pipeline human time is constant (only initial labeling is manually done)\n",
        "    pipeline_human_time = len(y_subset) * 10  # seconds\n",
        "    # Full manual time: time to label all images manually (in training set)\n",
        "    total_images = X_train_full.shape[0]\n",
        "    full_manual_time = total_images * 10  # seconds\n",
        "\n",
        "    # List to store test accuracies for each iteration\n",
        "    test_accuracies = []\n",
        "\n",
        "    # ----------------------------\n",
        "    # Iterative Training Loop\n",
        "    # ----------------------------\n",
        "    while iteration < max_iterations:\n",
        "        iteration += 1\n",
        "\n",
        "        # Combine current labeled data: initial subset, augmented data, and pseudo-labeled data\n",
        "        X_labeled_flat = np.vstack([X_subset_flat, X_augmented_flat, X_pseudo])\n",
        "        y_labeled = np.concatenate([y_subset, y_augmented, y_pseudo])\n",
        "\n",
        "        # Combine sample weights for SVM training\n",
        "        sample_weights = np.concatenate([\n",
        "            np.ones(len(X_subset_flat) + len(X_augmented_flat)),\n",
        "            weights\n",
        "        ])\n",
        "\n",
        "        # Train SVM model (using your train_svm function)\n",
        "        model = train_svm(X_labeled_flat, y_labeled,\n",
        "                          sample_weights=sample_weights,\n",
        "                          C=0.01,\n",
        "                          class_weight='balanced')\n",
        "\n",
        "        # Evaluate on the test set for early stopping\n",
        "        test_preds = model.predict(X_test_flat)\n",
        "        test_acc = accuracy_score(y_test, test_preds)\n",
        "        test_accuracies.append(test_acc)\n",
        "\n",
        "        print(f\"\\nIteration {iteration}:\")\n",
        "        print(f\"Test Accuracy: {test_acc:.4f} | Best Test Acc: {best_test_acc:.4f} | Patience: {patience_counter}/{patience}\")\n",
        "\n",
        "        # Early stopping check based on test set accuracy\n",
        "        if test_acc > best_test_acc:\n",
        "            best_test_acc = test_acc\n",
        "            best_model = copy.deepcopy(model)  # Preserve the fitted model\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early - no improvement for {patience} iterations\")\n",
        "            break\n",
        "\n",
        "        # --------------\n",
        "        # High-Confidence Pseudo-labeling from Unlabeled Pool\n",
        "        # --------------\n",
        "        # Create a dummy mask (all False) for the unlabeled pool\n",
        "        dummy_mask = np.zeros(len(X_unlabeled_flat), dtype=bool)\n",
        "        new_indices, X_new, y_new, conf_new = get_high_confidence_samples(\n",
        "            model, X_unlabeled_flat, dummy_mask,\n",
        "            confidence_threshold=confidence_threshold,\n",
        "            margin_threshold=margin_threshold\n",
        "        )\n",
        "\n",
        "        if len(new_indices) > 0:\n",
        "            # Update pseudo-labeled storage\n",
        "            X_pseudo = np.vstack([X_pseudo, X_new])\n",
        "            y_pseudo = np.concatenate([y_pseudo, y_new])\n",
        "            weights = np.concatenate([weights, conf_new])\n",
        "\n",
        "            # Remove high-confidence samples from the unlabeled pool\n",
        "            X_unlabeled_flat = np.delete(X_unlabeled_flat, new_indices, axis=0)\n",
        "            y_unlabeled = np.delete(y_unlabeled, new_indices, axis=0)\n",
        "\n",
        "            print(f\"New pseudo-labeled samples: {len(new_indices)}\")\n",
        "        else:\n",
        "            print(\"No new high-confidence samples found.\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\nTraining completed after {iteration} iterations\")\n",
        "    print(f\"Final Test Accuracy: {best_test_acc:.4f}\")\n",
        "\n",
        "    # Construct final labeled set (flattened)\n",
        "    X_labeled = np.vstack([X_subset_flat, X_augmented_flat, X_pseudo])\n",
        "\n",
        "    # Return:\n",
        "    # best_model, final labeled data (X_labeled, y_labeled), remaining unlabeled pool (X_unlabeled_flat, y_unlabeled),\n",
        "    # pipeline_human_time, full_manual_time, stopped_early, test_accuracies\n",
        "    stopped_early = (patience_counter >= patience)\n",
        "    return best_model, X_labeled, y_labeled, X_unlabeled_flat, y_unlabeled, pipeline_human_time, full_manual_time, stopped_early, test_accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ft4KBcIopjp",
        "outputId": "46607d9f-16c2-4515-b916-547ca77b31b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 1:\n",
            "Test Accuracy: 0.9030 | Best Test Acc: 0.0000 | Patience: 0/3\n",
            "New pseudo-labeled samples: 6161\n",
            "\n",
            "Iteration 2:\n",
            "Test Accuracy: 0.9080 | Best Test Acc: 0.9030 | Patience: 0/3\n",
            "New pseudo-labeled samples: 790\n",
            "\n",
            "Iteration 3:\n",
            "Test Accuracy: 0.9160 | Best Test Acc: 0.9080 | Patience: 0/3\n",
            "New pseudo-labeled samples: 294\n",
            "\n",
            "Iteration 4:\n",
            "Test Accuracy: 0.9205 | Best Test Acc: 0.9160 | Patience: 0/3\n",
            "New pseudo-labeled samples: 133\n",
            "\n",
            "Iteration 5:\n",
            "Test Accuracy: 0.9225 | Best Test Acc: 0.9205 | Patience: 0/3\n",
            "New pseudo-labeled samples: 67\n",
            "\n",
            "Iteration 6:\n",
            "Test Accuracy: 0.9250 | Best Test Acc: 0.9225 | Patience: 0/3\n",
            "New pseudo-labeled samples: 44\n",
            "\n",
            "Iteration 7:\n",
            "Test Accuracy: 0.9245 | Best Test Acc: 0.9250 | Patience: 0/3\n",
            "New pseudo-labeled samples: 35\n",
            "\n",
            "Iteration 8:\n",
            "Test Accuracy: 0.9240 | Best Test Acc: 0.9250 | Patience: 1/3\n",
            "New pseudo-labeled samples: 19\n",
            "\n",
            "Iteration 9:\n",
            "Test Accuracy: 0.9235 | Best Test Acc: 0.9250 | Patience: 2/3\n",
            "Stopping early - no improvement for 3 iterations\n",
            "\n",
            "Training completed after 9 iterations\n",
            "Final Test Accuracy: 0.9250\n"
          ]
        }
      ],
      "source": [
        "best_model, X_labeled, y_labeled, X_unlabeled, y_unlabeled, pipeline_time, full_manual_time , stopped_early, test_accuracies= iterative_training_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5lYT1MUrxyV",
        "outputId": "657441ce-4dbb-488b-b9dd-5f48390d029d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration  Test Accuracy   Pipeline Human Time (sec)      Pipeline Human Time (hrs)     \n",
            "----------------------------------------------------------------------------------------\n",
            "1          0.9030          4000                           1.11                          \n",
            "2          0.9080          4000                           1.11                          \n",
            "3          0.9160          4000                           1.11                          \n",
            "4          0.9205          4000                           1.11                          \n",
            "5          0.9225          4000                           1.11                          \n",
            "6          0.9250          4000                           1.11                          \n",
            "7          0.9245          4000                           1.11                          \n",
            "8          0.9240          4000                           1.11                          \n",
            "9          0.9235          4000                           1.11                          \n",
            "\n",
            "Estimated Full Manual Labeling Time:\n",
            "100000 seconds (27.78 hours)\n",
            "\n",
            "---------- Final Performance Summary ----------\n",
            "Final Labeled Training Accuracy: 0.9854\n",
            "Final Unlabeled (Auto-Labeled) Accuracy: 0.6101\n",
            "Number of Remaining Unlabeled Samples: 2057\n",
            "Early Stopping Triggered: True\n",
            "------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Print per-iteration table\n",
        "header = f\"{'Iteration':<10} {'Test Accuracy':<15} {'Pipeline Human Time (sec)':<30} {'Pipeline Human Time (hrs)':<30}\"\n",
        "print(header)\n",
        "print(\"-\" * len(header))\n",
        "# Since pipeline_time is constant (only the initial labeling is done manually),\n",
        "# we simply print that value for each iteration along with the test accuracy recorded.\n",
        "for i, acc in enumerate(test_accuracies, start=1):\n",
        "    time_hr = pipeline_time / 3600.0\n",
        "    print(f\"{i:<10} {acc:<15.4f} {pipeline_time:<30} {time_hr:<30.2f}\")\n",
        "\n",
        "# Convert full manual time to hours for display\n",
        "full_manual_time_hours = full_manual_time / 3600.0\n",
        "\n",
        "# Print estimated full manual labeling time\n",
        "print(\"\\nEstimated Full Manual Labeling Time:\")\n",
        "print(f\"{full_manual_time} seconds ({full_manual_time_hours:.2f} hours)\")\n",
        "\n",
        "# -----------------------------------------\n",
        "# Final Performance Evaluation\n",
        "# -----------------------------------------\n",
        "# Evaluate final model on the labeled training set\n",
        "X_labeled_flat = X_labeled.reshape(X_labeled.shape[0], -1)\n",
        "labeled_preds = best_model.predict(X_labeled_flat)\n",
        "labeled_acc = accuracy_score(y_labeled, labeled_preds)\n",
        "\n",
        "# Evaluate final model on the remaining unlabeled set (if any)\n",
        "if X_unlabeled.shape[0] > 0:\n",
        "    X_unlabeled_flat = X_unlabeled.reshape(X_unlabeled.shape[0], -1)\n",
        "    unlabeled_preds = best_model.predict(X_unlabeled_flat)\n",
        "    unlabeled_acc = accuracy_score(y_unlabeled, unlabeled_preds)\n",
        "else:\n",
        "    unlabeled_acc = None\n",
        "\n",
        "print(\"\\n---------- Final Performance Summary ----------\")\n",
        "print(f\"Final Labeled Training Accuracy: {labeled_acc:.4f}\")\n",
        "if unlabeled_acc is not None:\n",
        "    print(f\"Final Unlabeled (Auto-Labeled) Accuracy: {unlabeled_acc:.4f}\")\n",
        "else:\n",
        "    print(\"No remaining unlabeled samples.\")\n",
        "print(f\"Number of Remaining Unlabeled Samples: {X_unlabeled.shape[0]}\")\n",
        "print(f\"Early Stopping Triggered: {stopped_early}\")\n",
        "print(\"------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
