{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.10), please consider upgrading to the latest version (0.3.11).\n",
      "Dataset downloaded to: /home/youssef-abuzeid/.cache/kagglehub/datasets/mohamedgamal07/reduced-mnist/versions/1\n",
      "Files in the dataset: ['Reduced MNIST Data']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import kagglehub\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "# Check for GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Download the ReducedMNIST dataset\n",
    "path = kagglehub.dataset_download(\"mohamedgamal07/reduced-mnist\")\n",
    "print(f\"Dataset downloaded to: {path}\")\n",
    "\n",
    "# List the files in the dataset\n",
    "files = os.listdir(path)\n",
    "print(\"Files in the dataset:\", files)\n",
    "\n",
    "path = path+\"/Reduced MNIST Data\"\n",
    "\n",
    "train_dir = path +'/Reduced Trainging data'\n",
    "test_dir = path+'/Reduced Testing data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to load images from a directory\n",
    "def load_images_from_directory(directory, n_samples_per_class=None):\n",
    "    x_data, y_data = [], []\n",
    "    for class_label in range(10):\n",
    "        class_dir = os.path.join(directory, str(class_label))\n",
    "        images = [os.path.join(class_dir, f) for f in os.listdir(class_dir) if f.endswith(('.png', '.jpg'))]\n",
    "        if n_samples_per_class:\n",
    "            images = np.random.choice(images, n_samples_per_class, replace=False)\n",
    "        for img_path in images:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "            img = img.astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "            x_data.append(img)\n",
    "            y_data.append(class_label)\n",
    "    x_data = np.array(x_data).reshape(-1, 28, 28, 1)  # Reshape for CNN\n",
    "    y_data = np.array(y_data)\n",
    "    return x_data, y_data\n",
    "\n",
    "# Load training subsets\n",
    "x_train_300, y_train_300 = load_images_from_directory(train_dir, n_samples_per_class=30)  # 30 per class = 300 total\n",
    "x_train_700, y_train_700 = load_images_from_directory(train_dir, n_samples_per_class=70)  # 70 per class = 700 total\n",
    "x_train_1000, y_train_1000 = load_images_from_directory(train_dir, n_samples_per_class=100)  # 100 per class = 1000 total\n",
    "\n",
    "# Load test set (200 samples total)\n",
    "x_test, y_test = load_images_from_directory(test_dir, n_samples_per_class=200)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotate(image):\n",
    "    # Generate a random float between -30 and 30 degrees\n",
    "    angle_deg = tf.random.uniform([], minval=-30, maxval=30, dtype=tf.float32)\n",
    "\n",
    "    # Convert to float and normalize for RandomRotation (±30° ≈ ±0.083 of full turn)\n",
    "    angle_factor = float(angle_deg.numpy()) / 360.0\n",
    "\n",
    "    # Apply rotation\n",
    "    rotated = tf.keras.layers.RandomRotation(factor=angle_factor)(tf.expand_dims(image, 0))\n",
    "    return tf.squeeze(rotated, axis=0)\n",
    "\n",
    "def random_translate(image):\n",
    "    # Random shift in pixels\n",
    "    dx = tf.random.uniform([], -5, 5, dtype=tf.float32)\n",
    "    dy = tf.random.uniform([], -5, 5, dtype=tf.float32)\n",
    "\n",
    "    # Get image height and width as Python floats\n",
    "    height, width = image.shape[0], image.shape[1]\n",
    "\n",
    "    # Compute translation factor (fraction of image size)\n",
    "    height_factor = float(dy.numpy()) / float(height)\n",
    "    width_factor = float(dx.numpy()) / float(width)\n",
    "\n",
    "    # Apply translation\n",
    "    translated = tf.keras.layers.RandomTranslation(\n",
    "        height_factor=height_factor,\n",
    "        width_factor=width_factor\n",
    "    )(tf.expand_dims(image, 0))\n",
    "\n",
    "    return tf.squeeze(translated, axis=0)\n",
    "\n",
    "\n",
    "def add_white_noise(image, noise_level=0.1):\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "    noisy_image = image + noise * noise_level\n",
    "    return tf.clip_by_value(noisy_image, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def augment_image(image):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = random_rotate(image)\n",
    "    image = random_translate(image)\n",
    "    image = add_white_noise(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Controlled Augmentation Pipeline ---\n",
    "def generate_dataset_with_augmentation(images, labels, num_real, num_generated):\n",
    "    # Subsample real images\n",
    "    real_images = images[:num_real]\n",
    "    real_labels = labels[:num_real]\n",
    "\n",
    "    if num_generated == 0:\n",
    "        return real_images, real_labels\n",
    "\n",
    "    # How many augmented samples per real sample?\n",
    "    gen_per_sample = num_generated // num_real\n",
    "\n",
    "    synthetic_images = []\n",
    "    synthetic_labels = []\n",
    "\n",
    "    for i in range(num_real):\n",
    "        for _ in range(gen_per_sample):\n",
    "            aug_img = augment_image(real_images[i])\n",
    "            synthetic_images.append(aug_img)\n",
    "            synthetic_labels.append(real_labels[i])\n",
    "\n",
    "    synthetic_images = tf.stack(synthetic_images)\n",
    "    synthetic_labels = tf.convert_to_tensor(synthetic_labels)\n",
    "\n",
    "    # Combine real and generated\n",
    "    all_images = tf.concat([real_images, synthetic_images], axis=0)\n",
    "    all_labels = tf.concat([real_labels, synthetic_labels], axis=0)\n",
    "\n",
    "    return all_images, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Generated dataset with 300 real samples and 1000 synthetic samples.\n",
      "[INFO] Generated dataset with 700 real samples and 1000 synthetic samples.\n",
      "[INFO] Generated dataset with 1000 real samples and 1000 synthetic samples.\n",
      "[INFO] Generated dataset with 300 real samples and 2000 synthetic samples.\n",
      "[INFO] Generated dataset with 700 real samples and 2000 synthetic samples.\n",
      "[INFO] Generated dataset with 1000 real samples and 2000 synthetic samples.\n",
      "[INFO] Generated dataset with 300 real samples and 3000 synthetic samples.\n",
      "[INFO] Generated dataset with 700 real samples and 3000 synthetic samples.\n",
      "[INFO] Generated dataset with 1000 real samples and 3000 synthetic samples.\n"
     ]
    }
   ],
   "source": [
    "#300 samples + 1000 generated\n",
    "X_train_300_1000, y_train_300_1000 = generate_dataset_with_augmentation(x_train_300, y_train_300, 300, 1000)\n",
    "print(\"[INFO] Generated dataset with 300 real samples and 1000 synthetic samples.\")\n",
    "#700 samples + 1000 generated\n",
    "X_train_700_1000, y_train_700_1000 = generate_dataset_with_augmentation(x_train_700, y_train_700, 700, 1000)\n",
    "print(\"[INFO] Generated dataset with 700 real samples and 1000 synthetic samples.\")\n",
    "#1000 samples + 1000 generated\n",
    "X_train_1000_1000, y_train_1000_1000 = generate_dataset_with_augmentation(x_train_1000, y_train_1000, 1000, 1000)\n",
    "print(\"[INFO] Generated dataset with 1000 real samples and 1000 synthetic samples.\")\n",
    "\n",
    "#300 samples + 2000 generated\n",
    "X_train_300_2000, y_train_300_2000 = generate_dataset_with_augmentation(x_train_300, y_train_300, 300, 2000)\n",
    "print(\"[INFO] Generated dataset with 300 real samples and 2000 synthetic samples.\")\n",
    "#700 samples + 2000 generated\n",
    "X_train_700_2000, y_train_700_2000 = generate_dataset_with_augmentation(x_train_700, y_train_700, 700, 2000)\n",
    "print(\"[INFO] Generated dataset with 700 real samples and 2000 synthetic samples.\")\n",
    "#1000 samples + 2000 generated\n",
    "X_train_1000_2000, y_train_1000_2000 = generate_dataset_with_augmentation(x_train_1000, y_train_1000, 1000, 2000)\n",
    "print(\"[INFO] Generated dataset with 1000 real samples and 2000 synthetic samples.\")\n",
    "\n",
    "#300 samples + 3000 generated\n",
    "X_train_300_3000, y_train_300_3000 = generate_dataset_with_augmentation(x_train_300, y_train_300, 300, 3000)\n",
    "print(\"[INFO] Generated dataset with 300 real samples and 3000 synthetic samples.\")\n",
    "#700 samples + 3000 generated\n",
    "X_train_700_3000, y_train_700_3000 = generate_dataset_with_augmentation(x_train_700, y_train_700, 700, 3000)\n",
    "print(\"[INFO] Generated dataset with 700 real samples and 3000 synthetic samples.\")\n",
    "#1000 samples + 3000 generated\n",
    "X_train_1000_3000, y_train_1000_3000 = generate_dataset_with_augmentation(x_train_1000, y_train_1000, 1000, 3000)\n",
    "print(\"[INFO] Generated dataset with 1000 real samples and 3000 synthetic samples.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    \"\"\"Create a simple CNN model for digit classification\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_300_000 = create_cnn_model()\n",
    "model_700_000 = create_cnn_model()\n",
    "model_1000_000 = create_cnn_model()\n",
    "\n",
    "model_300_1000 = create_cnn_model()\n",
    "model_700_1000 = create_cnn_model()\n",
    "model_1000_1000 = create_cnn_model()\n",
    "\n",
    "model_300_2000 = create_cnn_model()\n",
    "model_700_2000 = create_cnn_model()\n",
    "model_1000_2000 = create_cnn_model()\n",
    "\n",
    "model_300_3000 = create_cnn_model()\n",
    "model_700_3000 = create_cnn_model()\n",
    "model_1000_3000 = create_cnn_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.1875 - loss: 2.2817"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 01:01:17.514232: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.6 = (f32[12,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,1,28,28]{3,2,1,0} %bitcast.4265, f32[32,1,3,3]{3,2,1,0} %bitcast.4272, f32[32]{0} %bitcast.4738), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_12_1/conv2d_24_1/convolution\" source_file=\"/home/youssef-abuzeid/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-17 01:01:17.563902: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.7 = (f32[12,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,32,13,13]{3,2,1,0} %bitcast.4802, f32[64,32,3,3]{3,2,1,0} %bitcast.4292, f32[64]{0} %bitcast.4862), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_12_1/conv2d_25_1/convolution\" source_file=\"/home/youssef-abuzeid/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.1638 - loss: 2.2547\n",
      "Epoch 2/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4041 - loss: 1.9736 \n",
      "Epoch 3/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5360 - loss: 1.5244 \n",
      "Epoch 4/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6662 - loss: 1.0844 \n",
      "Epoch 5/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7539 - loss: 0.7623 \n",
      "Epoch 6/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8182 - loss: 0.5456 \n",
      "Epoch 7/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8214 - loss: 0.4924 \n",
      "Epoch 8/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8736 - loss: 0.3797 \n",
      "Epoch 9/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8982 - loss: 0.2977 \n",
      "Epoch 10/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9168 - loss: 0.2204 \n",
      "Epoch 11/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9356 - loss: 0.2091 \n",
      "Epoch 12/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9339 - loss: 0.1971 \n",
      "Epoch 13/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9622 - loss: 0.1605 \n",
      "Epoch 14/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9525 - loss: 0.1633 \n",
      "Epoch 15/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9599 - loss: 0.1198 \n",
      "Epoch 16/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9683 - loss: 0.1232 \n",
      "Epoch 17/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9748 - loss: 0.1061 \n",
      "Epoch 18/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9476 - loss: 0.1353 \n",
      "Epoch 19/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9666 - loss: 0.1167 \n",
      "Epoch 20/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9785 - loss: 0.0999 \n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Classification Report for 300 samples + 0 generated:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       200\n",
      "           1       0.99      0.99      0.99       200\n",
      "           2       0.93      0.89      0.91       200\n",
      "           3       0.98      0.92      0.95       200\n",
      "           4       0.97      0.98      0.97       200\n",
      "           5       0.95      0.92      0.94       200\n",
      "           6       0.91      0.98      0.95       200\n",
      "           7       0.93      0.93      0.93       200\n",
      "           8       0.87      0.94      0.91       200\n",
      "           9       0.93      0.90      0.92       200\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.94      0.94      0.94      2000\n",
      "weighted avg       0.94      0.94      0.94      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_300_000 = model_300_000.fit(\n",
    "    x_train_300, y_train_300,\n",
    "    epochs=20,\n",
    "    batch_size=32,    \n",
    ")\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_300_000 = model_300_000.predict(x_test)\n",
    "y_pred_300_000_classes = np.argmax(y_pred_300_000, axis=1)\n",
    "print(\"Classification Report for 300 samples + 0 generated:\")\n",
    "print(classification_report(y_test, y_pred_300_000_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m21/38\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1377 - loss: 2.2810 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 01:04:37.575015: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.6 = (f32[16,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,1,28,28]{3,2,1,0} %bitcast.4265, f32[32,1,3,3]{3,2,1,0} %bitcast.4272, f32[32]{0} %bitcast.4738), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_15_1/conv2d_30_1/convolution\" source_file=\"/home/youssef-abuzeid/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-17 01:04:37.611878: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.7 = (f32[16,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,13,13]{3,2,1,0} %bitcast.4802, f32[64,32,3,3]{3,2,1,0} %bitcast.4292, f32[64]{0} %bitcast.4862), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_15_1/conv2d_31_1/convolution\" source_file=\"/home/youssef-abuzeid/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.1807 - loss: 2.2233\n",
      "Epoch 2/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5343 - loss: 1.4117\n",
      "Epoch 3/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7306 - loss: 0.8797\n",
      "Epoch 4/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.7036\n",
      "Epoch 5/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8222 - loss: 0.5871\n",
      "Epoch 6/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8698 - loss: 0.4379\n",
      "Epoch 7/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8693 - loss: 0.3783\n",
      "Epoch 8/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.2882\n",
      "Epoch 9/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.3032\n",
      "Epoch 10/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9297 - loss: 0.2404\n",
      "Epoch 11/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.2046\n",
      "Epoch 12/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9442 - loss: 0.1672\n",
      "Epoch 13/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1757\n",
      "Epoch 14/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.1567\n",
      "Epoch 15/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1361\n",
      "Epoch 16/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1231\n",
      "Epoch 17/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.1120\n",
      "Epoch 18/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.0945\n",
      "Epoch 19/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.1028\n",
      "Epoch 20/20\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9765 - loss: 0.0792\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Classification Report for 300 samples + 1000 generated:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       200\n",
      "           1       1.00      1.00      1.00       200\n",
      "           2       0.96      0.88      0.92       200\n",
      "           3       0.96      0.96      0.96       200\n",
      "           4       0.98      0.96      0.97       200\n",
      "           5       0.98      0.94      0.96       200\n",
      "           6       0.98      0.96      0.97       200\n",
      "           7       0.96      0.96      0.96       200\n",
      "           8       0.87      0.96      0.91       200\n",
      "           9       0.94      0.98      0.96       200\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_300_1000 = model_300_1000.fit(\n",
    "    X_train_300_1000, y_train_300_1000,\n",
    "    epochs=20,\n",
    "    batch_size=32,    \n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "y_pred_300_1000 = model_300_1000.predict(x_test)\n",
    "y_pred_300_1000_classes = np.argmax(y_pred_300_1000, axis=1)\n",
    "print(\"Classification Report for 300 samples + 1000 generated:\")\n",
    "print(classification_report(y_test, y_pred_300_1000_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m58/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2105 - loss: 2.1418"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 01:05:11.397018: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.6 = (f32[20,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,1,28,28]{3,2,1,0} %bitcast.4265, f32[32,1,3,3]{3,2,1,0} %bitcast.4272, f32[32]{0} %bitcast.4738), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_18_1/conv2d_36_1/convolution\" source_file=\"/home/youssef-abuzeid/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-17 01:05:11.435162: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.7 = (f32[20,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,32,13,13]{3,2,1,0} %bitcast.4802, f32[64,32,3,3]{3,2,1,0} %bitcast.4292, f32[64]{0} %bitcast.4862), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_18_1/conv2d_37_1/convolution\" source_file=\"/home/youssef-abuzeid/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.2309 - loss: 2.1005\n",
      "Epoch 2/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6192 - loss: 1.1404\n",
      "Epoch 3/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.7764\n",
      "Epoch 4/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8107 - loss: 0.5855\n",
      "Epoch 5/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8382 - loss: 0.4835\n",
      "Epoch 6/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8825 - loss: 0.3659\n",
      "Epoch 7/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.3326\n",
      "Epoch 8/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9001 - loss: 0.3165\n",
      "Epoch 9/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2535\n",
      "Epoch 10/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2512\n",
      "Epoch 11/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9311 - loss: 0.2073\n",
      "Epoch 12/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.1960\n",
      "Epoch 13/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9477 - loss: 0.1612\n",
      "Epoch 14/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1449\n",
      "Epoch 15/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9479 - loss: 0.1520\n",
      "Epoch 16/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1303\n",
      "Epoch 17/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9553 - loss: 0.1396\n",
      "Epoch 18/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0994\n",
      "Epoch 19/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.0958\n",
      "Epoch 20/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.1018\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Classification Report for 300 samples + 2000 generated:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       200\n",
      "           1       1.00      0.99      1.00       200\n",
      "           2       0.94      0.92      0.93       200\n",
      "           3       0.96      0.95      0.96       200\n",
      "           4       0.96      0.96      0.96       200\n",
      "           5       0.96      0.92      0.94       200\n",
      "           6       0.98      0.98      0.98       200\n",
      "           7       0.97      0.95      0.96       200\n",
      "           8       0.88      0.96      0.92       200\n",
      "           9       0.95      0.97      0.96       200\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_300_2000 = model_300_2000.fit(\n",
    "    X_train_300_2000, y_train_300_2000,\n",
    "    epochs=20,\n",
    "    batch_size=32,    \n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "y_pred_300_2000 = model_300_2000.predict(x_test)\n",
    "y_pred_300_2000_classes = np.argmax(y_pred_300_2000, axis=1)\n",
    "print(\"Classification Report for 300 samples + 2000 generated:\")\n",
    "print(classification_report(y_test, y_pred_300_2000_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m 99/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2915 - loss: 1.9921"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 01:05:32.004118: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.7 = (f32[4,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,32,13,13]{3,2,1,0} %bitcast.4800, f32[64,32,3,3]{3,2,1,0} %bitcast.4292, f32[64]{0} %bitcast.4860), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_21_1/conv2d_43_1/convolution\" source_file=\"/home/youssef-abuzeid/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.3009 - loss: 1.9690\n",
      "Epoch 2/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7069 - loss: 0.8593\n",
      "Epoch 3/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.5411\n",
      "Epoch 4/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8599 - loss: 0.4094\n",
      "Epoch 5/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.3208\n",
      "Epoch 6/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.2643\n",
      "Epoch 7/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9302 - loss: 0.2079\n",
      "Epoch 8/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9386 - loss: 0.1845\n",
      "Epoch 9/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1494\n",
      "Epoch 10/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1397\n",
      "Epoch 11/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9552 - loss: 0.1327\n",
      "Epoch 12/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1119\n",
      "Epoch 13/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.1163\n",
      "Epoch 14/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.0769\n",
      "Epoch 15/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9409 - loss: 0.1757\n",
      "Epoch 16/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0900\n",
      "Epoch 17/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9777 - loss: 0.0729\n",
      "Epoch 18/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.0657\n",
      "Epoch 19/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0521\n",
      "Epoch 20/20\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0575\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Classification Report for 300 samples + 3000 generated:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       200\n",
      "           1       1.00      1.00      1.00       200\n",
      "           2       0.94      0.93      0.94       200\n",
      "           3       0.97      0.95      0.96       200\n",
      "           4       0.94      0.99      0.97       200\n",
      "           5       0.97      0.93      0.95       200\n",
      "           6       0.97      0.97      0.97       200\n",
      "           7       0.93      0.96      0.95       200\n",
      "           8       0.89      0.95      0.92       200\n",
      "           9       0.98      0.90      0.93       200\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_300_3000 = model_300_3000.fit(\n",
    "    X_train_300_3000, y_train_300_3000,\n",
    "    epochs=20,\n",
    "    batch_size=32,    \n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "y_pred_300_3000 = model_300_3000.predict(x_test)\n",
    "y_pred_300_3000_classes = np.argmax(y_pred_300_3000, axis=1)\n",
    "print(\"Classification Report for 300 samples + 3000 generated:\")\n",
    "print(classification_report(y_test, y_pred_300_3000_classes))\n",
    "# Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m18/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1394 - loss: 2.2649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 01:06:21.117640: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.6 = (f32[28,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[28,1,28,28]{3,2,1,0} %bitcast.4265, f32[32,1,3,3]{3,2,1,0} %bitcast.4272, f32[32]{0} %bitcast.4738), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_13_1/conv2d_26_1/convolution\" source_file=\"/home/youssef-abuzeid/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-17 01:06:21.156211: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.7 = (f32[28,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[28,32,13,13]{3,2,1,0} %bitcast.4802, f32[64,32,3,3]{3,2,1,0} %bitcast.4292, f32[64]{0} %bitcast.4862), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_13_1/conv2d_27_1/convolution\" source_file=\"/home/youssef-abuzeid/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.1718 - loss: 2.2329\n",
      "Epoch 2/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5864 - loss: 1.3815\n",
      "Epoch 3/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7676 - loss: 0.7986\n",
      "Epoch 4/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8247 - loss: 0.5442\n",
      "Epoch 5/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8551 - loss: 0.4411\n",
      "Epoch 6/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9053 - loss: 0.3374\n",
      "Epoch 7/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9108 - loss: 0.2786\n",
      "Epoch 8/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9200 - loss: 0.2607\n",
      "Epoch 9/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9277 - loss: 0.2102\n",
      "Epoch 10/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.1683\n",
      "Epoch 11/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9499 - loss: 0.1765\n",
      "Epoch 12/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9455 - loss: 0.1546\n",
      "Epoch 13/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.1248\n",
      "Epoch 14/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9737 - loss: 0.1163\n",
      "Epoch 15/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.1293\n",
      "Epoch 16/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9679 - loss: 0.1038\n",
      "Epoch 17/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9737 - loss: 0.0987\n",
      "Epoch 18/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9712 - loss: 0.0759\n",
      "Epoch 19/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0689\n",
      "Epoch 20/20\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0569\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Classification Report for 700 samples + 0 generated:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       200\n",
      "           1       0.99      0.99      0.99       200\n",
      "           2       0.97      0.90      0.93       200\n",
      "           3       0.98      0.95      0.97       200\n",
      "           4       0.96      1.00      0.98       200\n",
      "           5       0.95      0.95      0.95       200\n",
      "           6       0.94      0.99      0.97       200\n",
      "           7       0.94      0.95      0.95       200\n",
      "           8       0.94      0.96      0.95       200\n",
      "           9       0.96      0.93      0.94       200\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_700_000 = model_700_000.fit(\n",
    "\n",
    "    x_train_700, y_train_700,\n",
    "    epochs=20,\n",
    "    batch_size=32,    \n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "y_pred_700_000 = model_700_000.predict(x_test)\n",
    "y_pred_700_000_classes = np.argmax(y_pred_700_000, axis=1)\n",
    "print(\"Classification Report for 700 samples + 0 generated:\")\n",
    "print(classification_report(y_test, y_pred_700_000_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.2503 - loss: 2.1196\n",
      "Epoch 2/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6345 - loss: 1.1401\n",
      "Epoch 3/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.8110\n",
      "Epoch 4/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.6682\n",
      "Epoch 5/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.4916\n",
      "Epoch 6/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8437 - loss: 0.4897\n",
      "Epoch 7/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.3891\n",
      "Epoch 8/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8890 - loss: 0.3464\n",
      "Epoch 9/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8976 - loss: 0.3442\n",
      "Epoch 10/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8915 - loss: 0.3139\n",
      "Epoch 11/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9346 - loss: 0.2235\n",
      "Epoch 12/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9206 - loss: 0.2324\n",
      "Epoch 13/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9408 - loss: 0.1829\n",
      "Epoch 14/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9461 - loss: 0.1556\n",
      "Epoch 15/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9409 - loss: 0.1923\n",
      "Epoch 16/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.1433\n",
      "Epoch 17/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9456 - loss: 0.1377\n",
      "Epoch 18/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9568 - loss: 0.1216\n",
      "Epoch 19/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9483 - loss: 0.1709\n",
      "Epoch 20/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9670 - loss: 0.1225\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Classification Report for 700 samples + 1000 generated:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       200\n",
      "           1       1.00      0.99      1.00       200\n",
      "           2       0.96      0.93      0.94       200\n",
      "           3       0.98      0.96      0.97       200\n",
      "           4       0.98      0.97      0.98       200\n",
      "           5       0.97      0.97      0.97       200\n",
      "           6       0.97      1.00      0.99       200\n",
      "           7       0.99      0.89      0.94       200\n",
      "           8       0.96      0.96      0.96       200\n",
      "           9       0.88      0.99      0.93       200\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_700_1000 = model_700_1000.fit(\n",
    "    X_train_700_1000, y_train_700_1000,\n",
    "    epochs=20,\n",
    "    batch_size=32,    \n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "y_pred_700_1000 = model_700_1000.predict(x_test)\n",
    "y_pred_700_1000_classes = np.argmax(y_pred_700_1000, axis=1)\n",
    "print(\"Classification Report for 700 samples + 1000 generated:\")\n",
    "print(classification_report(y_test, y_pred_700_1000_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.2365 - loss: 2.0673\n",
      "Epoch 2/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6775 - loss: 1.0320\n",
      "Epoch 3/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7708 - loss: 0.6993\n",
      "Epoch 4/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8262 - loss: 0.5663\n",
      "Epoch 5/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8521 - loss: 0.4450\n",
      "Epoch 6/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8753 - loss: 0.3887\n",
      "Epoch 7/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8772 - loss: 0.3554\n",
      "Epoch 8/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9021 - loss: 0.2857\n",
      "Epoch 9/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2454\n",
      "Epoch 10/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9246 - loss: 0.2267\n",
      "Epoch 11/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.1857\n",
      "Epoch 12/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1714\n",
      "Epoch 13/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9470 - loss: 0.1547\n",
      "Epoch 14/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9457 - loss: 0.1728\n",
      "Epoch 15/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1323\n",
      "Epoch 16/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1330\n",
      "Epoch 17/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9681 - loss: 0.1058\n",
      "Epoch 18/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.1252\n",
      "Epoch 19/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0967\n",
      "Epoch 20/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9765 - loss: 0.0708\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Classification Report for 700 samples + 2000 generated:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       200\n",
      "           1       1.00      0.99      1.00       200\n",
      "           2       0.98      0.93      0.95       200\n",
      "           3       1.00      0.96      0.98       200\n",
      "           4       0.99      0.97      0.98       200\n",
      "           5       0.95      0.97      0.96       200\n",
      "           6       0.98      0.99      0.99       200\n",
      "           7       0.98      0.91      0.95       200\n",
      "           8       0.93      0.98      0.95       200\n",
      "           9       0.88      0.98      0.93       200\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_700_2000 = model_700_2000.fit(\n",
    "    X_train_700_2000, y_train_700_2000,\n",
    "    epochs=20,\n",
    "    batch_size=32,    \n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "y_pred_700_2000 = model_700_2000.predict(x_test)\n",
    "y_pred_700_2000_classes = np.argmax(y_pred_700_2000, axis=1)\n",
    "print(\"Classification Report for 700 samples + 2000 generated:\")\n",
    "print(classification_report(y_test, y_pred_700_2000_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3030 - loss: 1.9430\n",
      "Epoch 2/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7265 - loss: 0.8556\n",
      "Epoch 3/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8161 - loss: 0.5911\n",
      "Epoch 4/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8539 - loss: 0.4791\n",
      "Epoch 5/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8862 - loss: 0.3617\n",
      "Epoch 6/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9076 - loss: 0.3037\n",
      "Epoch 7/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2737\n",
      "Epoch 8/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9241 - loss: 0.2119\n",
      "Epoch 9/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1913\n",
      "Epoch 10/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9405 - loss: 0.1650\n",
      "Epoch 11/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9539 - loss: 0.1479\n",
      "Epoch 12/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1262\n",
      "Epoch 13/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1163\n",
      "Epoch 14/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9673 - loss: 0.1025\n",
      "Epoch 15/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1060\n",
      "Epoch 16/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.0874\n",
      "Epoch 17/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9748 - loss: 0.0726\n",
      "Epoch 18/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.0763\n",
      "Epoch 19/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0572\n",
      "Epoch 20/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0668\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Classification Report for 700 samples + 3000 generated:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       200\n",
      "           1       1.00      0.99      1.00       200\n",
      "           2       0.97      0.94      0.95       200\n",
      "           3       0.99      0.96      0.98       200\n",
      "           4       0.99      0.99      0.99       200\n",
      "           5       0.95      0.97      0.96       200\n",
      "           6       0.98      0.99      0.99       200\n",
      "           7       0.94      0.99      0.97       200\n",
      "           8       0.94      0.96      0.95       200\n",
      "           9       1.00      0.96      0.98       200\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.98      0.97      0.98      2000\n",
      "weighted avg       0.98      0.97      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_700_3000 = model_700_3000.fit(\n",
    "    X_train_700_3000, y_train_700_3000,\n",
    "    epochs=20,\n",
    "    batch_size=32,    \n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "y_pred_700_3000 = model_700_3000.predict(x_test)\n",
    "y_pred_700_3000_classes = np.argmax(y_pred_700_3000, axis=1)\n",
    "print(\"Classification Report for 700 samples + 3000 generated:\")\n",
    "print(classification_report(y_test, y_pred_700_3000_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m19/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1879 - loss: 2.2121 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 01:07:42.102812: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.7 = (f32[8,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,32,13,13]{3,2,1,0} %bitcast.4800, f32[64,32,3,3]{3,2,1,0} %bitcast.4292, f32[64]{0} %bitcast.4860), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_14_1/conv2d_29_1/convolution\" source_file=\"/home/youssef-abuzeid/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.2577 - loss: 2.1029\n",
      "Epoch 2/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6804 - loss: 0.9916\n",
      "Epoch 3/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.5873\n",
      "Epoch 4/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8701 - loss: 0.4500\n",
      "Epoch 5/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8857 - loss: 0.3543\n",
      "Epoch 6/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9094 - loss: 0.3175\n",
      "Epoch 7/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.2956\n",
      "Epoch 8/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1727\n",
      "Epoch 9/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1593\n",
      "Epoch 10/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.1266\n",
      "Epoch 11/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9423 - loss: 0.1812\n",
      "Epoch 12/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1402\n",
      "Epoch 13/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9442 - loss: 0.1547\n",
      "Epoch 14/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1355\n",
      "Epoch 15/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9713 - loss: 0.0926\n",
      "Epoch 16/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9780 - loss: 0.0686\n",
      "Epoch 17/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.0751\n",
      "Epoch 18/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9806 - loss: 0.0629\n",
      "Epoch 19/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0636\n",
      "Epoch 20/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9753 - loss: 0.0613\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Classification Report for 1000 samples + 0 generated:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       200\n",
      "           1       1.00      0.98      0.99       200\n",
      "           2       0.96      0.94      0.95       200\n",
      "           3       0.99      0.94      0.97       200\n",
      "           4       0.99      0.97      0.98       200\n",
      "           5       0.97      0.96      0.97       200\n",
      "           6       0.97      0.99      0.98       200\n",
      "           7       0.95      0.97      0.96       200\n",
      "           8       0.92      0.97      0.95       200\n",
      "           9       0.96      0.96      0.96       200\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_1000_000 = model_1000_000.fit(\n",
    "    x_train_1000, y_train_1000,\n",
    "    epochs=20,\n",
    "    batch_size=32,    \n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "y_pred_1000_000 = model_1000_000.predict(x_test)\n",
    "y_pred_1000_000_classes = np.argmax(y_pred_1000_000, axis=1)\n",
    "print(\"Classification Report for 1000 samples + 0 generated:\")\n",
    "print(classification_report(y_test, y_pred_1000_000_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.2853 - loss: 2.0294\n",
      "Epoch 2/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7029 - loss: 0.9382\n",
      "Epoch 3/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7960 - loss: 0.6709\n",
      "Epoch 4/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8445 - loss: 0.5303\n",
      "Epoch 5/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8606 - loss: 0.4266\n",
      "Epoch 6/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8969 - loss: 0.3432\n",
      "Epoch 7/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 0.3305\n",
      "Epoch 8/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.2776\n",
      "Epoch 9/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9295 - loss: 0.2282\n",
      "Epoch 10/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9282 - loss: 0.2113\n",
      "Epoch 11/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9275 - loss: 0.2059\n",
      "Epoch 12/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9493 - loss: 0.1684\n",
      "Epoch 13/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1348\n",
      "Epoch 14/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9481 - loss: 0.1605\n",
      "Epoch 15/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9482 - loss: 0.1482\n",
      "Epoch 16/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.1077\n",
      "Epoch 17/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.1111\n",
      "Epoch 18/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0858\n",
      "Epoch 19/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.0930\n",
      "Epoch 20/20\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.0854\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Classification Report for 1000 samples + 1000 generated:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       200\n",
      "           1       1.00      0.99      0.99       200\n",
      "           2       0.98      0.96      0.97       200\n",
      "           3       0.99      0.98      0.99       200\n",
      "           4       1.00      0.99      0.99       200\n",
      "           5       0.98      0.97      0.98       200\n",
      "           6       0.97      1.00      0.99       200\n",
      "           7       0.93      0.98      0.96       200\n",
      "           8       0.98      0.98      0.98       200\n",
      "           9       0.99      0.95      0.97       200\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.98      0.98      0.98      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_1000_1000 = model_1000_1000.fit(\n",
    "    X_train_1000_1000, y_train_1000_1000,\n",
    "    epochs=20,\n",
    "    batch_size=32,    \n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "y_pred_1000_1000 = model_1000_1000.predict(x_test)\n",
    "y_pred_1000_1000_classes = np.argmax(y_pred_1000_1000, axis=1)\n",
    "print(\"Classification Report for 1000 samples + 1000 generated:\")\n",
    "print(classification_report(y_test, y_pred_1000_1000_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.3067 - loss: 1.9634\n",
      "Epoch 2/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7219 - loss: 0.8406\n",
      "Epoch 3/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 0.5991\n",
      "Epoch 4/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8396 - loss: 0.4999\n",
      "Epoch 5/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.4148\n",
      "Epoch 6/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.3636\n",
      "Epoch 7/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.3033\n",
      "Epoch 8/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8969 - loss: 0.2863\n",
      "Epoch 9/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9158 - loss: 0.2594\n",
      "Epoch 10/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.2387\n",
      "Epoch 11/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9378 - loss: 0.1781\n",
      "Epoch 12/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9407 - loss: 0.1910\n",
      "Epoch 13/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1544\n",
      "Epoch 14/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1274\n",
      "Epoch 15/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1133\n",
      "Epoch 16/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.1069\n",
      "Epoch 17/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.1033\n",
      "Epoch 18/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0999\n",
      "Epoch 19/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9681 - loss: 0.0896\n",
      "Epoch 20/20\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.0930\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Classification Report for 1000 samples + 2000 generated:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       200\n",
      "           1       1.00      0.96      0.98       200\n",
      "           2       0.98      0.96      0.97       200\n",
      "           3       1.00      0.98      0.99       200\n",
      "           4       0.99      0.98      0.99       200\n",
      "           5       0.97      0.99      0.98       200\n",
      "           6       0.97      1.00      0.98       200\n",
      "           7       0.98      0.97      0.97       200\n",
      "           8       0.95      0.98      0.96       200\n",
      "           9       0.97      0.97      0.97       200\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.98      0.98      0.98      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_1000_2000 = model_1000_2000.fit(\n",
    "    X_train_1000_2000, y_train_1000_2000,\n",
    "    epochs=20,\n",
    "    batch_size=32,    \n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "y_pred_1000_2000 = model_1000_2000.predict(x_test)\n",
    "y_pred_1000_2000_classes = np.argmax(y_pred_1000_2000, axis=1)\n",
    "print(\"Classification Report for 1000 samples + 2000 generated:\")\n",
    "print(classification_report(y_test, y_pred_1000_2000_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3409 - loss: 1.8771\n",
      "Epoch 2/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7248 - loss: 0.8533\n",
      "Epoch 3/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8088 - loss: 0.6059\n",
      "Epoch 4/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.4704\n",
      "Epoch 5/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8788 - loss: 0.3802\n",
      "Epoch 6/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 0.3371\n",
      "Epoch 7/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2784\n",
      "Epoch 8/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.2573\n",
      "Epoch 9/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9338 - loss: 0.2074\n",
      "Epoch 10/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9398 - loss: 0.1794\n",
      "Epoch 11/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9479 - loss: 0.1776\n",
      "Epoch 12/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9482 - loss: 0.1529\n",
      "Epoch 13/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1336\n",
      "Epoch 14/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1455\n",
      "Epoch 15/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.1140\n",
      "Epoch 16/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9654 - loss: 0.1033\n",
      "Epoch 17/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.0877\n",
      "Epoch 18/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9678 - loss: 0.0941\n",
      "Epoch 19/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.0867\n",
      "Epoch 20/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9748 - loss: 0.0691\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Classification Report for 1000 samples + 3000 generated:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       200\n",
      "           1       1.00      0.99      0.99       200\n",
      "           2       0.99      0.95      0.97       200\n",
      "           3       0.98      0.98      0.98       200\n",
      "           4       0.98      0.98      0.98       200\n",
      "           5       0.91      0.97      0.94       200\n",
      "           6       0.98      1.00      0.99       200\n",
      "           7       0.97      0.99      0.98       200\n",
      "           8       0.99      0.91      0.95       200\n",
      "           9       0.97      0.98      0.97       200\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.98      0.98      0.98      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_1000_3000 = model_1000_3000.fit(\n",
    "    X_train_1000_3000, y_train_1000_3000,\n",
    "    epochs=20,\n",
    "    batch_size=32,    \n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "y_pred_1000_3000 = model_1000_3000.predict(x_test)\n",
    "y_pred_1000_3000_classes = np.argmax(y_pred_1000_3000, axis=1)\n",
    "print(\"Classification Report for 1000 samples + 3000 generated:\")\n",
    "print(classification_report(y_test, y_pred_1000_3000_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 28, 28, 1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
