{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.10), please consider upgrading to the latest version (0.3.11).\n",
      "Dataset downloaded to: /home/youssef-abuzeid/.cache/kagglehub/datasets/mohamedgamal07/reduced-mnist/versions/1\n",
      "Files in the dataset: ['Reduced MNIST Data']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import kagglehub\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "# Check for GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Download the ReducedMNIST dataset\n",
    "path = kagglehub.dataset_download(\"mohamedgamal07/reduced-mnist\")\n",
    "print(f\"Dataset downloaded to: {path}\")\n",
    "\n",
    "# List the files in the dataset\n",
    "files = os.listdir(path)\n",
    "print(\"Files in the dataset:\", files)\n",
    "\n",
    "path = path+\"/Reduced MNIST Data\"\n",
    "\n",
    "train_dir = path +'/Reduced Trainging data'\n",
    "test_dir = path+'/Reduced Testing data'\n",
    "\n",
    "\n",
    "\n",
    "IMG_SIZE = 28\n",
    "NOISE_DIM = 100\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train_gen = data_gen.flow_from_directory(train_dir,\n",
    "                                          target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                          color_mode='grayscale',\n",
    "                                          class_mode='sparse',\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True)\n",
    "test_gen = data_gen.flow_from_directory(test_dir,\n",
    "                                            target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                            color_mode='grayscale',\n",
    "                                            class_mode='sparse',\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            shuffle=False)\n",
    "\n",
    "                                            \n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the GAN Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we'll define the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Class\n",
    "\n",
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self, noise_dim=NOISE_DIM):\n",
    "        super(Generator, self).__init__()\n",
    "        self.noise_dim = noise_dim\n",
    "\n",
    "        self.model = tf.keras.Sequential([\n",
    "            # Foundation for 7x7 feature maps\n",
    "            tf.keras.layers.Dense(7*7*256, use_bias=False, input_shape=(self.noise_dim,)),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(), \n",
    "            tf.keras.layers.Reshape((7, 7, 256)),\n",
    "            \n",
    "            # First upsampling block\n",
    "            tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            \n",
    "            # Second upsampling block\n",
    "            tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            \n",
    "            # Output layer with tanh activation\n",
    "            tf.keras.layers.Conv2D(1, (5, 5), padding='same', use_bias=True, activation='tanh')\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "       \n",
    "        return  self.model(inputs, training=training)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_noise(batch_size, noise_dim=NOISE_DIM):\n",
    "        \"\"\"Generate Gaussian noise for the generator input.\"\"\"\n",
    "        return np.random.normal(0, 1, (batch_size, noise_dim))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = tf.keras.Sequential([\n",
    "            # First conv block - no batchnorm\n",
    "            tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', \n",
    "                                input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            \n",
    "            # Second conv block\n",
    "            tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            \n",
    "            # Third conv block\n",
    "            tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'),\n",
    "            tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            \n",
    "            # Output layer\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(1)  # No activation - we'll use from_logits=True in loss\n",
    "        ])\n",
    "    def call(self, inputs, training=False):\n",
    "        return self.model(inputs, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(tf.keras.Model):\n",
    "    def __init__(self, noise_dim=NOISE_DIM):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.noise_dim = noise_dim\n",
    "        self.generator = Generator(noise_dim)\n",
    "        self.discriminator = Discriminator()\n",
    "        \n",
    "        # We'll now use separate optimizers instead of compiling the models individually\n",
    "        self.generator_optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "        self.discriminator_optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "        \n",
    "        # Define the GAN model for inference purposes only\n",
    "        self.gan = None\n",
    "    \n",
    "    def compile(self):\n",
    "        super(DCGAN, self).compile()\n",
    "        \n",
    "    @tf.function\n",
    "    def train_step(self, real_images, batch_size):\n",
    "        # Generate noise\n",
    "        \n",
    "        noise = tf.random.normal([batch_size, self.noise_dim])\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            # Generate fake images\n",
    "            generated_images = self.generator(noise, training=True)\n",
    "            \n",
    "            # Get predictions\n",
    "            real_output = self.discriminator(real_images, training=True)\n",
    "            fake_output = self.discriminator(generated_images, training=True)\n",
    "            \n",
    "            # Calculate losses\n",
    "            gen_loss = self.generator_loss(fake_output)\n",
    "            disc_loss = self.discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        gradients_of_generator = gen_tape.gradient(\n",
    "            gen_loss, self.generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(\n",
    "            disc_loss, self.discriminator.trainable_variables)\n",
    "        \n",
    "        # Apply gradients\n",
    "        self.generator_optimizer.apply_gradients(\n",
    "            zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "        self.discriminator_optimizer.apply_gradients(\n",
    "            zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "        \n",
    "        return {'d_loss': disc_loss, 'g_loss': gen_loss}\n",
    "    \n",
    "    def discriminator_loss(self, real_output, fake_output):\n",
    "        # Use from_logits=True for numerical stability\n",
    "        real_labels = tf.ones_like(real_output) * 0.9\n",
    "        real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(\n",
    "            real_labels, real_output)\n",
    "        fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(\n",
    "            tf.zeros_like(fake_output), fake_output)\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return total_loss\n",
    "\n",
    "    def generator_loss(self, fake_output):\n",
    "        return tf.keras.losses.BinaryCrossentropy(from_logits=True)(\n",
    "            tf.ones_like(fake_output), fake_output)\n",
    "    def train(self, real_images, epochs, batch_size):\n",
    "        # Rescale the images to [-1, 1]\n",
    "        real_images = (real_images - 0.5) * 2\n",
    "        \n",
    "        num_batches = len(real_images) // batch_size\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Shuffle data for each epoch\n",
    "            indices = np.random.permutation(len(real_images))\n",
    "            shuffled_images = real_images[indices]\n",
    "            \n",
    "            d_loss_total, g_loss_total = 0, 0\n",
    "            \n",
    "            # Process full batches\n",
    "            for batch_idx in range(num_batches):\n",
    "                start = batch_idx * batch_size\n",
    "                end = start + batch_size\n",
    "                batch_images = shuffled_images[start:end]\n",
    "                \n",
    "                # Train on this batch\n",
    "                losses = self.train_step(batch_images, batch_size)\n",
    "                d_loss_total += losses['d_loss']\n",
    "                g_loss_total += losses['g_loss']\n",
    "            \n",
    "            # Process last partial batch if needed\n",
    "            if len(real_images) % batch_size != 0:\n",
    "                last_batch = shuffled_images[num_batches * batch_size:]\n",
    "                if len(last_batch) > 1:  # Ensure batch size > 1 for batch normalization\n",
    "                    losses = self.train_step(last_batch, len(last_batch))\n",
    "                    d_loss_total += losses['d_loss']\n",
    "                    g_loss_total += losses['g_loss']\n",
    "                    num_batches += 1  # Account for the extra batch in the average\n",
    "            \n",
    "            # Calculate average losses\n",
    "            d_loss_avg = d_loss_total / num_batches\n",
    "            g_loss_avg = g_loss_total / num_batches\n",
    "            \n",
    "            # Print progress\n",
    "            if epoch % 5 == 0 or epoch == epochs - 1:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Discriminator Loss: {d_loss_avg:.4f}, Generator Loss: {g_loss_avg:.4f}\")\n",
    "                self.save_generated_images(epoch)\n",
    "    \n",
    "    def generate_synthetic_data(self, num_samples, num_classes):\n",
    "        \"\"\"Generate synthetic data with balanced labels.\"\"\"\n",
    "        synthetic_images, synthetic_labels = [], []\n",
    "        samples_per_class = num_samples // num_classes\n",
    "        \n",
    "        for digit in range(num_classes):\n",
    "            noise = tf.random.normal([samples_per_class, self.noise_dim])\n",
    "            generated_imgs = self.generator(noise, training=False)\n",
    "            generated_imgs = (generated_imgs + 1) / 2.0  # Rescale to [0, 1]\n",
    "            \n",
    "            synthetic_images.extend(generated_imgs.numpy())\n",
    "            synthetic_labels.extend([digit] * samples_per_class)\n",
    "        \n",
    "        return np.array(synthetic_images), np.array(synthetic_labels)\n",
    "    \n",
    "    def save_generated_images(self, epoch, output_dir='generated_images'):\n",
    "        \"\"\"Save 16 generated images for visualization.\"\"\"\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        noise = tf.random.normal([16, self.noise_dim])\n",
    "        gen_imgs = self.generator(noise, training=False)\n",
    "        gen_imgs = (gen_imgs + 1) / 2.0  # Rescale to [0, 1]\n",
    "        \n",
    "        fig, axs = plt.subplots(4, 4, figsize=(10, 10))\n",
    "        cnt = 0\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                axs[i, j].imshow(gen_imgs[cnt].numpy()[:, :, 0], cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        \n",
    "        plt.savefig(os.path.join(output_dir, f'epoch_{epoch}.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing the entire dataset...\n",
      "Processing 79 batches...\n",
      "Processed 10/79 batches\n",
      "Processed 20/79 batches\n",
      "Processed 30/79 batches\n",
      "Processed 40/79 batches\n",
      "Processed 50/79 batches\n",
      "Processed 60/79 batches\n",
      "Processed 70/79 batches\n",
      "Training data shape: (9984, 28, 28, 1)\n",
      "Reshaped training data: (9984, 28, 28, 1)\n",
      "Label shape: (78, 128)\n",
      "Epoch 1/200, Discriminator Loss: 0.6865, Generator Loss: 2.2331\n",
      "Epoch 6/200, Discriminator Loss: 1.2475, Generator Loss: 0.9695\n",
      "Epoch 11/200, Discriminator Loss: 1.1868, Generator Loss: 1.1057\n",
      "Epoch 16/200, Discriminator Loss: 1.2248, Generator Loss: 1.0378\n",
      "Epoch 21/200, Discriminator Loss: 1.2152, Generator Loss: 1.0969\n",
      "Epoch 26/200, Discriminator Loss: 1.1952, Generator Loss: 1.1266\n",
      "Epoch 31/200, Discriminator Loss: 1.1736, Generator Loss: 1.1610\n",
      "Epoch 36/200, Discriminator Loss: 1.1512, Generator Loss: 1.2005\n",
      "Epoch 41/200, Discriminator Loss: 1.1507, Generator Loss: 1.2089\n",
      "Epoch 46/200, Discriminator Loss: 1.1477, Generator Loss: 1.2093\n",
      "Epoch 51/200, Discriminator Loss: 1.1508, Generator Loss: 1.2240\n",
      "Epoch 56/200, Discriminator Loss: 1.1517, Generator Loss: 1.2224\n",
      "Epoch 61/200, Discriminator Loss: 1.1595, Generator Loss: 1.2370\n",
      "Epoch 66/200, Discriminator Loss: 1.1483, Generator Loss: 1.2361\n",
      "Epoch 71/200, Discriminator Loss: 1.1407, Generator Loss: 1.2505\n",
      "Epoch 76/200, Discriminator Loss: 1.1422, Generator Loss: 1.2524\n",
      "Epoch 81/200, Discriminator Loss: 1.1251, Generator Loss: 1.2702\n",
      "Epoch 86/200, Discriminator Loss: 1.1081, Generator Loss: 1.3031\n"
     ]
    }
   ],
   "source": [
    "# Initialize the DCGAN\n",
    "dcgan = DCGAN()\n",
    "dcgan.compile()\n",
    "\n",
    "# Load and process the entire training data from the generator\n",
    "print(\"Loading and processing the entire dataset...\")\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "# Get the number of batches in the generator\n",
    "num_batches = len(train_gen)\n",
    "print(f\"Processing {num_batches} batches...\")\n",
    "\n",
    "# Reset the generator to start from the beginning\n",
    "train_gen.reset()\n",
    "\n",
    "# Collect all images and labels from the generator\n",
    "for i in range(num_batches):\n",
    "    batch_images, batch_labels = next(train_gen)\n",
    "    if batch_images.shape[0] != BATCH_SIZE:\n",
    "        # Skip the last batch if it's smaller than BATCH_SIZE\n",
    "        continue\n",
    "    all_images.append(batch_images)\n",
    "    all_labels.append(batch_labels)\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"Processed {i+1}/{num_batches} batches\")\n",
    "\n",
    "# Combine all batches into single arrays\n",
    "train_images = np.vstack(all_images)\n",
    "train_labels = np.vstack(all_labels)\n",
    "\n",
    "print(\"Training data shape:\", train_images.shape)\n",
    "\n",
    "# Reshape if needed (depending on your data's format)\n",
    "if len(train_images.shape) == 3 or train_images.shape[-1] != 1:\n",
    "    train_images = train_images.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "print(\"Reshaped training data:\", train_images.shape)\n",
    "print(\"Label shape:\", train_labels.shape)\n",
    "\n",
    "# Train the DCGAN\n",
    "dcgan.train(train_images, EPOCHS, BATCH_SIZE)\n",
    "\n",
    "# Generate synthetic data\n",
    "num_samples = 10000\n",
    "num_classes = 10\n",
    "synthetic_images, synthetic_labels = dcgan.generate_synthetic_data(num_samples, num_classes)\n",
    "\n",
    "# Save the synthetic data\n",
    "np.save('synthetic_images.npy', synthetic_images)\n",
    "np.save('synthetic_labels.npy', synthetic_labels)\n",
    "print(f\"Generated and saved {num_samples} synthetic samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
