{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.10), please consider upgrading to the latest version (0.3.12).\n",
      "Dataset downloaded to: /home/youssef-abuzeid/.cache/kagglehub/datasets/mohamedgamal07/reduced-mnist/versions/1\n",
      "Files in the dataset: ['Reduced MNIST Data']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import kagglehub\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from datetime import datetime\n",
    "from augmentations import generate_dataset_with_augmentation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "# Check for GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Download the ReducedMNIST dataset\n",
    "path = kagglehub.dataset_download(\"mohamedgamal07/reduced-mnist\")\n",
    "print(f\"Dataset downloaded to: {path}\")\n",
    "\n",
    "# List the files in the dataset\n",
    "files = os.listdir(path)\n",
    "print(\"Files in the dataset:\", files)\n",
    "\n",
    "path = path+\"/Reduced MNIST Data\"\n",
    "\n",
    "train_dir = path +'/Reduced Trainging data'\n",
    "test_dir = path+'/Reduced Testing data'\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the images to the range [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "num_classes = 10\n",
    "IMG_SIZE = 28\n",
    "NOISE_DIM = 100\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 75\n",
    "\n",
    "# Reshape the images to include the channel dimension (28, 28, 1)\n",
    "x_train = x_train.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "x_test = x_test.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "# Print dataset shapes\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train_gen = data_gen.flow_from_directory(train_dir,\n",
    "                                          target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                          color_mode='grayscale',\n",
    "                                          class_mode='sparse',\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True)\n",
    "test_gen = data_gen.flow_from_directory(test_dir,\n",
    "                                            target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                            color_mode='grayscale',\n",
    "                                            class_mode='sparse',\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            shuffle=False)\n",
    "\n",
    "                                            \n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the GAN Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we'll define the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self, noise_dim=NOISE_DIM, num_classes=10, **kwargs):\n",
    "        super(Generator, self).__init__(**kwargs)\n",
    "        self.noise_dim = noise_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Increase label embedding dimension\n",
    "        self.label_embedding = tf.keras.layers.Embedding(num_classes, 100)  # Increased from 50\n",
    "        self.label_dense = tf.keras.layers.Dense(100, use_bias=False)       # Increased from 50\n",
    "        \n",
    "        # Combined noise and label processing\n",
    "        self.combined_dense = tf.keras.layers.Dense(7*7*256, use_bias=False)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu1 = tf.keras.layers.ReLU()\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3)  # Added dropout layer\n",
    "\n",
    "        \n",
    "        # Create label condition vectors for each layer\n",
    "        self.cond1 = tf.keras.layers.Dense(128, use_bias=False)  # For first upsampling block\n",
    "        self.cond2 = tf.keras.layers.Dense(64, use_bias=False)   # For second upsampling block\n",
    "        \n",
    "        # Reshape layer\n",
    "        self.reshape = tf.keras.layers.Reshape((7, 7, 256))\n",
    "        \n",
    "        # First upsampling block\n",
    "        self.conv_transpose1 = tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu2 = tf.keras.layers.ReLU()\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.3)  # Added dropout layer\n",
    "        # Second upsampling block\n",
    "        self.conv_transpose2 = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu3 = tf.keras.layers.ReLU()\n",
    "        self.dropout3 = tf.keras.layers.Dropout(0.3)  # Added dropout layer\n",
    "        # Output layer with tanh activation\n",
    "        self.output_layer = tf.keras.layers.Conv2D(1, (5, 5), padding='same', use_bias=True, activation='tanh')\n",
    "        \n",
    "        # Define conditioning layers for each block\n",
    "        self.gamma1_layer = tf.keras.layers.Dense(128)  # For first block conditioning\n",
    "        self.beta1_layer = tf.keras.layers.Dense(128)\n",
    "        self.gamma2_layer = tf.keras.layers.Dense(64)   # For second block conditioning\n",
    "        self.beta2_layer = tf.keras.layers.Dense(64)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        noise, labels = inputs\n",
    "        \n",
    "        # Process labels - enhanced embedding\n",
    "        label_embedding = self.label_embedding(labels)\n",
    "        label_embedding = tf.keras.layers.Flatten()(label_embedding)\n",
    "        label_info = self.label_dense(label_embedding)\n",
    "        \n",
    "        # Prepare conditional vectors for each layer\n",
    "        cond1_info = self.cond1(label_embedding)  # For first block\n",
    "        cond2_info = self.cond2(label_embedding)  # For second block\n",
    "        \n",
    "        # Concatenate noise and label info\n",
    "        x = tf.concat([noise, label_info], axis=1)\n",
    "        \n",
    "        # Process combined input\n",
    "        x = self.combined_dense(x)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x, training=training)  # Apply dropout\n",
    "        # Reshape\n",
    "        x = self.reshape(x)\n",
    "        \n",
    "        # First upsampling block with conditioning\n",
    "        x = self.conv_transpose1(x)\n",
    "        # Apply conditional batch normalization with predefined layers\n",
    "        x = self.conditional_bn(x, cond1_info, training, self.bn2, self.gamma1_layer, self.beta1_layer)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        \n",
    "        # Second upsampling block with conditioning\n",
    "        x = self.conv_transpose2(x)\n",
    "        # Apply conditional batch normalization with predefined layers\n",
    "        x = self.conditional_bn(x, cond2_info, training, self.bn3, self.gamma2_layer, self.beta2_layer)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x, training=training)\n",
    "        # Output layer\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def conditional_bn(self, x, condition, training, bn_layer, gamma_layer, beta_layer):\n",
    "        \"\"\"Custom conditional batch normalization using predefined layers\"\"\"\n",
    "        # Apply predefined batch normalization\n",
    "        x = bn_layer(x, training=training)\n",
    "        \n",
    "        # Reshape condition for broadcasting\n",
    "        condition = tf.reshape(condition, [-1, 1, 1, condition.shape[-1]])\n",
    "        \n",
    "        # Apply predefined gamma and beta layers\n",
    "        gamma = gamma_layer(condition)\n",
    "        beta = beta_layer(condition)\n",
    "        \n",
    "        # Apply scale and shift\n",
    "        return x * (1 + gamma) + beta\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_noise(batch_size, noise_dim=NOISE_DIM):\n",
    "        \"\"\"Generate Gaussian noise for the generator input.\"\"\"\n",
    "        return np.random.normal(0, 1, (batch_size, noise_dim))\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(Generator, self).get_config()\n",
    "        config.update({\n",
    "            'noise_dim': self.noise_dim,\n",
    "            'num_classes': self.num_classes\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Extract your custom parameters\n",
    "        noise_dim = config.pop('noise_dim', 100)  # Default if missing\n",
    "        num_classes = config.pop('num_classes', 10)  # Default if missing\n",
    "        \n",
    "        # Create instance with extracted parameters and remaining config\n",
    "        return cls(noise_dim=noise_dim, num_classes=num_classes, **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Class with Label Conditioning\n",
    "@register_keras_serializable()\n",
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10,**kwargs):\n",
    "        super(Discriminator, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Image processing\n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.leaky_relu1 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.3)\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.leaky_relu2 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.3)\n",
    "        \n",
    "        self.conv3 = tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.leaky_relu3 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(0.3)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "        # Label processing\n",
    "        self.label_embedding = tf.keras.layers.Embedding(num_classes, 50)\n",
    "        self.label_dense = tf.keras.layers.Dense(7*7, use_bias=False)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = tf.keras.layers.Dense(1)  # No activation - using from_logits=True\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        images, labels = inputs\n",
    "        \n",
    "        # Process images\n",
    "        x = self.conv1(images)\n",
    "        x = self.leaky_relu1(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.leaky_relu2(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.leaky_relu3(x)\n",
    "        x = self.dropout3(x, training=training)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Process labels\n",
    "        label_embedding = self.label_embedding(labels)\n",
    "        label_embedding = tf.keras.layers.Flatten()(label_embedding)\n",
    "        \n",
    "        # Combine image features and label info\n",
    "        combined = tf.concat([x, label_embedding], axis=1)\n",
    "        \n",
    "        # Output\n",
    "        return self.output_layer(combined)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(Discriminator, self).get_config()\n",
    "        config.update({\n",
    "            'num_classes': self.num_classes\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Extract your custom parameters\n",
    "        num_classes = config.pop('num_classes', 10)  # Default if missing\n",
    "        \n",
    "        # Create instance with extracted parameters and remaining config\n",
    "        return cls(num_classes=num_classes, **config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The GAN Class With the Auxiliary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Classifier to help with conditioning\n",
    "@register_keras_serializable()\n",
    "class AuxiliaryClassifier(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10,**kwargs):\n",
    "        super(AuxiliaryClassifier, self).__init__(**kwargs)\n",
    "\n",
    "        # Resize the input from (28, 28, 1) to (32, 32, 1)\n",
    "        self.resize = tf.keras.layers.Resizing(32, 32)\n",
    "\n",
    "        # Preprocessing layer to convert 1-channel input to 3 channels\n",
    "        self.preprocess = tf.keras.layers.Lambda(lambda x: tf.tile(x, [1, 1, 1, 3]))\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Load MobileNetV2 with input shape (32, 32, 3)\n",
    "        hidden = tf.keras.applications.MobileNetV2(\n",
    "            input_shape=(32, 32, 3),  # Adjusted to 32x32 with 3 channels\n",
    "            include_top=False,        # Exclude the top classification layer\n",
    "            weights='imagenet',       # Use pre-trained ImageNet weights\n",
    "        )\n",
    "\n",
    "        # Build the model with resizing, preprocessing, and MobileNetV2\n",
    "        self.model = tf.keras.Sequential([\n",
    "            self.resize,                       # Resize to 32x32\n",
    "            self.preprocess,                   # Convert (32, 32, 1) to (32, 32, 3)\n",
    "            hidden,                            # MobileNetV2 base\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),  # Reduce spatial dimensions\n",
    "            tf.keras.layers.Dense(512, activation='relu'),  # Dense layer\n",
    "            tf.keras.layers.Dropout(0.5),             # Regularization\n",
    "            tf.keras.layers.Dense(self.num_classes)  # Output layer\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        return self.model(inputs, training=training)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(AuxiliaryClassifier, self).get_config()\n",
    "        config.update({\n",
    "            'num_classes': self.num_classes\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Extract your custom parameters\n",
    "        num_classes = config.pop('num_classes', 10)  # Default if missing\n",
    "        \n",
    "        # Create instance with extracted parameters and remaining config\n",
    "        return cls(num_classes=num_classes, **config)\n",
    "\n",
    "   \n",
    "# Modified DCGAN Class with Auxiliary Classification Loss\n",
    "@register_keras_serializable()\n",
    "class DCGAN(tf.keras.Model):\n",
    "    def __init__(self, noise_dim=NOISE_DIM, num_classes=10):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.noise_dim = noise_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.generator = Generator(noise_dim, num_classes)\n",
    "        self.discriminator = Discriminator(num_classes)\n",
    "\n",
    "        # Add auxiliary classifier\n",
    "        self.classifier = AuxiliaryClassifier(num_classes)\n",
    "\n",
    "        # Optimizers\n",
    "        self.generator_optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "        self.discriminator_optimizer = tf.keras.optimizers.Adam(0.0001, 0.5)\n",
    "        self.classifier_optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "    def compile(self):\n",
    "        super(DCGAN, self).compile()\n",
    "\n",
    "    def pretrain_classifier(self, images, labels, epochs=20):\n",
    "        \"\"\"Pre-train the classifier on real data\"\"\"\n",
    "        print(\"Pre-training classifier...\")\n",
    "\n",
    "        # Create dataset from images and labels\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "        train_dataset = train_dataset.shuffle(len(images)).batch(128)\n",
    "\n",
    "        # Loss function\n",
    "        self.classifier.compile(\n",
    "            optimizer=self.classifier_optimizer,\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        # Train the classifier\n",
    "        self.classifier.fit(train_dataset, epochs=epochs)\n",
    "        print(\"Classifier pre-training complete.\")\n",
    "\n",
    "        # print(\"Classifier Evaluation\")\n",
    "        # pred = self.classifier(x_test)\n",
    "        # pred = np.argmax(pred,axis=1)\n",
    "        # print(accuracy_score(y_test,pred))\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data, epoch, total_epochs):\n",
    "        \"\"\"Enhanced train step with auxiliary classification loss\"\"\"\n",
    "        real_images, real_labels = data\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # Generate noise for fake images\n",
    "        noise = tf.random.normal([batch_size, self.noise_dim])\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            # Generate fake images\n",
    "            generated_images = self.generator([noise, real_labels], training=True)\n",
    "\n",
    "            # Get discriminator predictions\n",
    "            real_output = self.discriminator([real_images, real_labels], training=True)\n",
    "            fake_output = self.discriminator([generated_images, real_labels], training=True)\n",
    "\n",
    "            # Get classifier predictions for generated images\n",
    "            gen_class_logits = self.classifier(generated_images, training=False)\n",
    "\n",
    "            # Calculate standard GAN losses\n",
    "            gen_loss = self.generator_loss(fake_output)\n",
    "            disc_loss = self.discriminator_loss(real_output, fake_output)\n",
    "\n",
    "            # Calculate classification loss for generated images\n",
    "            classification_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                from_logits=True)(real_labels, gen_class_logits)\n",
    "\n",
    "            # Add classification loss to generator loss (weighted)\n",
    "            lambda_cls = 0.1 + (tf.cast(epoch, tf.float32) / total_epochs) * 0.3\n",
    "            gen_total_loss = gen_loss + lambda_cls * classification_loss\n",
    "\n",
    "        # Calculate gradients\n",
    "        gradients_of_generator = gen_tape.gradient(\n",
    "            gen_total_loss, self.generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(\n",
    "            disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "        # Apply gradients\n",
    "        self.generator_optimizer.apply_gradients(\n",
    "            zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "        self.discriminator_optimizer.apply_gradients(\n",
    "            zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "\n",
    "        return {\n",
    "            'd_loss': disc_loss,\n",
    "            'g_loss': gen_loss,\n",
    "            'cls_loss': classification_loss\n",
    "        }\n",
    "\n",
    "    def discriminator_loss(self, real_output, fake_output):\n",
    "        # Use from_logits=True for numerical stability\n",
    "        real_labels = tf.ones_like(real_output) * 0.9  # Label smoothing\n",
    "        real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(\n",
    "            real_labels, real_output)\n",
    "        fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(\n",
    "            tf.zeros_like(fake_output), fake_output)\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return total_loss\n",
    "\n",
    "    def generator_loss(self, fake_output):\n",
    "        return tf.keras.losses.BinaryCrossentropy(from_logits=True)(\n",
    "            tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "    def train(self, images, labels=None, epochs=10, batch_size=128,train_classifier=True):\n",
    "        \"\"\"\n",
    "        Train the model with separate images and labels\n",
    "\n",
    "        Parameters:\n",
    "        - images: The training images\n",
    "        - labels: The corresponding class labels (required)\n",
    "        - epochs: Number of training epochs\n",
    "        - batch_size: Batch size for training\n",
    "        \"\"\"\n",
    "        if labels is None:\n",
    "            raise ValueError(\"Labels must be provided for conditional GAN training\")\n",
    "\n",
    "        # First pre-train the classifier\n",
    "        if train_classifier:\n",
    "            self.pretrain_classifier(images, labels)\n",
    "\n",
    "        # Create dataset from images and labels\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "        train_dataset = train_dataset.shuffle(len(images)).batch(batch_size)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            d_loss_total, g_loss_total, cls_loss_total = 0, 0, 0\n",
    "            num_batches = 0\n",
    "\n",
    "            # Iterate through dataset\n",
    "            for real_images, real_labels in train_dataset:\n",
    "                # Rescale images to [-1, 1] if needed\n",
    "                if tf.reduce_max(real_images) > 1.0 or tf.reduce_min(real_images) < -1.0:\n",
    "                    real_images = tf.clip_by_value(real_images, 0, 255) / 127.5 - 1\n",
    "                elif tf.reduce_max(real_images) <= 1.0 and tf.reduce_min(real_images) >= 0:\n",
    "                    real_images = real_images * 2 - 1\n",
    "\n",
    "                # Train on this batch\n",
    "                losses = self.train_step((real_images, real_labels), epoch, epochs)\n",
    "                d_loss_total += losses['d_loss']\n",
    "                g_loss_total += losses['g_loss']\n",
    "                cls_loss_total += losses['cls_loss']\n",
    "                num_batches += 1\n",
    "\n",
    "            # Calculate average losses\n",
    "            d_loss_avg = d_loss_total / num_batches\n",
    "            g_loss_avg = g_loss_total / num_batches\n",
    "            cls_loss_avg = cls_loss_total / num_batches\n",
    "\n",
    "            # Print progress\n",
    "            if epoch % 2 == 0 or epoch == epochs - 1:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, D Loss: {d_loss_avg:.4f}, G Loss: {g_loss_avg:.4f}, Class Loss: {cls_loss_avg:.4f}\")\n",
    "                self.save_generated_images(epoch)\n",
    "                self.evaluate_class_accuracy(epoch)\n",
    "\n",
    "    def evaluate_class_accuracy(self, epoch, num_samples=500):\n",
    "        \"\"\"Evaluate how well the generated images match their class labels\"\"\"\n",
    "        # Generate images for each class\n",
    "        synthetic_images, synthetic_labels = self.generate_synthetic_data(num_samples)\n",
    "\n",
    "        # Convert images to tensor\n",
    "        synthetic_images = tf.convert_to_tensor(synthetic_images, dtype=tf.float32)\n",
    "        synthetic_labels = tf.convert_to_tensor(synthetic_labels, dtype=tf.int32)\n",
    "\n",
    "        # Get classifier predictions\n",
    "        predictions = self.classifier(synthetic_images, training=False)\n",
    "        predicted_classes = tf.argmax(predictions, axis=1).numpy()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = np.mean(predicted_classes == synthetic_labels.numpy())\n",
    "        print(f\"Epoch {epoch + 1} - Generated Image Class Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Create confusion matrix\n",
    "        confusion = tf.math.confusion_matrix(\n",
    "            labels=synthetic_labels,\n",
    "            predictions=predicted_classes,\n",
    "            num_classes=self.num_classes\n",
    "        ).numpy()\n",
    "\n",
    "        # Print per-class accuracy\n",
    "        class_accuracies = np.diag(confusion) / np.sum(confusion, axis=1)\n",
    "        for i, acc in enumerate(class_accuracies):\n",
    "            print(f\"  Class {i} accuracy: {acc:.4f}\")\n",
    "\n",
    "    \n",
    "\n",
    "    def generate_synthetic_data(self, num_samples, num_classes=10):\n",
    "        \"\"\"\n",
    "        Generate synthetic data with classifier verification.\n",
    "\n",
    "        Args:\n",
    "            num_samples (int): Total number of synthetic examples to generate.\n",
    "            num_classes (int): Number of classes (digits 0-9).\n",
    "            batch_size (int): Number of images to generate per batch.\n",
    "\n",
    "        Returns:\n",
    "            np.array: Synthetic images and their verified labels.\n",
    "        \"\"\"\n",
    "        if num_classes is None:\n",
    "            num_classes = self.num_classes\n",
    "\n",
    "        synthetic_images, synthetic_labels = [], []\n",
    "        samples_per_class = num_samples // num_classes\n",
    "\n",
    "        for digit in range(num_classes):\n",
    "            # Create noise and labels\n",
    "            noise = tf.random.normal([samples_per_class, self.noise_dim])\n",
    "            labels = tf.ones(samples_per_class, dtype=tf.int32) * digit\n",
    "\n",
    "            # Generate class-specific images\n",
    "            generated_imgs = self.generator([noise, labels], training=False)\n",
    "            generated_imgs = (generated_imgs + 1) / 2.0  # Rescale to [0, 1]\n",
    "\n",
    "            synthetic_images.extend(generated_imgs.numpy())\n",
    "            synthetic_labels.extend([digit] * samples_per_class)\n",
    "\n",
    "        return np.array(synthetic_images), np.array(synthetic_labels)\n",
    "\n",
    "    def save_generated_images(self, epoch, output_dir='generated_images'):\n",
    "        \"\"\"Save generated images for each class for visualization.\"\"\"\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Generate one image per class in a 3x4 grid (for 10 classes)\n",
    "        fig, axs = plt.subplots(3, 4, figsize=(12, 9))\n",
    "        axs = axs.flatten()\n",
    "\n",
    "        # Generate sample for each class\n",
    "        for digit in range(min(10, self.num_classes)):\n",
    "            noise = tf.random.normal([1, self.noise_dim])\n",
    "            label = tf.constant([digit], dtype=tf.int32)\n",
    "            gen_img = self.generator([noise, label], training=False)\n",
    "            gen_img = (gen_img + 1) / 2.0  # Rescale to [0, 1]\n",
    "\n",
    "            axs[digit].imshow(gen_img[0, :, :, 0], cmap='gray')\n",
    "            axs[digit].set_title(f\"Class {digit}\")\n",
    "            axs[digit].axis('off')\n",
    "\n",
    "        # Remove any unused subplots\n",
    "        for i in range(self.num_classes, len(axs)):\n",
    "            fig.delaxes(axs[i])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'epoch_{epoch}_classes.png'))\n",
    "        plt.close()\n",
    "\n",
    "    def _ensure_optimizers_initialized(self):\n",
    "        if self.generator.trainable_variables:\n",
    "            zero_grads_g = [tf.zeros_like(v) for v in self.generator.trainable_variables]\n",
    "            self.generator_optimizer.apply_gradients(zip(zero_grads_g, self.generator.trainable_variables))\n",
    "        if self.discriminator.trainable_variables:\n",
    "            zero_grads_d = [tf.zeros_like(v) for v in self.discriminator.trainable_variables]\n",
    "            self.discriminator_optimizer.apply_gradients(zip(zero_grads_d, self.discriminator.trainable_variables))\n",
    "        if self.classifier.trainable_variables:\n",
    "            zero_grads_c = [tf.zeros_like(v) for v in self.classifier.trainable_variables]\n",
    "            self.classifier_optimizer.apply_gradients(zip(zero_grads_c, self.classifier.trainable_variables))\n",
    "\n",
    "    def save(self, checkpoint_dir):\n",
    "        self.generator.save(os.path.join(checkpoint_dir, 'generator.keras'))\n",
    "        self.discriminator.save(os.path.join(checkpoint_dir, 'discriminator.keras'))\n",
    "        self.classifier.save(os.path.join(checkpoint_dir, 'classifier.keras'))\n",
    "        self._ensure_optimizers_initialized()\n",
    "        checkpoint = tf.train.Checkpoint(\n",
    "            generator_optimizer=self.generator_optimizer,\n",
    "            discriminator_optimizer=self.discriminator_optimizer,\n",
    "            classifier_optimizer=self.classifier_optimizer\n",
    "        )\n",
    "        checkpoint.save(os.path.join(checkpoint_dir, 'optimizer_checkpoint'))\n",
    "        # Save optimizer states\n",
    "        checkpoint_manager = tf.train.CheckpointManager(\n",
    "            checkpoint, os.path.join(checkpoint_dir, 'optimizer_ckpt'), max_to_keep=1\n",
    "        )\n",
    "        checkpoint_manager.save()\n",
    "        \n",
    "        # Save additional configurations\n",
    "        config = {\n",
    "            'noise_dim': self.noise_dim,\n",
    "            'num_classes': self.num_classes\n",
    "        }\n",
    "        np.save(os.path.join(checkpoint_dir, 'config.npy'), config)\n",
    "        \n",
    "        print(f\"Model saved successfully to {checkpoint_dir}\")\n",
    "    \n",
    " \n",
    "    @classmethod\n",
    "    def load(cls, checkpoint_dir='checkpoints', custom_objects=None):\n",
    "        \"\"\"Load a complete GAN model from a checkpoint directory\"\"\"\n",
    "        # Load configuration\n",
    "        config_path = os.path.join(checkpoint_dir, 'config.npy')\n",
    "        if not os.path.exists(config_path):\n",
    "            raise FileNotFoundError(f\"Configuration file not found at {config_path}\")\n",
    "        \n",
    "        config = np.load(config_path, allow_pickle=True).item()\n",
    "        \n",
    "        # Create a new instance with the saved configuration\n",
    "        gan = cls(noise_dim=config['noise_dim'], num_classes=config['num_classes'])\n",
    "        \n",
    "        # Initialize the models\n",
    "        gan._initialize_models()\n",
    "        \n",
    "        # Load models\n",
    "        gan.generator = tf.keras.models.load_model(\n",
    "            os.path.join(checkpoint_dir, 'generator.keras'),\n",
    "            custom_objects=custom_objects\n",
    "        )\n",
    "        \n",
    "        gan.discriminator = tf.keras.models.load_model(\n",
    "            os.path.join(checkpoint_dir, 'discriminator.keras'),\n",
    "            custom_objects=custom_objects\n",
    "        )\n",
    "        \n",
    "        gan.classifier = tf.keras.models.load_model(\n",
    "            os.path.join(checkpoint_dir, 'classifier.keras'),\n",
    "            custom_objects=custom_objects\n",
    "        )\n",
    "        \n",
    "        # Initialize optimizers\n",
    "        gan._ensure_optimizers_initialized()\n",
    "        \n",
    "        # Create optimizer checkpoint\n",
    "        checkpoint = tf.train.Checkpoint(\n",
    "            generator_optimizer=gan.generator_optimizer,\n",
    "            discriminator_optimizer=gan.discriminator_optimizer,\n",
    "            classifier_optimizer=gan.classifier_optimizer\n",
    "        )\n",
    "        \n",
    "        # Find latest checkpoint\n",
    "        latest_checkpoint = tf.train.latest_checkpoint(\n",
    "            os.path.join(checkpoint_dir, 'optimizer_ckpt')\n",
    "        )\n",
    "        \n",
    "        if latest_checkpoint:\n",
    "            # Restore optimizer states\n",
    "            checkpoint.restore(latest_checkpoint)\n",
    "            print(f\"Optimizer states restored from {latest_checkpoint}\")\n",
    "        else:\n",
    "            print(\"Warning: No optimizer checkpoint found. Starting with fresh optimizers.\")\n",
    "        \n",
    "        print(f\"Model loaded successfully from {checkpoint_dir}\")\n",
    "        return gan\n",
    "    \n",
    "    def _initialize_models(self):\n",
    "        \"\"\"Initialize models by running a dummy forward pass\"\"\"\n",
    "        # Create dummy data\n",
    "        batch_size = 2\n",
    "        dummy_images = tf.random.normal([batch_size, 28, 28, 1])\n",
    "        dummy_labels = tf.random.uniform([batch_size], 0, self.num_classes, dtype=tf.int32)\n",
    "        \n",
    "        # Forward pass through each model to build them\n",
    "        noise = tf.random.normal([batch_size, self.noise_dim])\n",
    "        _ = self.generator([noise, dummy_labels], training=False)\n",
    "        _ = self.discriminator([dummy_images, dummy_labels], training=False)\n",
    "        _ = self.classifier(dummy_images, training=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the the Full MNIST GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745414689.357809   54824 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4610 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_54824/512743676.py:16: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  hidden = tf.keras.applications.MobileNetV2(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 43\u001b[0m\n\u001b[1;32m      3\u001b[0m dcgan\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load and process the entire training data from the generator\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(\"Loading and processing the entire dataset...\")\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# all_images = []\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Train the DCGAN\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m dcgan\u001b[38;5;241m.\u001b[39mtrain(\u001b[43mx_train\u001b[49m,y_train, EPOCHS, BATCH_SIZE)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Generate synthetic data\u001b[39;00m\n\u001b[1;32m     46\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the DCGAN\n",
    "dcgan = DCGAN()\n",
    "dcgan.compile()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the DCGAN\n",
    "dcgan.train(x_train,y_train, EPOCHS, BATCH_SIZE)\n",
    "\n",
    "# Save the model\n",
    "dcgan.save('my_gan_checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the 300,700,1000 MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to load images from a directory\n",
    "def load_images_from_directory(directory, n_samples_per_class=None):\n",
    "    x_data, y_data = [], []\n",
    "    for class_label in range(10):\n",
    "        class_dir = os.path.join(directory, str(class_label))\n",
    "        images = [os.path.join(class_dir, f) for f in os.listdir(class_dir) if f.endswith(('.png', '.jpg'))]\n",
    "        if n_samples_per_class:\n",
    "            images = np.random.choice(images, n_samples_per_class, replace=False)\n",
    "        for img_path in images:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "            img = img.astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "            x_data.append(img)\n",
    "            y_data.append(class_label)\n",
    "    x_data = np.array(x_data).reshape(-1, 28, 28, 1)  # Reshape for CNN\n",
    "    y_data = np.array(y_data)\n",
    "    return x_data, y_data\n",
    "\n",
    "# Load training subsets\n",
    "x_train_300, y_train_300 = load_images_from_directory(train_dir, n_samples_per_class=300)  # 30 per class = 300 total\n",
    "x_train_700, y_train_700 = load_images_from_directory(train_dir, n_samples_per_class=700)  # 70 per class = 700 total\n",
    "x_train_1000, y_train_1000 = load_images_from_directory(train_dir, n_samples_per_class=1000)  # 100 per class = 1000 total\n",
    "\n",
    "# Load test set (200 samples total)\n",
    "x_test, y_test = load_images_from_directory(test_dir, n_samples_per_class=200)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the 300 GAN\n",
    "### We will train the model for 75 and save the model if we are not satisfied with the results we load the model and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745406169.347444  234251 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4610 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_234251/512743676.py:16: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  hidden = tf.keras.applications.MobileNetV2(\n",
      "I0000 00:00:1745406172.169639  234251 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:407: UserWarning: `build()` was called on layer 'discriminator', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer states restored from my_gan_checkpoint_300/optimizer_ckpt/ckpt-2\n",
      "Model loaded successfully from my_gan_checkpoint_300\n",
      "Pre-training classifier...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745406190.053254  234515 service.cc:152] XLA service 0x7caf14003d40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745406190.053271  234515 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2025-04-23 13:03:10.692720: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 7/24\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9958 - loss: 0.0130 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745406206.865011  234515 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 706ms/step - accuracy: 0.9923 - loss: 0.0266\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9879 - loss: 0.0353\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9886 - loss: 0.0511\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9939 - loss: 0.0180\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9968 - loss: 0.0126\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9976 - loss: 0.0150\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9943 - loss: 0.0161\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9927 - loss: 0.0196\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9962 - loss: 0.0150\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9964 - loss: 0.0151\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9970 - loss: 0.0107\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9975 - loss: 0.0107\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9977 - loss: 0.0122\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9924 - loss: 0.0170\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9987 - loss: 0.0065\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9969 - loss: 0.0106\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9957 - loss: 0.0122\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9988 - loss: 0.0037\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9974 - loss: 0.0073\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9972 - loss: 0.0066\n",
      "Classifier pre-training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745406234.129196  234251 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-04-23 13:04:01.715570: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75, D Loss: 1.2308, G Loss: 1.0919, Class Loss: 2.4332\n",
      "Epoch 1 - Generated Image Class Accuracy: 0.1100\n",
      "  Class 0 accuracy: 0.0200\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.2000\n",
      "  Class 3 accuracy: 0.0600\n",
      "  Class 4 accuracy: 0.1200\n",
      "  Class 5 accuracy: 0.1000\n",
      "  Class 6 accuracy: 0.1800\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1000\n",
      "  Class 9 accuracy: 0.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 13:04:11.163597: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/75, D Loss: 1.2005, G Loss: 1.0973, Class Loss: 2.5449\n",
      "Epoch 3 - Generated Image Class Accuracy: 0.0960\n",
      "  Class 0 accuracy: 0.0200\n",
      "  Class 1 accuracy: 0.0400\n",
      "  Class 2 accuracy: 0.0200\n",
      "  Class 3 accuracy: 0.0600\n",
      "  Class 4 accuracy: 0.1000\n",
      "  Class 5 accuracy: 0.1000\n",
      "  Class 6 accuracy: 0.0800\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1600\n",
      "  Class 9 accuracy: 0.3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 13:04:28.430117: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/75, D Loss: 1.2047, G Loss: 1.0991, Class Loss: 2.5815\n",
      "Epoch 5 - Generated Image Class Accuracy: 0.0800\n",
      "  Class 0 accuracy: 0.0200\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0400\n",
      "  Class 4 accuracy: 0.1000\n",
      "  Class 5 accuracy: 0.1400\n",
      "  Class 6 accuracy: 0.1400\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0800\n",
      "  Class 9 accuracy: 0.2800\n",
      "Epoch 7/75, D Loss: 1.2133, G Loss: 1.0915, Class Loss: 2.5484\n",
      "Epoch 7 - Generated Image Class Accuracy: 0.0740\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0200\n",
      "  Class 4 accuracy: 0.0600\n",
      "  Class 5 accuracy: 0.1600\n",
      "  Class 6 accuracy: 0.0800\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0800\n",
      "  Class 9 accuracy: 0.3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745406297.319605  234251 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-04-23 13:05:02.702697: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/75, D Loss: 1.2106, G Loss: 1.0928, Class Loss: 2.4985\n",
      "Epoch 9 - Generated Image Class Accuracy: 0.0860\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0000\n",
      "  Class 4 accuracy: 0.2000\n",
      "  Class 5 accuracy: 0.0400\n",
      "  Class 6 accuracy: 0.1200\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1600\n",
      "  Class 9 accuracy: 0.3200\n",
      "Epoch 11/75, D Loss: 1.1977, G Loss: 1.1035, Class Loss: 2.5426\n",
      "Epoch 11 - Generated Image Class Accuracy: 0.0860\n",
      "  Class 0 accuracy: 0.0400\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0600\n",
      "  Class 4 accuracy: 0.1000\n",
      "  Class 5 accuracy: 0.0800\n",
      "  Class 6 accuracy: 0.0400\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1400\n",
      "  Class 9 accuracy: 0.3800\n",
      "Epoch 13/75, D Loss: 1.2241, G Loss: 1.0669, Class Loss: 2.4928\n",
      "Epoch 13 - Generated Image Class Accuracy: 0.0620\n",
      "  Class 0 accuracy: 0.0200\n",
      "  Class 1 accuracy: 0.0400\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0400\n",
      "  Class 4 accuracy: 0.0200\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 0.0200\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1000\n",
      "  Class 9 accuracy: 0.3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745406357.326993  234251 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/75, D Loss: 1.1987, G Loss: 1.1117, Class Loss: 2.4878\n",
      "Epoch 15 - Generated Image Class Accuracy: 0.0820\n",
      "  Class 0 accuracy: 0.0400\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0200\n",
      "  Class 4 accuracy: 0.0400\n",
      "  Class 5 accuracy: 0.1200\n",
      "  Class 6 accuracy: 0.1200\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1400\n",
      "  Class 9 accuracy: 0.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 13:06:11.788459: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/75, D Loss: 1.1998, G Loss: 1.0849, Class Loss: 2.4965\n",
      "Epoch 17 - Generated Image Class Accuracy: 0.1160\n",
      "  Class 0 accuracy: 0.0600\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0800\n",
      "  Class 3 accuracy: 0.0200\n",
      "  Class 4 accuracy: 0.1200\n",
      "  Class 5 accuracy: 0.1600\n",
      "  Class 6 accuracy: 0.1200\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1000\n",
      "  Class 9 accuracy: 0.4800\n",
      "Epoch 19/75, D Loss: 1.2180, G Loss: 1.0764, Class Loss: 2.5291\n",
      "Epoch 19 - Generated Image Class Accuracy: 0.0880\n",
      "  Class 0 accuracy: 0.0200\n",
      "  Class 1 accuracy: 0.0400\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0000\n",
      "  Class 4 accuracy: 0.1000\n",
      "  Class 5 accuracy: 0.0600\n",
      "  Class 6 accuracy: 0.1400\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.2200\n",
      "  Class 9 accuracy: 0.3000\n",
      "Epoch 21/75, D Loss: 1.2059, G Loss: 1.0984, Class Loss: 2.5384\n",
      "Epoch 21 - Generated Image Class Accuracy: 0.1000\n",
      "  Class 0 accuracy: 0.0200\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0400\n",
      "  Class 4 accuracy: 0.1200\n",
      "  Class 5 accuracy: 0.2000\n",
      "  Class 6 accuracy: 0.1200\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1600\n",
      "  Class 9 accuracy: 0.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745406418.305075  234251 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/75, D Loss: 1.1929, G Loss: 1.1074, Class Loss: 2.4904\n",
      "Epoch 23 - Generated Image Class Accuracy: 0.0860\n",
      "  Class 0 accuracy: 0.0400\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.1400\n",
      "  Class 4 accuracy: 0.1000\n",
      "  Class 5 accuracy: 0.1200\n",
      "  Class 6 accuracy: 0.0600\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0600\n",
      "  Class 9 accuracy: 0.3400\n",
      "Epoch 25/75, D Loss: 1.2079, G Loss: 1.0841, Class Loss: 2.5104\n",
      "Epoch 25 - Generated Image Class Accuracy: 0.0780\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0600\n",
      "  Class 4 accuracy: 0.0600\n",
      "  Class 5 accuracy: 0.1000\n",
      "  Class 6 accuracy: 0.0800\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0800\n",
      "  Class 9 accuracy: 0.4000\n",
      "Epoch 27/75, D Loss: 1.1977, G Loss: 1.0932, Class Loss: 2.4646\n",
      "Epoch 27 - Generated Image Class Accuracy: 0.0800\n",
      "  Class 0 accuracy: 0.0400\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0800\n",
      "  Class 3 accuracy: 0.1200\n",
      "  Class 4 accuracy: 0.0400\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 0.0600\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0800\n",
      "  Class 9 accuracy: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745406479.253639  234251 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/75, D Loss: 1.1844, G Loss: 1.1249, Class Loss: 2.4684\n",
      "Epoch 29 - Generated Image Class Accuracy: 0.0900\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.1000\n",
      "  Class 4 accuracy: 0.0800\n",
      "  Class 5 accuracy: 0.1800\n",
      "  Class 6 accuracy: 0.0600\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1000\n",
      "  Class 9 accuracy: 0.3600\n",
      "Epoch 31/75, D Loss: 1.2015, G Loss: 1.1057, Class Loss: 2.4994\n",
      "Epoch 31 - Generated Image Class Accuracy: 0.0820\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.1400\n",
      "  Class 4 accuracy: 0.1200\n",
      "  Class 5 accuracy: 0.1400\n",
      "  Class 6 accuracy: 0.1400\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0200\n",
      "  Class 9 accuracy: 0.2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 13:08:31.134954: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/75, D Loss: 1.2008, G Loss: 1.1029, Class Loss: 2.4775\n",
      "Epoch 33 - Generated Image Class Accuracy: 0.0680\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0600\n",
      "  Class 4 accuracy: 0.0400\n",
      "  Class 5 accuracy: 0.1400\n",
      "  Class 6 accuracy: 0.1000\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0400\n",
      "  Class 9 accuracy: 0.3000\n",
      "Epoch 35/75, D Loss: 1.1875, G Loss: 1.1208, Class Loss: 2.4921\n",
      "Epoch 35 - Generated Image Class Accuracy: 0.0920\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0800\n",
      "  Class 4 accuracy: 0.0600\n",
      "  Class 5 accuracy: 0.1600\n",
      "  Class 6 accuracy: 0.1800\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0600\n",
      "  Class 9 accuracy: 0.3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745406541.405398  234251 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/75, D Loss: 1.1709, G Loss: 1.1383, Class Loss: 2.4680\n",
      "Epoch 37 - Generated Image Class Accuracy: 0.0920\n",
      "  Class 0 accuracy: 0.0200\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0600\n",
      "  Class 4 accuracy: 0.2000\n",
      "  Class 5 accuracy: 0.1400\n",
      "  Class 6 accuracy: 0.1000\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0600\n",
      "  Class 9 accuracy: 0.3400\n",
      "Epoch 39/75, D Loss: 1.1840, G Loss: 1.1407, Class Loss: 2.4545\n",
      "Epoch 39 - Generated Image Class Accuracy: 0.0700\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.1000\n",
      "  Class 4 accuracy: 0.0600\n",
      "  Class 5 accuracy: 0.1000\n",
      "  Class 6 accuracy: 0.1000\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1000\n",
      "  Class 9 accuracy: 0.2400\n",
      "Epoch 41/75, D Loss: 1.1781, G Loss: 1.1260, Class Loss: 2.4281\n",
      "Epoch 41 - Generated Image Class Accuracy: 0.0820\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0800\n",
      "  Class 4 accuracy: 0.0800\n",
      "  Class 5 accuracy: 0.1200\n",
      "  Class 6 accuracy: 0.0800\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0600\n",
      "  Class 9 accuracy: 0.3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745406604.404566  234251 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/75, D Loss: 1.1755, G Loss: 1.1502, Class Loss: 2.4646\n",
      "Epoch 43 - Generated Image Class Accuracy: 0.0740\n",
      "  Class 0 accuracy: 0.0200\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0200\n",
      "  Class 4 accuracy: 0.1200\n",
      "  Class 5 accuracy: 0.1200\n",
      "  Class 6 accuracy: 0.1000\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1200\n",
      "  Class 9 accuracy: 0.2400\n",
      "Epoch 45/75, D Loss: 1.1468, G Loss: 1.1723, Class Loss: 2.4430\n",
      "Epoch 45 - Generated Image Class Accuracy: 0.0760\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0400\n",
      "  Class 4 accuracy: 0.0800\n",
      "  Class 5 accuracy: 0.1400\n",
      "  Class 6 accuracy: 0.1200\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0400\n",
      "  Class 9 accuracy: 0.3200\n",
      "Epoch 47/75, D Loss: 1.1871, G Loss: 1.1265, Class Loss: 2.3738\n",
      "Epoch 47 - Generated Image Class Accuracy: 0.0720\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0000\n",
      "  Class 4 accuracy: 0.1800\n",
      "  Class 5 accuracy: 0.0600\n",
      "  Class 6 accuracy: 0.0400\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.2200\n",
      "  Class 9 accuracy: 0.2200\n",
      "Epoch 49/75, D Loss: 1.1612, G Loss: 1.1594, Class Loss: 2.4030\n",
      "Epoch 49 - Generated Image Class Accuracy: 0.0800\n",
      "  Class 0 accuracy: 0.0200\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0600\n",
      "  Class 3 accuracy: 0.0400\n",
      "  Class 4 accuracy: 0.1400\n",
      "  Class 5 accuracy: 0.1000\n",
      "  Class 6 accuracy: 0.0800\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0800\n",
      "  Class 9 accuracy: 0.2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745406667.012576  234251 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/75, D Loss: 1.1585, G Loss: 1.2282, Class Loss: 2.4188\n",
      "Epoch 51 - Generated Image Class Accuracy: 0.0980\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0400\n",
      "  Class 2 accuracy: 0.0600\n",
      "  Class 3 accuracy: 0.0400\n",
      "  Class 4 accuracy: 0.0800\n",
      "  Class 5 accuracy: 0.2400\n",
      "  Class 6 accuracy: 0.1200\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0800\n",
      "  Class 9 accuracy: 0.3200\n",
      "Epoch 53/75, D Loss: 1.1500, G Loss: 1.1545, Class Loss: 2.4172\n",
      "Epoch 53 - Generated Image Class Accuracy: 0.1260\n",
      "  Class 0 accuracy: 0.0400\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.2200\n",
      "  Class 3 accuracy: 0.0800\n",
      "  Class 4 accuracy: 0.1000\n",
      "  Class 5 accuracy: 0.2200\n",
      "  Class 6 accuracy: 0.1600\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0600\n",
      "  Class 9 accuracy: 0.3800\n",
      "Epoch 55/75, D Loss: 1.1727, G Loss: 1.1588, Class Loss: 2.4258\n",
      "Epoch 55 - Generated Image Class Accuracy: 0.0700\n",
      "  Class 0 accuracy: 0.0400\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0600\n",
      "  Class 3 accuracy: 0.0400\n",
      "  Class 4 accuracy: 0.0800\n",
      "  Class 5 accuracy: 0.0400\n",
      "  Class 6 accuracy: 0.0600\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0600\n",
      "  Class 9 accuracy: 0.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745406727.304647  234251 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/75, D Loss: 1.1446, G Loss: 1.1757, Class Loss: 2.3973\n",
      "Epoch 57 - Generated Image Class Accuracy: 0.0780\n",
      "  Class 0 accuracy: 0.0600\n",
      "  Class 1 accuracy: 0.0400\n",
      "  Class 2 accuracy: 0.0200\n",
      "  Class 3 accuracy: 0.0600\n",
      "  Class 4 accuracy: 0.0400\n",
      "  Class 5 accuracy: 0.0600\n",
      "  Class 6 accuracy: 0.1000\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0800\n",
      "  Class 9 accuracy: 0.3200\n",
      "Epoch 59/75, D Loss: 1.1791, G Loss: 1.1595, Class Loss: 2.4256\n",
      "Epoch 59 - Generated Image Class Accuracy: 0.1040\n",
      "  Class 0 accuracy: 0.0800\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.1000\n",
      "  Class 4 accuracy: 0.1000\n",
      "  Class 5 accuracy: 0.2000\n",
      "  Class 6 accuracy: 0.1200\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0400\n",
      "  Class 9 accuracy: 0.4000\n",
      "Epoch 61/75, D Loss: 1.1628, G Loss: 1.1829, Class Loss: 2.3926\n",
      "Epoch 61 - Generated Image Class Accuracy: 0.0900\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0400\n",
      "  Class 4 accuracy: 0.0800\n",
      "  Class 5 accuracy: 0.2400\n",
      "  Class 6 accuracy: 0.0800\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0800\n",
      "  Class 9 accuracy: 0.3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745406789.673589  234251 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/75, D Loss: 1.1706, G Loss: 1.1601, Class Loss: 2.4127\n",
      "Epoch 63 - Generated Image Class Accuracy: 0.0880\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0000\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0600\n",
      "  Class 4 accuracy: 0.1000\n",
      "  Class 5 accuracy: 0.0600\n",
      "  Class 6 accuracy: 0.1000\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1600\n",
      "  Class 9 accuracy: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 13:13:19.012869: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/75, D Loss: 1.1462, G Loss: 1.1838, Class Loss: 2.3909\n",
      "Epoch 65 - Generated Image Class Accuracy: 0.0680\n",
      "  Class 0 accuracy: 0.0200\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0200\n",
      "  Class 3 accuracy: 0.0200\n",
      "  Class 4 accuracy: 0.0400\n",
      "  Class 5 accuracy: 0.0600\n",
      "  Class 6 accuracy: 0.1000\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1200\n",
      "  Class 9 accuracy: 0.2800\n",
      "Epoch 67/75, D Loss: 1.1313, G Loss: 1.2826, Class Loss: 2.3918\n",
      "Epoch 67 - Generated Image Class Accuracy: 0.0940\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0600\n",
      "  Class 3 accuracy: 0.1200\n",
      "  Class 4 accuracy: 0.1000\n",
      "  Class 5 accuracy: 0.0800\n",
      "  Class 6 accuracy: 0.1200\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0600\n",
      "  Class 9 accuracy: 0.3800\n",
      "Epoch 69/75, D Loss: 1.1367, G Loss: 1.2012, Class Loss: 2.3889\n",
      "Epoch 69 - Generated Image Class Accuracy: 0.0940\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.1400\n",
      "  Class 4 accuracy: 0.0400\n",
      "  Class 5 accuracy: 0.2000\n",
      "  Class 6 accuracy: 0.1400\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0400\n",
      "  Class 9 accuracy: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745406851.262322  234251 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/75, D Loss: 1.1225, G Loss: 1.2332, Class Loss: 2.3689\n",
      "Epoch 71 - Generated Image Class Accuracy: 0.0700\n",
      "  Class 0 accuracy: 0.0200\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.1000\n",
      "  Class 4 accuracy: 0.0600\n",
      "  Class 5 accuracy: 0.1200\n",
      "  Class 6 accuracy: 0.0200\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.1000\n",
      "  Class 9 accuracy: 0.2600\n",
      "Epoch 73/75, D Loss: 1.1531, G Loss: 1.1795, Class Loss: 2.4174\n",
      "Epoch 73 - Generated Image Class Accuracy: 0.0660\n",
      "  Class 0 accuracy: 0.0000\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0200\n",
      "  Class 4 accuracy: 0.0800\n",
      "  Class 5 accuracy: 0.1400\n",
      "  Class 6 accuracy: 0.1800\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0200\n",
      "  Class 9 accuracy: 0.2000\n",
      "Epoch 75/75, D Loss: 1.1523, G Loss: 1.1958, Class Loss: 2.4286\n",
      "Epoch 75 - Generated Image Class Accuracy: 0.0740\n",
      "  Class 0 accuracy: 0.0200\n",
      "  Class 1 accuracy: 0.0200\n",
      "  Class 2 accuracy: 0.0000\n",
      "  Class 3 accuracy: 0.0200\n",
      "  Class 4 accuracy: 0.1400\n",
      "  Class 5 accuracy: 0.1400\n",
      "  Class 6 accuracy: 0.0600\n",
      "  Class 7 accuracy: 0.0000\n",
      "  Class 8 accuracy: 0.0600\n",
      "  Class 9 accuracy: 0.2800\n",
      "mkdir: cannot create directory ‘my_gan_checkpoint_300’: File exists\n",
      "Model saved successfully to my_gan_checkpoint_300\n"
     ]
    }
   ],
   "source": [
    "dcgan_300 = DCGAN.load(checkpoint_dir='my_gan_checkpoint_300')\n",
    "# dcgan_300.compile()\n",
    "# Train the DCGAN on the 300-sample subset\n",
    "dcgan_300.train(x_train_300, y_train_300, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "# Save the model\n",
    "!mkdir  my_gan_checkpoint_300\n",
    "dcgan_300.save(checkpoint_dir='my_gan_checkpoint_300')\n",
    "!mv generated_images generated_images_300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the 300 GAN\n",
    "### We will train the model for 75 and save the model if we are not satisfied with the results we load the model and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745400497.386411  188263 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4610 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_188263/512743676.py:16: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  hidden = tf.keras.applications.MobileNetV2(\n",
      "I0000 00:00:1745400499.885800  188263 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:407: UserWarning: `build()` was called on layer 'discriminator', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer states restored from my_gan_checkpoint_700/optimizer_ckpt/ckpt-2\n",
      "Model loaded successfully from my_gan_checkpoint_700\n",
      "Pre-training classifier...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745400517.402144  188699 service.cc:152] XLA service 0x775e34002ce0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745400517.402158  188699 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2025-04-23 11:28:37.975599: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 7/55\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9980 - loss: 0.0037     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745400534.019486  188699 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 307ms/step - accuracy: 0.9969 - loss: 0.0104\n",
      "Epoch 2/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9987 - loss: 0.0050\n",
      "Epoch 3/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9987 - loss: 0.0060\n",
      "Epoch 4/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9984 - loss: 0.0097\n",
      "Epoch 5/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9980 - loss: 0.0048\n",
      "Epoch 6/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9987 - loss: 0.0045\n",
      "Epoch 7/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9980 - loss: 0.0062\n",
      "Epoch 8/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9985 - loss: 0.0069\n",
      "Epoch 9/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9989 - loss: 0.0048\n",
      "Epoch 10/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9991 - loss: 0.0028\n",
      "Epoch 11/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9992 - loss: 0.0027\n",
      "Epoch 12/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9997 - loss: 9.1981e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9998 - loss: 0.0015\n",
      "Epoch 14/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9970 - loss: 0.0135\n",
      "Epoch 15/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9983 - loss: 0.0084\n",
      "Epoch 16/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9991 - loss: 0.0041\n",
      "Epoch 17/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9993 - loss: 0.0035\n",
      "Epoch 18/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9980 - loss: 0.0084\n",
      "Epoch 19/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9981 - loss: 0.0069\n",
      "Epoch 20/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9993 - loss: 0.0019\n",
      "Classifier pre-training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745400572.818043  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-04-23 11:29:43.394139: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75, D Loss: 0.7826, G Loss: 2.3729, Class Loss: 2.3375\n",
      "Epoch 1 - Generated Image Class Accuracy: 0.7960\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9600\n",
      "  Class 3 accuracy: 0.9400\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0400\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9400\n",
      "  Class 8 accuracy: 0.1200\n",
      "  Class 9 accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:29:55.668554: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/75, D Loss: 0.8121, G Loss: 2.2530, Class Loss: 2.6488\n",
      "Epoch 3 - Generated Image Class Accuracy: 0.7860\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9600\n",
      "  Class 3 accuracy: 0.9400\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:30:18.425425: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/75, D Loss: 0.8384, G Loss: 2.1627, Class Loss: 2.5356\n",
      "Epoch 5 - Generated Image Class Accuracy: 0.7680\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8000\n",
      "  Class 4 accuracy: 0.9400\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745400633.133850  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/75, D Loss: 0.8528, G Loss: 2.1321, Class Loss: 2.2920\n",
      "Epoch 7 - Generated Image Class Accuracy: 0.7660\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:31:04.651632: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/75, D Loss: 0.8559, G Loss: 2.1448, Class Loss: 2.2963\n",
      "Epoch 9 - Generated Image Class Accuracy: 0.7700\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.8400\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745400698.864010  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/75, D Loss: 0.8637, G Loss: 2.1136, Class Loss: 2.3552\n",
      "Epoch 11 - Generated Image Class Accuracy: 0.7680\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.7800\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9600\n",
      "Epoch 13/75, D Loss: 0.8582, G Loss: 2.1320, Class Loss: 2.3760\n",
      "Epoch 13 - Generated Image Class Accuracy: 0.7740\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.7800\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9600\n",
      "Epoch 15/75, D Loss: 0.8454, G Loss: 2.1725, Class Loss: 2.1180\n",
      "Epoch 15 - Generated Image Class Accuracy: 0.7660\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.7600\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:32:37.785796: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "E0000 00:00:1745400760.542007  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/75, D Loss: 0.8483, G Loss: 2.1226, Class Loss: 2.2292\n",
      "Epoch 17 - Generated Image Class Accuracy: 0.7740\n",
      "  Class 0 accuracy: 0.9800\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8400\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0400\n",
      "  Class 9 accuracy: 0.8800\n",
      "Epoch 19/75, D Loss: 0.8513, G Loss: 2.1436, Class Loss: 2.1897\n",
      "Epoch 19 - Generated Image Class Accuracy: 0.8740\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8200\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 1.0000\n",
      "  Class 9 accuracy: 0.9200\n",
      "Epoch 21/75, D Loss: 0.8406, G Loss: 2.1646, Class Loss: 2.1474\n",
      "Epoch 21 - Generated Image Class Accuracy: 0.8720\n",
      "  Class 0 accuracy: 0.9800\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9800\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.8200\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745400827.314514  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/75, D Loss: 0.8404, G Loss: 2.1906, Class Loss: 2.0333\n",
      "Epoch 23 - Generated Image Class Accuracy: 0.7760\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8800\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9000\n",
      "Epoch 25/75, D Loss: 0.8378, G Loss: 2.2152, Class Loss: 2.0130\n",
      "Epoch 25 - Generated Image Class Accuracy: 0.7660\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.7800\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9000\n",
      "Epoch 27/75, D Loss: 0.8334, G Loss: 2.1867, Class Loss: 2.0072\n",
      "Epoch 27 - Generated Image Class Accuracy: 0.7760\n",
      "  Class 0 accuracy: 0.9800\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8600\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745400889.633420  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/75, D Loss: 0.8234, G Loss: 2.2228, Class Loss: 1.9556\n",
      "Epoch 29 - Generated Image Class Accuracy: 0.7620\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.8400\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.8400\n",
      "Epoch 31/75, D Loss: 0.8376, G Loss: 2.2155, Class Loss: 1.8654\n",
      "Epoch 31 - Generated Image Class Accuracy: 0.8400\n",
      "  Class 0 accuracy: 0.9800\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8600\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0200\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.5600\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:35:44.369331: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "E0000 00:00:1745400956.148005  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/75, D Loss: 0.8254, G Loss: 2.2368, Class Loss: 1.7826\n",
      "Epoch 33 - Generated Image Class Accuracy: 0.7740\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 0.9800\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.7800\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n",
      "Epoch 35/75, D Loss: 0.8315, G Loss: 2.2168, Class Loss: 1.8866\n",
      "Epoch 35 - Generated Image Class Accuracy: 0.7820\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8200\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 37/75, D Loss: 0.8328, G Loss: 2.2466, Class Loss: 1.8137\n",
      "Epoch 37 - Generated Image Class Accuracy: 0.7820\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8800\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745401018.465810  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/75, D Loss: 0.8149, G Loss: 2.2758, Class Loss: 1.6068\n",
      "Epoch 39 - Generated Image Class Accuracy: 0.8240\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.4400\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 41/75, D Loss: 0.7945, G Loss: 2.3231, Class Loss: 1.4504\n",
      "Epoch 41 - Generated Image Class Accuracy: 0.7960\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0600\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 43/75, D Loss: 0.8196, G Loss: 2.2847, Class Loss: 1.4243\n",
      "Epoch 43 - Generated Image Class Accuracy: 0.8940\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.8000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.2400\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745401078.868272  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/75, D Loss: 0.8207, G Loss: 2.2583, Class Loss: 1.3966\n",
      "Epoch 45 - Generated Image Class Accuracy: 0.8800\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9400\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.8600\n",
      "Epoch 47/75, D Loss: 0.8244, G Loss: 2.2928, Class Loss: 1.5840\n",
      "Epoch 47 - Generated Image Class Accuracy: 0.9520\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8200\n",
      "  Class 4 accuracy: 0.9600\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.7800\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745401144.439900  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/75, D Loss: 0.8036, G Loss: 2.3501, Class Loss: 1.3931\n",
      "Epoch 49 - Generated Image Class Accuracy: 0.9280\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.4800\n",
      "  Class 9 accuracy: 0.9200\n",
      "Epoch 51/75, D Loss: 0.7939, G Loss: 2.2989, Class Loss: 1.2766\n",
      "Epoch 51 - Generated Image Class Accuracy: 0.8320\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9400\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.5000\n",
      "  Class 9 accuracy: 0.9000\n",
      "Epoch 53/75, D Loss: 0.8023, G Loss: 2.3097, Class Loss: 1.3544\n",
      "Epoch 53 - Generated Image Class Accuracy: 0.8480\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8200\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.6600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745401205.243566  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/75, D Loss: 0.7828, G Loss: 2.4213, Class Loss: 1.1696\n",
      "Epoch 55 - Generated Image Class Accuracy: 0.7760\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8400\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9200\n",
      "Epoch 57/75, D Loss: 0.7837, G Loss: 2.3537, Class Loss: 1.2491\n",
      "Epoch 57 - Generated Image Class Accuracy: 0.7740\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9600\n",
      "  Class 3 accuracy: 0.9200\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.8600\n",
      "Epoch 59/75, D Loss: 0.7904, G Loss: 2.3359, Class Loss: 1.1739\n",
      "Epoch 59 - Generated Image Class Accuracy: 0.8580\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.7600\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9200\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745401268.028894  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/75, D Loss: 0.7884, G Loss: 2.3699, Class Loss: 1.2211\n",
      "Epoch 61 - Generated Image Class Accuracy: 0.8360\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9400\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.5600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.8600\n",
      "Epoch 63/75, D Loss: 0.8039, G Loss: 2.3340, Class Loss: 1.2781\n",
      "Epoch 63 - Generated Image Class Accuracy: 0.8860\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8800\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 11:42:04.029604: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "E0000 00:00:1745401334.807806  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/75, D Loss: 0.7813, G Loss: 2.4038, Class Loss: 1.1320\n",
      "Epoch 65 - Generated Image Class Accuracy: 0.9640\n",
      "  Class 0 accuracy: 0.9800\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8600\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.8600\n",
      "  Class 9 accuracy: 0.9400\n",
      "Epoch 67/75, D Loss: 0.7823, G Loss: 2.4025, Class Loss: 1.0616\n",
      "Epoch 67 - Generated Image Class Accuracy: 0.8660\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.7600\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9000\n",
      "Epoch 69/75, D Loss: 0.7791, G Loss: 2.4043, Class Loss: 1.2107\n",
      "Epoch 69 - Generated Image Class Accuracy: 0.8720\n",
      "  Class 0 accuracy: 0.9800\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8200\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745401396.199613  188263 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/75, D Loss: 0.7771, G Loss: 2.4380, Class Loss: 1.3086\n",
      "Epoch 71 - Generated Image Class Accuracy: 0.8780\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8200\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9600\n",
      "Epoch 73/75, D Loss: 0.7648, G Loss: 2.4836, Class Loss: 1.0814\n",
      "Epoch 73 - Generated Image Class Accuracy: 0.8900\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 75/75, D Loss: 0.7830, G Loss: 2.4341, Class Loss: 1.1095\n",
      "Epoch 75 - Generated Image Class Accuracy: 0.8940\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9800\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n",
      "mkdir: cannot create directory ‘my_gan_checkpoint_700’: File exists\n",
      "Model saved successfully to my_gan_checkpoint_700\n"
     ]
    }
   ],
   "source": [
    "dcgan_700 = DCGAN.load(checkpoint_dir='my_gan_checkpoint_700')\n",
    "# dcgan_700.compile()\n",
    "# Train the DCGAN on the 700-sample subset\n",
    "dcgan_700.train(x_train_700, y_train_700, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "# Save the model\n",
    "!mkdir  my_gan_checkpoint_700\n",
    "dcgan_700.save(checkpoint_dir='my_gan_checkpoint_700')\n",
    "!mv generated_images generated_images_700\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the 1000 GAN\n",
    "### We will train the model for 75 and save the model if we are not satisfied with the results we load the model and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745416092.514567   67415 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4610 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_67415/512743676.py:16: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  hidden = tf.keras.applications.MobileNetV2(\n",
      "I0000 00:00:1745416095.102962   67415 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:407: UserWarning: `build()` was called on layer 'discriminator', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer states restored from my_gan_checkpoint_1000/optimizer_ckpt/ckpt-2\n",
      "Model loaded successfully from my_gan_checkpoint_1000\n",
      "Pre-training classifier...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745416112.734799   67952 service.cc:152] XLA service 0x7d19240033f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745416112.734825   67952 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2025-04-23 15:48:33.324260: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 7/79\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9994 - loss: 0.0021     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745416129.480761   67952 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 214ms/step - accuracy: 0.9982 - loss: 0.0050\n",
      "Epoch 2/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9982 - loss: 0.0049\n",
      "Epoch 3/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9983 - loss: 0.0077\n",
      "Epoch 4/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9975 - loss: 0.0099\n",
      "Epoch 5/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9967 - loss: 0.0103\n",
      "Epoch 6/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9961 - loss: 0.0162\n",
      "Epoch 7/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9975 - loss: 0.0057\n",
      "Epoch 8/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9960 - loss: 0.0185\n",
      "Epoch 9/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9972 - loss: 0.0125\n",
      "Epoch 10/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9947 - loss: 0.0217\n",
      "Epoch 11/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9965 - loss: 0.0088\n",
      "Epoch 12/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9961 - loss: 0.0127\n",
      "Epoch 13/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9980 - loss: 0.0071\n",
      "Epoch 14/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9954 - loss: 0.0329\n",
      "Epoch 15/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9984 - loss: 0.0052\n",
      "Epoch 16/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9984 - loss: 0.0056\n",
      "Epoch 17/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9983 - loss: 0.0053\n",
      "Epoch 18/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9976 - loss: 0.0091\n",
      "Epoch 19/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9973 - loss: 0.0080\n",
      "Epoch 20/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9983 - loss: 0.0050\n",
      "Classifier pre-training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745416176.108127   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-04-23 15:49:48.233298: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75, D Loss: 0.6987, G Loss: 2.6750, Class Loss: 2.9344\n",
      "Epoch 1 - Generated Image Class Accuracy: 0.9720\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 1.0000\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.7600\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 15:50:02.140457: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/75, D Loss: 0.7876, G Loss: 2.4080, Class Loss: 3.7212\n",
      "Epoch 3 - Generated Image Class Accuracy: 0.8880\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9400\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0600\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 15:50:28.350331: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "E0000 00:00:1745416240.148823   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/75, D Loss: 0.8149, G Loss: 2.2883, Class Loss: 3.7634\n",
      "Epoch 5 - Generated Image Class Accuracy: 0.8880\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9800\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n",
      "Epoch 7/75, D Loss: 0.8140, G Loss: 2.2844, Class Loss: 3.8211\n",
      "Epoch 7 - Generated Image Class Accuracy: 0.8880\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 1.0000\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.9600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9600\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 15:51:20.554453: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/75, D Loss: 0.8338, G Loss: 2.2134, Class Loss: 4.0024\n",
      "Epoch 9 - Generated Image Class Accuracy: 0.8580\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9200\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.8200\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745416306.581089   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/75, D Loss: 0.8372, G Loss: 2.1708, Class Loss: 3.8292\n",
      "Epoch 11 - Generated Image Class Accuracy: 0.8820\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9800\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.9200\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0200\n",
      "  Class 9 accuracy: 0.9400\n",
      "Epoch 13/75, D Loss: 0.8440, G Loss: 2.1510, Class Loss: 3.6619\n",
      "Epoch 13 - Generated Image Class Accuracy: 0.8800\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 0.9600\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9600\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745416372.636543   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/75, D Loss: 0.8419, G Loss: 2.1957, Class Loss: 3.5510\n",
      "Epoch 15 - Generated Image Class Accuracy: 0.8800\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.8800\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9400\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 15:53:06.903426: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/75, D Loss: 0.8290, G Loss: 2.2180, Class Loss: 3.4538\n",
      "Epoch 17 - Generated Image Class Accuracy: 0.8660\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 0.9200\n",
      "  Class 5 accuracy: 0.9000\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 19/75, D Loss: 0.8304, G Loss: 2.1914, Class Loss: 3.4975\n",
      "Epoch 19 - Generated Image Class Accuracy: 0.8700\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.8000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0400\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745416437.307898   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/75, D Loss: 0.8433, G Loss: 2.1731, Class Loss: 3.8481\n",
      "Epoch 21 - Generated Image Class Accuracy: 0.8780\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 0.9800\n",
      "  Class 2 accuracy: 0.9600\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 0.9600\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n",
      "Epoch 23/75, D Loss: 0.8330, G Loss: 2.2371, Class Loss: 3.2807\n",
      "Epoch 23 - Generated Image Class Accuracy: 0.9800\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 0.9800\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9600\n",
      "  Class 4 accuracy: 0.9600\n",
      "  Class 5 accuracy: 0.9200\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 1.0000\n",
      "  Class 9 accuracy: 0.9800\n",
      "Epoch 25/75, D Loss: 0.8260, G Loss: 2.2557, Class Loss: 3.2373\n",
      "Epoch 25 - Generated Image Class Accuracy: 0.8900\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 1.0000\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745416500.930332   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/75, D Loss: 0.8274, G Loss: 2.2305, Class Loss: 3.4036\n",
      "Epoch 27 - Generated Image Class Accuracy: 0.8920\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 1.0000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9600\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 29/75, D Loss: 0.8345, G Loss: 2.1849, Class Loss: 3.3488\n",
      "Epoch 29 - Generated Image Class Accuracy: 0.8900\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 1.0000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9200\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745416569.435873   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/75, D Loss: 0.8079, G Loss: 2.2353, Class Loss: 3.3017\n",
      "Epoch 31 - Generated Image Class Accuracy: 0.8920\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9000\n",
      "  Class 3 accuracy: 1.0000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0400\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 15:56:23.358272: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/75, D Loss: 0.8160, G Loss: 2.2453, Class Loss: 3.1593\n",
      "Epoch 33 - Generated Image Class Accuracy: 0.8860\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 1.0000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9000\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 35/75, D Loss: 0.8090, G Loss: 2.3170, Class Loss: 3.0836\n",
      "Epoch 35 - Generated Image Class Accuracy: 0.9360\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9600\n",
      "  Class 3 accuracy: 0.9600\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.8600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.6200\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745416631.030723   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/75, D Loss: 0.8019, G Loss: 2.3082, Class Loss: 2.9396\n",
      "Epoch 37 - Generated Image Class Accuracy: 0.9800\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 1.0000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.8800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.9400\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 39/75, D Loss: 0.7866, G Loss: 2.3482, Class Loss: 2.9132\n",
      "Epoch 39 - Generated Image Class Accuracy: 0.9660\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9400\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.8600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.9000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 41/75, D Loss: 0.7762, G Loss: 2.3972, Class Loss: 2.9461\n",
      "Epoch 41 - Generated Image Class Accuracy: 0.9700\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9200\n",
      "  Class 4 accuracy: 0.9400\n",
      "  Class 5 accuracy: 0.8800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 1.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745416695.320326   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/75, D Loss: 0.7821, G Loss: 2.3891, Class Loss: 2.9111\n",
      "Epoch 43 - Generated Image Class Accuracy: 0.9760\n",
      "  Class 0 accuracy: 0.9800\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9600\n",
      "  Class 3 accuracy: 0.9200\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9400\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.9600\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 45/75, D Loss: 0.7842, G Loss: 2.3871, Class Loss: 2.7449\n",
      "Epoch 45 - Generated Image Class Accuracy: 0.9740\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9200\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.8600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 1.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745416763.716527   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/75, D Loss: 0.7656, G Loss: 2.4854, Class Loss: 2.7564\n",
      "Epoch 47 - Generated Image Class Accuracy: 0.9860\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9600\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.9600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.9800\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 49/75, D Loss: 0.7742, G Loss: 2.4563, Class Loss: 2.6437\n",
      "Epoch 49 - Generated Image Class Accuracy: 0.8820\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9200\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9200\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 51/75, D Loss: 0.7637, G Loss: 2.4744, Class Loss: 2.6977\n",
      "Epoch 51 - Generated Image Class Accuracy: 0.8720\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 0.9600\n",
      "  Class 5 accuracy: 0.9000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745416824.189119   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/75, D Loss: 0.7641, G Loss: 2.4676, Class Loss: 2.5527\n",
      "Epoch 53 - Generated Image Class Accuracy: 0.9280\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9800\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.3400\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 55/75, D Loss: 0.7754, G Loss: 2.4279, Class Loss: 2.4369\n",
      "Epoch 55 - Generated Image Class Accuracy: 0.9820\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9400\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.9000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 1.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745416885.458991   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/75, D Loss: 0.7646, G Loss: 2.4578, Class Loss: 2.3228\n",
      "Epoch 57 - Generated Image Class Accuracy: 0.9900\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 0.9800\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9800\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 1.0000\n",
      "  Class 9 accuracy: 0.9800\n",
      "Epoch 59/75, D Loss: 0.7515, G Loss: 2.5213, Class Loss: 2.4020\n",
      "Epoch 59 - Generated Image Class Accuracy: 0.8840\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9400\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9200\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 61/75, D Loss: 0.7493, G Loss: 2.5638, Class Loss: 2.2367\n",
      "Epoch 61 - Generated Image Class Accuracy: 0.8860\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745416946.336289   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/75, D Loss: 0.7463, G Loss: 2.5576, Class Loss: 2.2094\n",
      "Epoch 63 - Generated Image Class Accuracy: 0.9560\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9600\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.7000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 16:02:50.988667: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/75, D Loss: 0.7446, G Loss: 2.6008, Class Loss: 2.0032\n",
      "Epoch 65 - Generated Image Class Accuracy: 0.9060\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 0.9800\n",
      "  Class 2 accuracy: 1.0000\n",
      "  Class 3 accuracy: 0.9200\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9200\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.2400\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745417007.745468   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/75, D Loss: 0.7533, G Loss: 2.5585, Class Loss: 1.9516\n",
      "Epoch 67 - Generated Image Class Accuracy: 0.8740\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9400\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9200\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 69/75, D Loss: 0.7195, G Loss: 2.6771, Class Loss: 1.8908\n",
      "Epoch 69 - Generated Image Class Accuracy: 0.8860\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9400\n",
      "  Class 3 accuracy: 0.9600\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9400\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0200\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 71/75, D Loss: 0.7401, G Loss: 2.6328, Class Loss: 1.9177\n",
      "Epoch 71 - Generated Image Class Accuracy: 0.8900\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 1.0000\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9200\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745417068.647211   67415 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/75, D Loss: 0.7462, G Loss: 2.6166, Class Loss: 2.0210\n",
      "Epoch 73 - Generated Image Class Accuracy: 0.9660\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9600\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9400\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.7800\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 75/75, D Loss: 0.7354, G Loss: 2.6224, Class Loss: 1.9053\n",
      "Epoch 75 - Generated Image Class Accuracy: 0.8960\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9800\n",
      "  Class 3 accuracy: 0.9800\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 0.9200\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0800\n",
      "  Class 9 accuracy: 1.0000\n",
      "mkdir: cannot create directory ‘my_gan_checkpoint_1000’: File exists\n",
      "Model saved successfully to my_gan_checkpoint_1000\n"
     ]
    }
   ],
   "source": [
    "# dcgan_1000 = DCGAN()\n",
    "# dcgan_1000.compile()\n",
    "dcgan_1000 = DCGAN.load(checkpoint_dir='my_gan_checkpoint_1000')\n",
    "# Train the DCGAN on the 1000-sample subset\n",
    "dcgan_1000.train(x_train_1000, y_train_1000, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "# Save the model\n",
    "!mkdir  my_gan_checkpoint_1000\n",
    "dcgan_1000.save(checkpoint_dir='my_gan_checkpoint_1000')\n",
    "!mv generated_images generated_images_1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    \"\"\"Create a simple CNN model for digit classification\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for testing the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:27:21] Loading pre-trained GAN models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_93956/512743676.py:16: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  hidden = tf.keras.applications.MobileNetV2(\n",
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:407: UserWarning: `build()` was called on layer 'discriminator_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer states restored from my_gan_checkpoint_300/optimizer_ckpt/ckpt-2\n",
      "Model loaded successfully from my_gan_checkpoint_300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:407: UserWarning: `build()` was called on layer 'discriminator_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer states restored from my_gan_checkpoint_700/optimizer_ckpt/ckpt-2\n",
      "Model loaded successfully from my_gan_checkpoint_700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:407: UserWarning: `build()` was called on layer 'discriminator_6', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer states restored from my_gan_checkpoint_1000/optimizer_ckpt/ckpt-2\n",
      "Model loaded successfully from my_gan_checkpoint_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:407: UserWarning: `build()` was called on layer 'discriminator_7', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer states restored from my_gan_checkpoint/optimizer_ckpt/ckpt-2\n",
      "Model loaded successfully from my_gan_checkpoint\n",
      "[2025-04-24 18:27:40] Starting experiment pipeline for Problem 3 (GAN Evaluation)\n",
      "[2025-04-24 18:27:40] Loading real training data\n",
      "[2025-04-24 18:27:41] Training data shapes: 300: (3000, 28, 28, 1), 700: (7000, 28, 28, 1), 1000: (10000, 28, 28, 1)\n",
      "[2025-04-24 18:27:41] Loading test data\n",
      "[2025-04-24 18:27:41] Test data shape: x_test=(2000, 28, 28, 1), y_test=(2000,)\n",
      "[2025-04-24 18:27:41] Starting experiments for 300 real samples per class\n",
      "[2025-04-24 18:27:41] Experiment: 300 real + 0 generated\n",
      "[2025-04-24 18:27:41] Training model on real data only\n",
      "[2025-04-24 18:27:49] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "[2025-04-24 18:27:50] Test Accuracy (0 generated): 0.9785\n",
      "[2025-04-24 18:27:50] Experiment: 300 real + 1000 generated per class (10000 total)\n",
      "[2025-04-24 18:27:50] Using dcgan_300 to generate 1000 samples per class\n",
      "[2025-04-24 18:27:51] Combined data shape: (13000, 28, 28, 1)\n",
      "[2025-04-24 18:27:51] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:28:14] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "[2025-04-24 18:28:14] Test Accuracy with dcgan_300: 0.9485\n",
      "[2025-04-24 18:28:14] Using dcgan_full to generate 1000 samples per class\n",
      "[2025-04-24 18:28:15] Combined data shape: (13000, 28, 28, 1)\n",
      "[2025-04-24 18:28:15] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:28:38] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "[2025-04-24 18:28:39] Test Accuracy with dcgan_full: 0.9655\n",
      "[2025-04-24 18:28:39] Experiment: 300 real + 2000 generated per class (20000 total)\n",
      "[2025-04-24 18:28:39] Using dcgan_300 to generate 2000 samples per class\n",
      "[2025-04-24 18:28:41] Combined data shape: (23000, 28, 28, 1)\n",
      "[2025-04-24 18:28:41] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:29:18] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:29:19] Test Accuracy with dcgan_300: 0.9400\n",
      "[2025-04-24 18:29:19] Using dcgan_full to generate 2000 samples per class\n",
      "[2025-04-24 18:29:21] Combined data shape: (23000, 28, 28, 1)\n",
      "[2025-04-24 18:29:21] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:30:00] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:30:00] Test Accuracy with dcgan_full: 0.9800\n",
      "[2025-04-24 18:30:00] Experiment: 300 real + 3000 generated per class (30000 total)\n",
      "[2025-04-24 18:30:00] Using dcgan_300 to generate 3000 samples per class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:30:00.845931: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.82GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-24 18:30:01.449248: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.87GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-24 18:30:01.454364: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.72GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:30:06] Combined data shape: (33000, 28, 28, 1)\n",
      "[2025-04-24 18:30:06] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:30:58] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "[2025-04-24 18:30:58] Test Accuracy with dcgan_300: 0.9110\n",
      "[2025-04-24 18:30:58] Using dcgan_full to generate 3000 samples per class\n",
      "[2025-04-24 18:31:02] Combined data shape: (33000, 28, 28, 1)\n",
      "[2025-04-24 18:31:02] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:31:53] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "[2025-04-24 18:31:54] Test Accuracy with dcgan_full: 0.9735\n",
      "[2025-04-24 18:31:54] Starting experiments for 700 real samples per class\n",
      "[2025-04-24 18:31:54] Experiment: 700 real + 0 generated\n",
      "[2025-04-24 18:31:54] Training model on real data only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:32:09] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:32:09] Test Accuracy (0 generated): 0.9815\n",
      "[2025-04-24 18:32:09] Experiment: 700 real + 1000 generated per class (10000 total)\n",
      "[2025-04-24 18:32:09] Using dcgan_700 to generate 1000 samples per class\n",
      "[2025-04-24 18:32:11] Combined data shape: (17000, 28, 28, 1)\n",
      "[2025-04-24 18:32:11] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:32:39] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:32:40] Test Accuracy with dcgan_700: 0.9860\n",
      "[2025-04-24 18:32:40] Using dcgan_full to generate 1000 samples per class\n",
      "[2025-04-24 18:32:41] Combined data shape: (17000, 28, 28, 1)\n",
      "[2025-04-24 18:32:41] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:33:10] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:33:10] Test Accuracy with dcgan_full: 0.9855\n",
      "[2025-04-24 18:33:10] Experiment: 700 real + 2000 generated per class (20000 total)\n",
      "[2025-04-24 18:33:10] Using dcgan_700 to generate 2000 samples per class\n",
      "[2025-04-24 18:33:13] Combined data shape: (27000, 28, 28, 1)\n",
      "[2025-04-24 18:33:13] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:33:56] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:33:56] Test Accuracy with dcgan_700: 0.9840\n",
      "[2025-04-24 18:33:56] Using dcgan_full to generate 2000 samples per class\n",
      "[2025-04-24 18:33:59] Combined data shape: (27000, 28, 28, 1)\n",
      "[2025-04-24 18:33:59] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:34:42] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:34:42] Test Accuracy with dcgan_full: 0.9855\n",
      "[2025-04-24 18:34:42] Experiment: 700 real + 3000 generated per class (30000 total)\n",
      "[2025-04-24 18:34:42] Using dcgan_700 to generate 3000 samples per class\n",
      "[2025-04-24 18:34:46] Combined data shape: (37000, 28, 28, 1)\n",
      "[2025-04-24 18:34:46] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:35:43] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:35:44] Test Accuracy with dcgan_700: 0.9830\n",
      "[2025-04-24 18:35:44] Using dcgan_full to generate 3000 samples per class\n",
      "[2025-04-24 18:35:47] Combined data shape: (37000, 28, 28, 1)\n",
      "[2025-04-24 18:35:47] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:36:44] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:36:45] Test Accuracy with dcgan_full: 0.9845\n",
      "[2025-04-24 18:36:45] Starting experiments for 1000 real samples per class\n",
      "[2025-04-24 18:36:45] Experiment: 1000 real + 0 generated\n",
      "[2025-04-24 18:36:45] Training model on real data only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2025-04-24 18:36:48.347445: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.6 = (f32[16,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,1,28,28]{3,2,1,0} %bitcast.4265, f32[32,1,3,3]{3,2,1,0} %bitcast.4272, f32[32]{0} %bitcast.4738), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_37_1/conv2d_106_1/convolution\" source_file=\"/home/youssef-abuzeid/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-24 18:36:48.384618: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.7 = (f32[16,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,13,13]{3,2,1,0} %bitcast.4802, f32[64,32,3,3]{3,2,1,0} %bitcast.4292, f32[64]{0} %bitcast.4862), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_37_1/conv2d_107_1/convolution\" source_file=\"/home/youssef-abuzeid/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:37:04] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:37:04] Test Accuracy (0 generated): 0.9890\n",
      "[2025-04-24 18:37:04] Experiment: 1000 real + 1000 generated per class (10000 total)\n",
      "[2025-04-24 18:37:04] Using dcgan_1000 to generate 1000 samples per class\n",
      "[2025-04-24 18:37:05] Combined data shape: (20000, 28, 28, 1)\n",
      "[2025-04-24 18:37:05] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:37:38] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:37:38] Test Accuracy with dcgan_1000: 0.9900\n",
      "[2025-04-24 18:37:38] Using dcgan_full to generate 1000 samples per class\n",
      "[2025-04-24 18:37:40] Combined data shape: (20000, 28, 28, 1)\n",
      "[2025-04-24 18:37:40] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:38:11] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "[2025-04-24 18:38:12] Test Accuracy with dcgan_full: 0.9875\n",
      "[2025-04-24 18:38:12] Experiment: 1000 real + 2000 generated per class (20000 total)\n",
      "[2025-04-24 18:38:12] Using dcgan_1000 to generate 2000 samples per class\n",
      "[2025-04-24 18:38:14] Combined data shape: (30000, 28, 28, 1)\n",
      "[2025-04-24 18:38:14] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:39:01] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:39:02] Test Accuracy with dcgan_1000: 0.9895\n",
      "[2025-04-24 18:39:02] Using dcgan_full to generate 2000 samples per class\n",
      "[2025-04-24 18:39:04] Combined data shape: (30000, 28, 28, 1)\n",
      "[2025-04-24 18:39:04] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:39:57] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:39:58] Test Accuracy with dcgan_full: 0.9865\n",
      "[2025-04-24 18:39:58] Experiment: 1000 real + 3000 generated per class (30000 total)\n",
      "[2025-04-24 18:39:58] Using dcgan_1000 to generate 3000 samples per class\n",
      "[2025-04-24 18:40:01] Combined data shape: (40000, 28, 28, 1)\n",
      "[2025-04-24 18:40:01] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:41:06] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "[2025-04-24 18:41:07] Test Accuracy with dcgan_1000: 0.9895\n",
      "[2025-04-24 18:41:07] Using dcgan_full to generate 3000 samples per class\n",
      "[2025-04-24 18:41:10] Combined data shape: (40000, 28, 28, 1)\n",
      "[2025-04-24 18:41:10] Training model on combined real and synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 18:42:15] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 18:42:15] Test Accuracy with dcgan_full: 0.9865\n",
      "[2025-04-24 18:42:15] Test Accuracies Table:\n",
      "| Real Samples | 0 Generated | 1000 Generated (Specific GAN) | 1000 Generated (GAN Full) | 2000 Generated (Specific GAN) | 2000 Generated (GAN Full) | 3000 Generated (Specific GAN) | 3000 Generated (GAN Full) |\n",
      "|--------------|-------------|-------------------------------|---------------------------|-------------------------------|---------------------------|-------------------------------|---------------------------|\n",
      "| 300          | 0.9785       | 0.9485                     | 0.9655                 | 0.9400                     | 0.9800                 | 0.9110                     | 0.9735                 |\n",
      "| 700          | 0.9815       | 0.9860                     | 0.9855                 | 0.9840                     | 0.9855                 | 0.9830                     | 0.9845                 |\n",
      "| 1000         | 0.9890       | 0.9900                     | 0.9875                 | 0.9895                     | 0.9865                 | 0.9895                     | 0.9865                 |\n",
      "[2025-04-24 18:42:15] Experiment pipeline completed\n"
     ]
    }
   ],
   "source": [
    "def log_message(message):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] {message}\")\n",
    "\n",
    "# Step 1: Load GAN models\n",
    "log_message(\"Loading pre-trained GAN models\")\n",
    "dcgan_300 = DCGAN.load(checkpoint_dir='my_gan_checkpoint_300')  # Trained on 300 real samples per class\n",
    "dcgan_700 = DCGAN.load(checkpoint_dir='my_gan_checkpoint_700')  # Trained on 700 real samples per class\n",
    "dcgan_1000 = DCGAN.load(checkpoint_dir='my_gan_checkpoint_1000')  # Trained on 1000 real samples per class\n",
    "dcgan_full = DCGAN.load(checkpoint_dir='my_gan_checkpoint')  # Trained on full MNIST dataset (best quality)\n",
    "\n",
    "# Step 2: Load real and test data\n",
    "log_message(\"Starting experiment pipeline for Problem 3 (GAN Evaluation)\")\n",
    "log_message(\"Loading real training data\")\n",
    "num_classes = 10\n",
    "x_train_300, y_train_300 = load_images_from_directory(train_dir, n_samples_per_class=300)  # 300 per class (3000 total)\n",
    "x_train_700, y_train_700 = load_images_from_directory(train_dir, n_samples_per_class=700)  # 700 per class (7000 total)\n",
    "x_train_1000, y_train_1000 = load_images_from_directory(train_dir, n_samples_per_class=1000)  # 1000 per class (10000 total)\n",
    "log_message(f\"Training data shapes: 300: {x_train_300.shape}, 700: {x_train_700.shape}, 1000: {x_train_1000.shape}\")\n",
    "\n",
    "log_message(\"Loading test data\")\n",
    "x_test, y_test = load_images_from_directory(test_dir, n_samples_per_class=200)  # 200 per class (2000 total)\n",
    "log_message(f\"Test data shape: x_test={x_test.shape}, y_test={y_test.shape}\")\n",
    "\n",
    "# Step 3: Define the results table\n",
    "# Structure: {real_samples: {generated_samples_per_class: accuracy}}\n",
    "results_table = {\n",
    "    300: {0: 0, 1000: {}, 2000: {}, 3000: {}},\n",
    "    700: {0: 0, 1000: {}, 2000: {}, 3000: {}},\n",
    "    1000: {0: 0, 1000: {}, 2000: {}, 3000: {}}\n",
    "}\n",
    "# Sub-dictionary for 1000, 2000, 3000 generated samples per class to store results for specific GANs\n",
    "for real_samples in [300, 700, 1000]:\n",
    "    for gen_samples in [1000, 2000, 3000]:\n",
    "        # For each real sample size, use the corresponding GAN and dcgan_full\n",
    "        if real_samples == 300:\n",
    "            results_table[real_samples][gen_samples] = {'dcgan_300': 0, 'dcgan_full': 0}\n",
    "        elif real_samples == 700:\n",
    "            results_table[real_samples][gen_samples] = {'dcgan_700': 0, 'dcgan_full': 0}\n",
    "        else:  # real_samples == 1000\n",
    "            results_table[real_samples][gen_samples] = {'dcgan_1000': 0, 'dcgan_full': 0}\n",
    "\n",
    "# Step 4: Run experiments for each combination\n",
    "for real_samples, x_train, y_train in [(300, x_train_300, y_train_300),\n",
    "                                       (700, x_train_700, y_train_700),\n",
    "                                       (1000, x_train_1000, y_train_1000)]:\n",
    "    log_message(f\"Starting experiments for {real_samples} real samples per class\")\n",
    "    \n",
    "    # Step 4.1: Evaluate with only real data (0 generated samples)\n",
    "    log_message(f\"Experiment: {real_samples} real + 0 generated\")\n",
    "    try:\n",
    "        model = create_cnn_model()\n",
    "        log_message(\"Training model on real data only\")\n",
    "        history = model.fit(\n",
    "            x_train, y_train,\n",
    "            epochs=20, batch_size=32, verbose=0\n",
    "        )\n",
    "        \n",
    "        # Evaluate on the test set\n",
    "        log_message(\"Evaluating model on test set\")\n",
    "        pred = model.predict(x_test)\n",
    "        y_pred = np.argmax(pred, axis=1)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        results_table[real_samples][0] = test_accuracy\n",
    "        log_message(f\"Test Accuracy (0 generated): {test_accuracy:.4f}\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during training/evaluation (0 generated): {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    # Step 4.2: Evaluate with 1000, 2000, 3000 synthetic samples per class using specific GANs\n",
    "    for gen_samples_per_class in [1000, 2000, 3000]:\n",
    "        total_gen_samples = gen_samples_per_class * num_classes  # Total synthetic samples\n",
    "        log_message(f\"Experiment: {real_samples} real + {gen_samples_per_class} generated per class ({total_gen_samples} total)\")\n",
    "        \n",
    "        # Select GAN models based on real sample size\n",
    "        if real_samples == 300:\n",
    "            gan_models = [('dcgan_300', dcgan_300), ('dcgan_full', dcgan_full)]\n",
    "        elif real_samples == 700:\n",
    "            gan_models = [('dcgan_700', dcgan_700), ('dcgan_full', dcgan_full)]\n",
    "        else:  # real_samples == 1000\n",
    "            gan_models = [('dcgan_1000', dcgan_1000), ('dcgan_full', dcgan_full)]\n",
    "        \n",
    "        for gan_name, gan_model in gan_models:\n",
    "            log_message(f\"Using {gan_name} to generate {gen_samples_per_class} samples per class\")\n",
    "            \n",
    "            # Generate synthetic data\n",
    "            try:\n",
    "                synthetic_images, synthetic_labels = gan_model.generate_synthetic_data(total_gen_samples, num_classes)\n",
    "                # Combine real and synthetic data\n",
    "                x_train_combined = np.concatenate((x_train, synthetic_images), axis=0)\n",
    "                y_train_combined = np.concatenate((y_train, synthetic_labels), axis=0)\n",
    "                log_message(f\"Combined data shape: {x_train_combined.shape}\")\n",
    "            except Exception as e:\n",
    "                log_message(f\"Error during synthetic data generation with {gan_name}: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            # Train the model\n",
    "            try:\n",
    "                model = create_cnn_model()\n",
    "                log_message(\"Training model on combined real and synthetic data\")\n",
    "                history = model.fit(\n",
    "                    x_train_combined, y_train_combined,\n",
    "                    epochs=20, batch_size=32, verbose=0\n",
    "                )\n",
    "            except Exception as e:\n",
    "                log_message(f\"Error during training with {gan_name}: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            # Evaluate on the test set\n",
    "            log_message(\"Evaluating model on test set\")\n",
    "            try:\n",
    "                pred = model.predict(x_test)\n",
    "                y_pred = np.argmax(pred, axis=1)\n",
    "                test_accuracy = accuracy_score(y_test, y_pred)\n",
    "                results_table[real_samples][gen_samples_per_class][gan_name] = test_accuracy\n",
    "                log_message(f\"Test Accuracy with {gan_name}: {test_accuracy:.4f}\")\n",
    "            except Exception as e:\n",
    "                log_message(f\"Error during evaluation with {gan_name}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "# Step 5: Display the results table\n",
    "log_message(\"Test Accuracies Table:\")\n",
    "# Main table header\n",
    "print(\"| Real Samples | 0 Generated | 1000 Generated (Specific GAN) | 1000 Generated (GAN Full) | 2000 Generated (Specific GAN) | 2000 Generated (GAN Full) | 3000 Generated (Specific GAN) | 3000 Generated (GAN Full) |\")\n",
    "print(\"|--------------|-------------|-------------------------------|---------------------------|-------------------------------|---------------------------|-------------------------------|---------------------------|\")\n",
    "# Rows for each real sample size\n",
    "for real_samples in [300, 700, 1000]:\n",
    "    # Determine the specific GAN name based on real sample size\n",
    "    specific_gan = 'dcgan_300' if real_samples == 300 else 'dcgan_700' if real_samples == 700 else 'dcgan_1000'\n",
    "    row = f\"| {real_samples:<12} | {results_table[real_samples][0]:.4f}       | \" + \\\n",
    "          f\"{results_table[real_samples][1000][specific_gan]:.4f}                     | \" + \\\n",
    "          f\"{results_table[real_samples][1000]['dcgan_full']:.4f}                 | \" + \\\n",
    "          f\"{results_table[real_samples][2000][specific_gan]:.4f}                     | \" + \\\n",
    "          f\"{results_table[real_samples][2000]['dcgan_full']:.4f}                 | \" + \\\n",
    "          f\"{results_table[real_samples][3000][specific_gan]:.4f}                     | \" + \\\n",
    "          f\"{results_table[real_samples][3000]['dcgan_full']:.4f}                 |\"\n",
    "    print(row)\n",
    "\n",
    "log_message(\"Experiment pipeline completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Sample Accuracy\n",
    "\n",
    "| Real Samples | 0 Generated | 1000 Generated | 2000 Generated | 3000 Generated |\n",
    "|--------------|-------------|----------------|----------------|----------------|\n",
    "| 300          | 97.85%      | 94.85%          | 94%         | 91.1%          |\n",
    "| 700          | 98.15%      | 98.6%          | 98.4%          | 98.3%          |\n",
    "| 1000         | 98.9%       | 99%         | 98.95%         | 98.95%          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Pipeline\n",
    "### 1. Augment the 300 real samples with 1000 generated samples\n",
    "### 2. Train the GAN on the augmented dataset\n",
    "### 3. Generate 1000 new samples\n",
    "### 4. Train the Classifier on the augmented dataset\n",
    "### 5. Evaluate the Classifier on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745507013.485078   59712 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4610 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: found 300 images\n",
      "Generated 1000/1000 augmented images for class 0\n",
      "Class 1: found 300 images\n",
      "Generated 1000/1000 augmented images for class 1\n",
      "Class 2: found 300 images\n",
      "Generated 1000/1000 augmented images for class 2\n",
      "Class 3: found 300 images\n",
      "Generated 1000/1000 augmented images for class 3\n",
      "Class 4: found 300 images\n",
      "Generated 1000/1000 augmented images for class 4\n",
      "Class 5: found 300 images\n",
      "Generated 1000/1000 augmented images for class 5\n",
      "Class 6: found 300 images\n",
      "Generated 1000/1000 augmented images for class 6\n",
      "Class 7: found 300 images\n",
      "Generated 1000/1000 augmented images for class 7\n",
      "Class 8: found 300 images\n",
      "Generated 1000/1000 augmented images for class 8\n",
      "Class 9: found 300 images\n",
      "Generated 1000/1000 augmented images for class 9\n",
      "Total synthetic images: 10000\n",
      "Final dataset: 13000 images (3000 real + 10000 synthetic)\n"
     ]
    }
   ],
   "source": [
    "from augmentations import generate_dataset_with_augmentation\n",
    "# Generate augmented dataset\n",
    "augmented_images,augmented_labels = generate_dataset_with_augmentation(x_train_300, y_train_300,3000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_59712/512743676.py:16: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  hidden = tf.keras.applications.MobileNetV2(\n",
      "I0000 00:00:1745507022.896133   59712 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:407: UserWarning: `build()` was called on layer 'discriminator', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer states restored from my_gan_checkpoint_augmented/optimizer_ckpt/ckpt-2\n",
      "Model loaded successfully from my_gan_checkpoint_augmented\n",
      "Pre-training classifier...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745507039.908406   60116 service.cc:152] XLA service 0x7830c80030f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745507039.908421   60116 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2025-04-24 17:04:00.468918: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  7/102\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9993 - loss: 0.0065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745507056.099308   60116 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 170ms/step - accuracy: 0.9967 - loss: 0.0156\n",
      "Epoch 2/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9963 - loss: 0.0121\n",
      "Epoch 3/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9983 - loss: 0.0070\n",
      "Epoch 4/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9988 - loss: 0.0055\n",
      "Epoch 5/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9990 - loss: 0.0045\n",
      "Epoch 6/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9975 - loss: 0.0106\n",
      "Epoch 7/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9982 - loss: 0.0059\n",
      "Epoch 8/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9956 - loss: 0.0191\n",
      "Epoch 9/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9983 - loss: 0.0061\n",
      "Epoch 10/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9971 - loss: 0.0122\n",
      "Epoch 11/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9958 - loss: 0.0173\n",
      "Epoch 12/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9984 - loss: 0.0063\n",
      "Epoch 13/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9978 - loss: 0.0083\n",
      "Epoch 14/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 15/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9994 - loss: 0.0020\n",
      "Epoch 16/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9971 - loss: 0.0113\n",
      "Epoch 17/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9985 - loss: 0.0050\n",
      "Epoch 18/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9979 - loss: 0.0070\n",
      "Epoch 19/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9988 - loss: 0.0052\n",
      "Epoch 20/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9983 - loss: 0.0053\n",
      "Classifier pre-training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745507110.509464   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-04-24 17:05:24.839996: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75, D Loss: 0.7627, G Loss: 2.4334, Class Loss: 2.5551\n",
      "Epoch 1 - Generated Image Class Accuracy: 0.8260\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.7600\n",
      "  Class 3 accuracy: 0.5400\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 17:05:40.758918: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/75, D Loss: 0.7751, G Loss: 2.3886, Class Loss: 2.3390\n",
      "Epoch 3 - Generated Image Class Accuracy: 0.8240\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.7000\n",
      "  Class 3 accuracy: 0.8600\n",
      "  Class 4 accuracy: 0.7600\n",
      "  Class 5 accuracy: 0.9600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 17:06:11.106112: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "E0000 00:00:1745507173.708416   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/75, D Loss: 0.8037, G Loss: 2.2663, Class Loss: 2.9973\n",
      "Epoch 5 - Generated Image Class Accuracy: 0.8380\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.6400\n",
      "  Class 3 accuracy: 0.8400\n",
      "  Class 4 accuracy: 0.9200\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 7/75, D Loss: 0.7994, G Loss: 2.2784, Class Loss: 2.4342\n",
      "Epoch 7 - Generated Image Class Accuracy: 0.8440\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.6200\n",
      "  Class 3 accuracy: 0.8800\n",
      "  Class 4 accuracy: 0.9600\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0200\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 17:07:12.593448: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "E0000 00:00:1745507235.399932   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/75, D Loss: 0.7942, G Loss: 2.2771, Class Loss: 2.4343\n",
      "Epoch 9 - Generated Image Class Accuracy: 0.8760\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 0.9800\n",
      "  Class 2 accuracy: 0.6800\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 0.9200\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.3000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 11/75, D Loss: 0.7798, G Loss: 2.3926, Class Loss: 2.0084\n",
      "Epoch 11 - Generated Image Class Accuracy: 0.9300\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.7000\n",
      "  Class 3 accuracy: 0.7800\n",
      "  Class 4 accuracy: 0.9200\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.9200\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745507297.355237   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/75, D Loss: 0.7935, G Loss: 2.2709, Class Loss: 2.1917\n",
      "Epoch 13 - Generated Image Class Accuracy: 0.8920\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.5400\n",
      "  Class 3 accuracy: 0.8200\n",
      "  Class 4 accuracy: 0.9000\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.6800\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 15/75, D Loss: 0.7821, G Loss: 2.3213, Class Loss: 1.9726\n",
      "Epoch 15 - Generated Image Class Accuracy: 0.8340\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 0.9800\n",
      "  Class 2 accuracy: 0.7200\n",
      "  Class 3 accuracy: 0.8800\n",
      "  Class 4 accuracy: 0.8400\n",
      "  Class 5 accuracy: 0.9600\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 17:09:15.574751: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "E0000 00:00:1745507357.945486   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/75, D Loss: 0.7726, G Loss: 2.3440, Class Loss: 1.9812\n",
      "Epoch 17 - Generated Image Class Accuracy: 0.8600\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.8000\n",
      "  Class 3 accuracy: 0.8600\n",
      "  Class 4 accuracy: 0.9600\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n",
      "Epoch 19/75, D Loss: 0.7732, G Loss: 2.3136, Class Loss: 1.6871\n",
      "Epoch 19 - Generated Image Class Accuracy: 0.8520\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.7200\n",
      "  Class 3 accuracy: 0.7200\n",
      "  Class 4 accuracy: 0.9400\n",
      "  Class 5 accuracy: 0.9400\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.2000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745507427.094445   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/75, D Loss: 0.7698, G Loss: 2.3280, Class Loss: 1.7282\n",
      "Epoch 21 - Generated Image Class Accuracy: 0.8420\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.8200\n",
      "  Class 3 accuracy: 0.8000\n",
      "  Class 4 accuracy: 0.9600\n",
      "  Class 5 accuracy: 0.9000\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9600\n",
      "Epoch 23/75, D Loss: 0.7655, G Loss: 2.3500, Class Loss: 1.6862\n",
      "Epoch 23 - Generated Image Class Accuracy: 0.8980\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.7800\n",
      "  Class 3 accuracy: 0.7800\n",
      "  Class 4 accuracy: 0.8600\n",
      "  Class 5 accuracy: 0.9400\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.6200\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 25/75, D Loss: 0.7674, G Loss: 2.3405, Class Loss: 1.8655\n",
      "Epoch 25 - Generated Image Class Accuracy: 0.8660\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.8200\n",
      "  Class 3 accuracy: 0.8600\n",
      "  Class 4 accuracy: 0.9600\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0400\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745507489.016798   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/75, D Loss: 0.7580, G Loss: 2.4106, Class Loss: 1.6595\n",
      "Epoch 27 - Generated Image Class Accuracy: 0.9360\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9000\n",
      "  Class 3 accuracy: 0.6200\n",
      "  Class 4 accuracy: 0.9600\n",
      "  Class 5 accuracy: 0.9600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.9400\n",
      "  Class 9 accuracy: 0.9800\n",
      "Epoch 29/75, D Loss: 0.7515, G Loss: 2.4056, Class Loss: 1.4360\n",
      "Epoch 29 - Generated Image Class Accuracy: 0.8840\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.8600\n",
      "  Class 3 accuracy: 0.8400\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.9600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.2000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745507557.480781   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/75, D Loss: 0.7564, G Loss: 2.4103, Class Loss: 1.2943\n",
      "Epoch 31 - Generated Image Class Accuracy: 0.8360\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.7600\n",
      "  Class 3 accuracy: 0.7400\n",
      "  Class 4 accuracy: 0.8800\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 17:13:07.645034: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/75, D Loss: 0.7506, G Loss: 2.4484, Class Loss: 1.3264\n",
      "Epoch 33 - Generated Image Class Accuracy: 0.8540\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.7600\n",
      "  Class 3 accuracy: 0.9200\n",
      "  Class 4 accuracy: 0.9000\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745507619.270648   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/75, D Loss: 0.7522, G Loss: 2.4428, Class Loss: 1.3222\n",
      "Epoch 35 - Generated Image Class Accuracy: 0.8540\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9000\n",
      "  Class 3 accuracy: 0.8000\n",
      "  Class 4 accuracy: 0.8000\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0600\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 37/75, D Loss: 0.7259, G Loss: 2.5266, Class Loss: 1.2081\n",
      "Epoch 37 - Generated Image Class Accuracy: 0.8620\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 0.9800\n",
      "  Class 2 accuracy: 0.8400\n",
      "  Class 3 accuracy: 0.9000\n",
      "  Class 4 accuracy: 0.9000\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745507688.124658   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/75, D Loss: 0.7433, G Loss: 2.4998, Class Loss: 1.1077\n",
      "Epoch 39 - Generated Image Class Accuracy: 0.8340\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.7400\n",
      "  Class 3 accuracy: 0.8000\n",
      "  Class 4 accuracy: 0.8200\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 41/75, D Loss: 0.7365, G Loss: 2.4701, Class Loss: 1.1878\n",
      "Epoch 41 - Generated Image Class Accuracy: 0.8660\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9000\n",
      "  Class 3 accuracy: 0.7600\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0200\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 43/75, D Loss: 0.7337, G Loss: 2.4881, Class Loss: 1.0768\n",
      "Epoch 43 - Generated Image Class Accuracy: 0.8500\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.8200\n",
      "  Class 3 accuracy: 0.8000\n",
      "  Class 4 accuracy: 0.9400\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745507751.006082   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/75, D Loss: 0.7416, G Loss: 2.4920, Class Loss: 1.1044\n",
      "Epoch 45 - Generated Image Class Accuracy: 0.8580\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 0.9600\n",
      "  Class 2 accuracy: 0.6800\n",
      "  Class 3 accuracy: 0.8200\n",
      "  Class 4 accuracy: 0.9000\n",
      "  Class 5 accuracy: 0.9400\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.2800\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 47/75, D Loss: 0.7321, G Loss: 2.4777, Class Loss: 1.0755\n",
      "Epoch 47 - Generated Image Class Accuracy: 0.9440\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.7800\n",
      "  Class 3 accuracy: 0.7800\n",
      "  Class 4 accuracy: 0.9200\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.9800\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745507820.408349   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/75, D Loss: 0.7189, G Loss: 2.5522, Class Loss: 0.9435\n",
      "Epoch 49 - Generated Image Class Accuracy: 0.9340\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.8200\n",
      "  Class 3 accuracy: 0.7200\n",
      "  Class 4 accuracy: 0.9200\n",
      "  Class 5 accuracy: 0.9400\n",
      "  Class 6 accuracy: 0.9800\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.9600\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 51/75, D Loss: 0.7251, G Loss: 2.5475, Class Loss: 0.9979\n",
      "Epoch 51 - Generated Image Class Accuracy: 0.8480\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 0.9800\n",
      "  Class 2 accuracy: 0.8400\n",
      "  Class 3 accuracy: 0.7800\n",
      "  Class 4 accuracy: 0.8800\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745507881.264453   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/75, D Loss: 0.7244, G Loss: 2.5144, Class Loss: 1.0167\n",
      "Epoch 53 - Generated Image Class Accuracy: 0.8440\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 0.9800\n",
      "  Class 2 accuracy: 0.7600\n",
      "  Class 3 accuracy: 0.7400\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 55/75, D Loss: 0.7156, G Loss: 2.5826, Class Loss: 0.9947\n",
      "Epoch 55 - Generated Image Class Accuracy: 0.8620\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.8800\n",
      "  Class 3 accuracy: 0.8600\n",
      "  Class 4 accuracy: 0.8800\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0200\n",
      "  Class 9 accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745507944.536947   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/75, D Loss: 0.7180, G Loss: 2.5427, Class Loss: 0.9756\n",
      "Epoch 57 - Generated Image Class Accuracy: 0.9520\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.8400\n",
      "  Class 3 accuracy: 0.7800\n",
      "  Class 4 accuracy: 0.9200\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 1.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 59/75, D Loss: 0.7193, G Loss: 2.5912, Class Loss: 1.0284\n",
      "Epoch 59 - Generated Image Class Accuracy: 0.8460\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.7800\n",
      "  Class 3 accuracy: 0.8600\n",
      "  Class 4 accuracy: 0.8200\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745508008.636273   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/75, D Loss: 0.7215, G Loss: 2.5456, Class Loss: 0.9512\n",
      "Epoch 61 - Generated Image Class Accuracy: 0.8180\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.7800\n",
      "  Class 3 accuracy: 0.5000\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.9400\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 0.9800\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 63/75, D Loss: 0.7177, G Loss: 2.5937, Class Loss: 0.8833\n",
      "Epoch 63 - Generated Image Class Accuracy: 0.8460\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.8600\n",
      "  Class 3 accuracy: 0.7400\n",
      "  Class 4 accuracy: 0.9600\n",
      "  Class 5 accuracy: 0.9000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745508072.761062   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-04-24 17:21:13.438723: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/75, D Loss: 0.7147, G Loss: 2.6076, Class Loss: 0.8709\n",
      "Epoch 65 - Generated Image Class Accuracy: 0.8440\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.8200\n",
      "  Class 3 accuracy: 0.6800\n",
      "  Class 4 accuracy: 0.9600\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "Epoch 67/75, D Loss: 0.7120, G Loss: 2.6176, Class Loss: 0.9215\n",
      "Epoch 67 - Generated Image Class Accuracy: 0.9680\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 0.9800\n",
      "  Class 2 accuracy: 0.9200\n",
      "  Class 3 accuracy: 0.8200\n",
      "  Class 4 accuracy: 1.0000\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.9600\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745508139.238518   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/75, D Loss: 0.7145, G Loss: 2.6170, Class Loss: 0.8512\n",
      "Epoch 69 - Generated Image Class Accuracy: 0.8500\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.9200\n",
      "  Class 3 accuracy: 0.7400\n",
      "  Class 4 accuracy: 0.9400\n",
      "  Class 5 accuracy: 0.9200\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0000\n",
      "  Class 9 accuracy: 0.9800\n",
      "Epoch 71/75, D Loss: 0.7137, G Loss: 2.6706, Class Loss: 0.7711\n",
      "Epoch 71 - Generated Image Class Accuracy: 0.8660\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.8800\n",
      "  Class 3 accuracy: 0.8000\n",
      "  Class 4 accuracy: 0.9400\n",
      "  Class 5 accuracy: 0.9600\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.0800\n",
      "  Class 9 accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745508203.619044   59712 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape indiscriminator_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/75, D Loss: 0.6986, G Loss: 2.6859, Class Loss: 0.7153\n",
      "Epoch 73 - Generated Image Class Accuracy: 0.9320\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.8600\n",
      "  Class 3 accuracy: 0.7000\n",
      "  Class 4 accuracy: 0.8600\n",
      "  Class 5 accuracy: 1.0000\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 0.9200\n",
      "  Class 9 accuracy: 0.9800\n",
      "Epoch 75/75, D Loss: 0.6978, G Loss: 2.6692, Class Loss: 0.7586\n",
      "Epoch 75 - Generated Image Class Accuracy: 0.9600\n",
      "  Class 0 accuracy: 1.0000\n",
      "  Class 1 accuracy: 1.0000\n",
      "  Class 2 accuracy: 0.8400\n",
      "  Class 3 accuracy: 0.8000\n",
      "  Class 4 accuracy: 0.9800\n",
      "  Class 5 accuracy: 0.9800\n",
      "  Class 6 accuracy: 1.0000\n",
      "  Class 7 accuracy: 1.0000\n",
      "  Class 8 accuracy: 1.0000\n",
      "  Class 9 accuracy: 1.0000\n",
      "mkdir: cannot create directory ‘my_gan_checkpoint_augmented’: File exists\n",
      "Model saved successfully to my_gan_checkpoint_augmented\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# augmented_GAN = DCGAN()\n",
    "# augmented_GAN.compile()\n",
    "augmented_GAN = DCGAN.load(checkpoint_dir='my_gan_checkpoint_augmented')\n",
    "\n",
    "augmented_GAN.train(augmented_images,augmented_labels, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "!mkdir  my_gan_checkpoint_augmented\n",
    "augmented_GAN.save(checkpoint_dir='my_gan_checkpoint_augmented')\n",
    "\n",
    "!mv generated_images generated_images_augmented\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the proposed pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 19:05:00] Loading pre-trained GAN model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93956/512743676.py:16: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  hidden = tf.keras.applications.MobileNetV2(\n",
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:407: UserWarning: `build()` was called on layer 'discriminator_10', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer states restored from my_gan_checkpoint_augmented/optimizer_ckpt/ckpt-2\n",
      "Model loaded successfully from my_gan_checkpoint_augmented\n",
      "[2025-04-24 19:05:05] Starting experiment pipeline for Problem 3 (300 Real Samples per Class)\n",
      "[2025-04-24 19:05:05] Loading real training data\n",
      "[2025-04-24 19:05:05] Training data shape: 300: (3000, 28, 28, 1)\n",
      "[2025-04-24 19:05:05] Loading test data\n",
      "[2025-04-24 19:05:05] Test data shape: x_test=(2000, 28, 28, 1), y_test=(2000,)\n",
      "[2025-04-24 19:05:05] Augmenting the dataset to 1000 samples per class\n",
      "Class 0: found 300 images\n",
      "Generated 1000/1000 augmented images for class 0\n",
      "Class 1: found 300 images\n",
      "Generated 1000/1000 augmented images for class 1\n",
      "Class 2: found 300 images\n",
      "Generated 1000/1000 augmented images for class 2\n",
      "Class 3: found 300 images\n",
      "Generated 1000/1000 augmented images for class 3\n",
      "Class 4: found 300 images\n",
      "Generated 1000/1000 augmented images for class 4\n",
      "Class 5: found 300 images\n",
      "Generated 1000/1000 augmented images for class 5\n",
      "Class 6: found 300 images\n",
      "Generated 1000/1000 augmented images for class 6\n",
      "Class 7: found 300 images\n",
      "Generated 1000/1000 augmented images for class 7\n",
      "Class 8: found 300 images\n",
      "Generated 1000/1000 augmented images for class 8\n",
      "Class 9: found 300 images\n",
      "Generated 1000/1000 augmented images for class 9\n",
      "Total synthetic images: 10000\n",
      "Final dataset: 13000 images (3000 real + 10000 synthetic)\n",
      "[2025-04-24 19:05:12] Augmented data shape: (13000, 28, 28, 1)\n",
      "[2025-04-24 19:05:12] Experiment: 300 real + 1000 augmented + 0 generated per class (0 total)\n",
      "[2025-04-24 19:05:12] Using real + augmented data only, no synthetic samples\n",
      "[2025-04-24 19:05:12] Training model on combined data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 19:05:36] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "[2025-04-24 19:05:37] Test Accuracy: 0.9850\n",
      "[2025-04-24 19:05:37] Experiment: 300 real + 1000 augmented + 1000 generated per class (10000 total)\n",
      "[2025-04-24 19:05:38] Combined data shape: (23000, 28, 28, 1)\n",
      "[2025-04-24 19:05:38] Training model on combined data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 19:06:16] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "[2025-04-24 19:06:16] Test Accuracy: 0.9855\n",
      "[2025-04-24 19:06:16] Experiment: 300 real + 1000 augmented + 2000 generated per class (20000 total)\n",
      "[2025-04-24 19:06:18] Combined data shape: (33000, 28, 28, 1)\n",
      "[2025-04-24 19:06:18] Training model on combined data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 19:07:12] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "[2025-04-24 19:07:12] Test Accuracy: 0.9875\n",
      "[2025-04-24 19:07:12] Experiment: 300 real + 1000 augmented + 3000 generated per class (30000 total)\n",
      "[2025-04-24 19:07:16] Combined data shape: (43000, 28, 28, 1)\n",
      "[2025-04-24 19:07:16] Training model on combined data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef-abuzeid/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-24 19:08:24] Evaluating model on test set\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "[2025-04-24 19:08:24] Test Accuracy: 0.9860\n",
      "[2025-04-24 19:08:24] Test Accuracies Table:\n",
      "| Real Samples | Augmented Samples | 0 Generated | 1000 Generated | 2000 Generated | 3000 Generated |\n",
      "|--------------|-------------------|-------------|----------------|----------------|----------------|\n",
      "| 300          | 1000              | 0.9850       | 0.9855         | 0.9875         | 0.9860         |\n",
      "[2025-04-24 19:08:24] Experiment pipeline completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load the GAN model\n",
    "log_message(\"Loading pre-trained GAN model\")\n",
    "dcgan_augmented = DCGAN.load(checkpoint_dir='my_gan_checkpoint_augmented')  # Trained on 300 real + 1000 augmented per class\n",
    "\n",
    "# Step 2: Load real and test data\n",
    "log_message(\"Starting experiment pipeline for Problem 3 (300 Real Samples per Class)\")\n",
    "log_message(\"Loading real training data\")\n",
    "num_classes = 10\n",
    "x_train_300, y_train_300 = load_images_from_directory(train_dir, n_samples_per_class=300)  # 300 per class (3000 total)\n",
    "log_message(f\"Training data shape: 300: {x_train_300.shape}\")\n",
    "\n",
    "log_message(\"Loading test data\")\n",
    "x_test, y_test = load_images_from_directory(test_dir, n_samples_per_class=200)  # 200 per class (2000 total)\n",
    "log_message(f\"Test data shape: x_test={x_test.shape}, y_test={y_test.shape}\")\n",
    "\n",
    "# Step 3: Augment the dataset to 1000 samples per class\n",
    "log_message(\"Augmenting the dataset to 1000 samples per class\")\n",
    "try:\n",
    "    x_train_augmented, y_train_augmented = generate_dataset_with_augmentation(\n",
    "        x_train_300, y_train_300, 300*10,1000*10\n",
    "    )  # Augment to 1000 per class (10,000 total)\n",
    "    log_message(f\"Augmented data shape: {x_train_augmented.shape}\")\n",
    "except Exception as e:\n",
    "    log_message(f\"Error during augmentation: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Step 4: Define the results table\n",
    "# Structure: {generated_samples_per_class: accuracy}\n",
    "results_table = {\n",
    "    0: 0,\n",
    "    1000: 0,\n",
    "    2000: 0,\n",
    "    3000: 0\n",
    "}\n",
    "\n",
    "# Step 5: Run experiments for each combination of synthetic samples\n",
    "for gen_samples_per_class in [0, 1000, 2000, 3000]:\n",
    "    total_gen_samples = gen_samples_per_class * num_classes  # Total synthetic samples\n",
    "    log_message(f\"Experiment: 300 real + 1000 augmented + {gen_samples_per_class} generated per class ({total_gen_samples} total)\")\n",
    "    \n",
    "    # Step 5.1: Combine datasets\n",
    "    if gen_samples_per_class == 0:\n",
    "        x_train_combined = x_train_augmented\n",
    "        y_train_combined = y_train_augmented\n",
    "        log_message(\"Using real + augmented data only, no synthetic samples\")\n",
    "    else:\n",
    "        try:\n",
    "            # Generate synthetic data\n",
    "            synthetic_images, synthetic_labels = dcgan_augmented.generate_synthetic_data(total_gen_samples, num_classes)\n",
    "            # Combine real + augmented + synthetic data\n",
    "            x_train_combined = np.concatenate((x_train_augmented, synthetic_images), axis=0)\n",
    "            y_train_combined = np.concatenate((y_train_augmented, synthetic_labels), axis=0)\n",
    "            log_message(f\"Combined data shape: {x_train_combined.shape}\")\n",
    "        except Exception as e:\n",
    "            log_message(f\"Error during synthetic data generation: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Step 5.2: Train the model\n",
    "    try:\n",
    "        model = create_cnn_model()\n",
    "        log_message(\"Training model on combined data\")\n",
    "        history = model.fit(\n",
    "            x_train_combined, y_train_combined,\n",
    "            epochs=20, batch_size=32, verbose=0\n",
    "        )\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during training: {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    # Step 5.3: Evaluate on the test set\n",
    "    log_message(\"Evaluating model on test set\")\n",
    "    try:\n",
    "        pred = model.predict(x_test)\n",
    "        y_pred = np.argmax(pred, axis=1)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        results_table[gen_samples_per_class] = test_accuracy\n",
    "        log_message(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during evaluation: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Step 6: Display the results table\n",
    "log_message(\"Test Accuracies Table:\")\n",
    "print(\"| Real Samples | Augmented Samples | 0 Generated | 1000 Generated | 2000 Generated | 3000 Generated |\")\n",
    "print(\"|--------------|-------------------|-------------|----------------|----------------|----------------|\")\n",
    "row = f\"| {300:<12} | {1000:<17} | {results_table[0]:.4f}       | {results_table[1000]:.4f}         | {results_table[2000]:.4f}         | {results_table[3000]:.4f}         |\"\n",
    "print(row)\n",
    "\n",
    "log_message(\"Experiment pipeline completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
