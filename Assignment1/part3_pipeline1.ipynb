{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rsz0RVJDsPCE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from scipy.ndimage import rotate, shift, zoom\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.base import clone\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEh-JeqasPCK",
        "outputId": "9f109078-5aa9-4e0e-b2e8-24e236a88ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/mohamedgamal07/reduced-mnist/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mohamedgamal07/reduced-mnist\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YfyU2FoRsPCL"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# Data Loading Functions\n",
        "# --------------------------\n",
        "def load_data(train_dir, test_dir):\n",
        "    \"\"\"Load MNIST data from directories\"\"\"\n",
        "    # Load training data\n",
        "    images, labels = [], []\n",
        "    for label in sorted(os.listdir(train_dir)):\n",
        "        label_dir = os.path.join(train_dir, label)\n",
        "        if os.path.isdir(label_dir):\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                img_path = os.path.join(label_dir, img_name)\n",
        "                with Image.open(img_path) as img:\n",
        "                    img_array = np.array(img.convert('L'), dtype=np.float32) / 255.0\n",
        "                    images.append(img_array)\n",
        "                    labels.append(int(label))\n",
        "\n",
        "    # Load test data\n",
        "    test_images, test_labels = [], []\n",
        "    for label in sorted(os.listdir(test_dir)):\n",
        "        label_dir = os.path.join(test_dir, label)\n",
        "        if os.path.isdir(label_dir):\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                img_path = os.path.join(label_dir, img_name)\n",
        "                with Image.open(img_path) as img:\n",
        "                    img_array = np.array(img.convert('L'), dtype=np.float32) / 255.0\n",
        "                    test_images.append(img_array)\n",
        "                    test_labels.append(int(label))\n",
        "\n",
        "    return (\n",
        "        np.array(images), np.array(labels),\n",
        "        np.array(test_images), np.array(test_labels)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bLtztNdtsPCO"
      },
      "outputs": [],
      "source": [
        "train_dir = \"/root/.cache/kagglehub/datasets/mohamedgamal07/reduced-mnist/versions/1/Reduced MNIST Data/Reduced Trainging data\"\n",
        "test_dir= \"/root/.cache/kagglehub/datasets/mohamedgamal07/reduced-mnist/versions/1/Reduced MNIST Data/Reduced Testing data\"\n",
        "\n",
        "# Load data\n",
        "X_train, y_train, X_test, y_test = load_data(train_dir, test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2HGt2AgsPCP",
        "outputId": "aebe5c66-372f-4685-fcf3-78f17d65195b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (10000, 784)\n",
            "Test data shape: (2000, 784)\n"
          ]
        }
      ],
      "source": [
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "print(\"Training data shape:\", X_train_flat.shape)\n",
        "print(\"Test data shape:\", X_test_flat.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XnLvjmaUUYlD"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters=100, random_state=42)\n",
        "cluster_labels = kmeans.fit_predict(X_train_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4FPW_XcUeNb",
        "outputId": "b8e07f92-38e2-4e9f-91c5-fe542ced7490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "initial_labels = np.zeros(10000)\n",
        "majority_labels = np.zeros(100)\n",
        "for i in range(100):\n",
        "    idx = np.where(cluster_labels == i)[0]\n",
        "    sample_idx = np.random.choice(idx, 5, replace=False)\n",
        "    sample_labels = y_train[sample_idx]  # Simulate manual labeling\n",
        "    majority_label = Counter(sample_labels).most_common(1)[0][0]\n",
        "    initial_labels[idx] = majority_label\n",
        "    majority_labels[i] = majority_label\n",
        "\n",
        "print(len(majority_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0pbQANtZUnr_"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "svm = SVC(kernel='rbf', probability=True, random_state=42)  # Add probability=True\n",
        "svm.fit(X_train_flat, initial_labels)\n",
        "test_pred = svm.predict(X_test_flat)\n",
        "accuracy_iter1 = accuracy_score(y_test, test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myyY9fTDUv0h",
        "outputId": "b8e5939e-d972-4af9-c7ed-873e448edb0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.936\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_iter1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXayZ-JgVZhk",
        "outputId": "a9d06af5-e2e0-412b-9064-bf09fe46c57f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8967\n"
          ]
        }
      ],
      "source": [
        "pred_labels = svm.predict(X_train_flat)\n",
        "accuracy_training1 = accuracy_score(y_train,pred_labels)\n",
        "print(accuracy_training1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZQV--FU1TUQ",
        "outputId": "0e9f41ce-c5aa-4dfc-8720-8719fa86917e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No significant improvement (0.0000), patience counter: 1/2\n",
            "Iteration 1:\n",
            " - Training Accuracy: 0.9005\n",
            " - Test Accuracy: 0.9360\n",
            "Iteration 2:\n",
            " - Training Accuracy: 0.9028\n",
            " - Test Accuracy: 0.9390\n",
            "Iteration 3:\n",
            " - Training Accuracy: 0.9036\n",
            " - Test Accuracy: 0.9425\n",
            "Iteration 4:\n",
            " - Training Accuracy: 0.9043\n",
            " - Test Accuracy: 0.9415\n",
            "Iteration 5:\n",
            " - Training Accuracy: 0.9047\n",
            " - Test Accuracy: 0.9410\n",
            "Iteration 6:\n",
            " - Training Accuracy: 0.9048\n",
            " - Test Accuracy: 0.9405\n",
            "No significant improvement (0.0000), patience counter: 1/2\n",
            "Iteration 7:\n",
            " - Training Accuracy: 0.9049\n",
            " - Test Accuracy: 0.9405\n",
            "Iteration 8:\n",
            " - Training Accuracy: 0.9050\n",
            " - Test Accuracy: 0.9400\n",
            "No significant improvement (0.0000), patience counter: 1/2\n",
            "Iteration 9:\n",
            " - Training Accuracy: 0.9051\n",
            " - Test Accuracy: 0.9400\n",
            "No significant improvement (0.0000), patience counter: 2/2\n",
            "Iteration 10:\n",
            " - Training Accuracy: 0.9051\n",
            " - Test Accuracy: 0.9400\n",
            "Early stopping triggered after 2 iterations without improvement\n",
            "\n",
            "Final Results:\n",
            "Iter 0: Train=0.8967, Test=0.9360\n",
            "Iter 1: Train=0.9005, Test=0.9360\n",
            "Iter 2: Train=0.9028, Test=0.9390\n",
            "Iter 3: Train=0.9036, Test=0.9425\n",
            "Iter 4: Train=0.9043, Test=0.9415\n",
            "Iter 5: Train=0.9047, Test=0.9410\n",
            "Iter 6: Train=0.9048, Test=0.9405\n",
            "Iter 7: Train=0.9049, Test=0.9405\n",
            "Iter 8: Train=0.9050, Test=0.9400\n",
            "Iter 9: Train=0.9051, Test=0.9400\n",
            "Iter 10: Train=0.9051, Test=0.9400\n"
          ]
        }
      ],
      "source": [
        "# --------------------------\n",
        "# Automated Iteration Loop with Patience\n",
        "# --------------------------\n",
        "max_iterations = 10\n",
        "patience = 2  # Number of iterations to wait without improvement\n",
        "accuracy_history = []\n",
        "training_accuracy_history = []\n",
        "patience_counter = 0\n",
        "\n",
        "# Initialize with first iteration results\n",
        "current_svm = svm\n",
        "current_labels = pred_labels\n",
        "accuracy_history.append(accuracy_iter1)\n",
        "training_accuracy_history.append(accuracy_training1)\n",
        "\n",
        "for iteration in range(1, max_iterations+1):\n",
        "    # Train new SVM with current pseudo-labels\n",
        "    new_svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "    new_svm.fit(X_train_flat, current_labels)\n",
        "\n",
        "    # Predict and calculate accuracies\n",
        "    test_pred = new_svm.predict(X_test_flat)\n",
        "    train_pred = new_svm.predict(X_train_flat)\n",
        "\n",
        "    # Store metrics\n",
        "    iter_test_acc = accuracy_score(y_test, test_pred)\n",
        "    iter_train_acc = accuracy_score(y_train, train_pred)\n",
        "\n",
        "    # Update tracking\n",
        "    accuracy_history.append(iter_test_acc)\n",
        "    training_accuracy_history.append(iter_train_acc)\n",
        "\n",
        "    # Check for improvement\n",
        "    improvement = iter_test_acc - accuracy_history[-2]\n",
        "    if abs(improvement) < 0.0001:\n",
        "        patience_counter += 1\n",
        "        print(f\"No significant improvement ({improvement:.4f}), patience counter: {patience_counter}/{patience}\")\n",
        "    else:\n",
        "        patience_counter = 0  # Reset counter if improvement occurs\n",
        "\n",
        "    # Update for next iteration\n",
        "    current_labels = train_pred\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"Iteration {iteration}:\")\n",
        "    print(f\" - Training Accuracy: {iter_train_acc:.4f}\")\n",
        "    print(f\" - Test Accuracy: {iter_test_acc:.4f}\")\n",
        "\n",
        "    # Early stopping check\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"Early stopping triggered after {patience} iterations without improvement\")\n",
        "        break\n",
        "\n",
        "# --------------------------\n",
        "# Final Results\n",
        "# --------------------------\n",
        "print(\"\\nFinal Results:\")\n",
        "for i, (train_acc, test_acc) in enumerate(zip(training_accuracy_history, accuracy_history)):\n",
        "    print(f\"Iter {i}: Train={train_acc:.4f}, Test={test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WgUUPs0q3fvg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline 1 Manual Pipeline Time:\n",
            "5000 seconds (1.39 hours)\n",
            "\n",
            "Full Manual Labeling Time:\n",
            "100000 seconds (27.78 hours)\n"
          ]
        }
      ],
      "source": [
        "# Define the constants for the calculations\n",
        "samples_per_cluster = 5      # Number of samples manually checked per cluster\n",
        "num_clusters = 100           # Total number of clusters\n",
        "seconds_per_sample = 10      # Time taken to check one sample in seconds\n",
        "\n",
        "# Calculate the manual time for Pipeline 1\n",
        "time_pipeline1_seconds = samples_per_cluster * num_clusters * seconds_per_sample\n",
        "time_pipeline1_hours = time_pipeline1_seconds / 3600\n",
        "\n",
        "# Calculate the manual time for full manual labeling\n",
        "total_images = 10000         # Total number of images\n",
        "time_full_seconds = total_images * seconds_per_sample\n",
        "time_full_hours = time_full_seconds / 3600\n",
        "\n",
        "# Print the results\n",
        "print(\"Pipeline 1 Manual Pipeline Time:\")\n",
        "print(f\"{time_pipeline1_seconds} seconds ({time_pipeline1_hours:.2f} hours)\")\n",
        "print(\"\\nFull Manual Labeling Time:\")\n",
        "print(f\"{time_full_seconds} seconds ({time_full_hours:.2f} hours)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
