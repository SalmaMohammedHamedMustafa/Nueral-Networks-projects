{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification with Feature Extraction and MLP Models\n",
    "\n",
    "This notebook implements a digit classification task using the Reduced MNIST dataset. We explore three feature extraction techniques—Principal Component Analysis (PCA), Discrete Cosine Transform (DCT), and Autoencoders (AE)—and evaluate their performance with Multi-Layer Perceptron (MLP) models of varying architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 20:02:23.791981: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-26 20:02:23.885786: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-26 20:02:23.958267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743012144.034971    5392 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743012144.057239    5392 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743012144.210454    5392 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743012144.210482    5392 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743012144.210484    5392 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743012144.210486    5392 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-26 20:02:24.227000: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.fft import dct\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "In this section, we load the Reduced MNIST dataset from the specified training and testing directories. The images are grayscale (28x28 pixels), and the folder names (0-9) serve as labels. We shuffle the data to ensure randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class directories: ['0', '7', '5', '2', '6', '8', '4', '9', '3', '1']\n",
      "Testing class directories: ['0', '7', '5', '2', '6', '8', '4', '9', '3', '1']\n",
      "Training images shape: (10000, 28, 28)\n",
      "Training labels shape: (10000,)\n",
      "Testing images shape: (2000, 28, 28)\n",
      "Testing labels shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "# Define paths to training and testing data directories\n",
    "train_data_dir = './Reduced MNIST Data/Reduced Training data'\n",
    "test_data_dir = './Reduced MNIST Data/Reduced Testing data'\n",
    "\n",
    "# Get list of subdirectories (each representing a digit class)\n",
    "train_class_dirs = os.listdir(train_data_dir)\n",
    "test_class_dirs = os.listdir(test_data_dir)\n",
    "\n",
    "print(\"Training class directories:\", train_class_dirs)\n",
    "print(\"Testing class directories:\", test_class_dirs)\n",
    "\n",
    "# Initialize lists to store images and labels\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "# Load training data\n",
    "for digit_class in train_class_dirs:\n",
    "    class_path = os.path.join(train_data_dir, digit_class)\n",
    "    for image_file in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "        # Read image in grayscale (0-255 pixel values)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        train_images.append(image)\n",
    "        train_labels.append(digit_class)  # Folder name is the label\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "print(\"Training images shape:\", train_images.shape)\n",
    "print(\"Training labels shape:\", train_labels.shape)\n",
    "\n",
    "# Load testing data\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for digit_class in test_class_dirs:\n",
    "    class_path = os.path.join(test_data_dir, digit_class)\n",
    "    for image_file in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        test_images.append(image)\n",
    "        test_labels.append(digit_class)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(\"Testing images shape:\", test_images.shape)\n",
    "print(\"Testing labels shape:\", test_labels.shape)\n",
    "\n",
    "# Shuffle training and testing data for randomness\n",
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=4)\n",
    "test_images, test_labels = shuffle(test_images, test_labels, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction Techniques\n",
    "\n",
    "We apply three feature extraction methods to reduce dimensionality and extract meaningful features from the 28x28 images (784 dimensions):\n",
    "- **PCA**: Reduces dimensions while retaining 95% variance.\n",
    "- **DCT**: Extracts frequency-based features using a 15x15 coefficient grid (225 components).\n",
    "- **Autoencoder**: Learns a compressed representation (225 components) through an encoder-decoder network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dimensions: 784, PCA dimensions: 262\n",
      "DCT training features shape: (10000, 225)\n",
      "DCT testing features shape: (2000, 225)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1743012151.149292    5392 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1743012151.150237    5392 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 0.1095 - val_loss: 0.0508\n",
      "Epoch 2/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0465 - val_loss: 0.0397\n",
      "Epoch 3/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0375 - val_loss: 0.0332\n",
      "Epoch 4/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0319 - val_loss: 0.0302\n",
      "Epoch 5/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0290 - val_loss: 0.0285\n",
      "Epoch 6/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0271 - val_loss: 0.0272\n",
      "Epoch 7/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0251 - val_loss: 0.0260\n",
      "Epoch 8/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0235 - val_loss: 0.0249\n",
      "Epoch 9/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0221 - val_loss: 0.0240\n",
      "Epoch 10/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0212 - val_loss: 0.0232\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# --- PCA Feature Extraction ---\n",
    "desired_variance = 0.95\n",
    "pca_model = PCA(n_components=desired_variance)\n",
    "\n",
    "# Flatten images to 784-dimensional vectors for PCA\n",
    "train_images_flat = train_images.reshape(train_images.shape[0], 28 * 28)\n",
    "test_images_flat = test_images.reshape(test_images.shape[0], 28 * 28)\n",
    "\n",
    "# Fit PCA on training data and transform both sets\n",
    "train_pca_features = pca_model.fit_transform(train_images_flat)\n",
    "test_pca_features = pca_model.transform(test_images_flat)\n",
    "\n",
    "print(f\"Original dimensions: {28*28}, PCA dimensions: {train_pca_features.shape[1]}\")\n",
    "\n",
    "# --- DCT Feature Extraction ---\n",
    "def extract_dct_features(images, num_components=225):\n",
    "    \"\"\"Extract DCT features from flattened images.\"\"\"\n",
    "    sqrt_img_size = int(np.sqrt(images.shape[1]))  # 28\n",
    "    sqrt_components = int(np.sqrt(num_components))  # 15\n",
    "    dct_features = []\n",
    "    \n",
    "    for img in images:\n",
    "        # Reshape to 28x28 for 2D DCT\n",
    "        img_2d = img.reshape(sqrt_img_size, sqrt_img_size)\n",
    "        # Apply 2D DCT with orthogonal normalization\n",
    "        dct_img = dct(dct(img_2d, axis=0, norm='ortho'), axis=1, norm='ortho')\n",
    "        # Take top-left 15x15 coefficients and flatten\n",
    "        dct_features.append(dct_img[:sqrt_components, :sqrt_components].flatten())\n",
    "    \n",
    "    return np.array(dct_features)\n",
    "\n",
    "# Normalize images to [0, 1] range\n",
    "train_images_normalized = train_images_flat / 255.0\n",
    "test_images_normalized = test_images_flat / 255.0\n",
    "\n",
    "# Extract DCT features\n",
    "train_dct_features = extract_dct_features(train_images_normalized)\n",
    "test_dct_features = extract_dct_features(test_images_normalized)\n",
    "\n",
    "print(\"DCT training features shape:\", train_dct_features.shape)\n",
    "print(\"DCT testing features shape:\", test_dct_features.shape)\n",
    "\n",
    "# --- Autoencoder Feature Extraction ---\n",
    "def extract_autoencoder_features(train_data, test_data, num_components=64, epochs=10, batch_size=64):\n",
    "    \"\"\"Train an autoencoder and extract features from the bottleneck layer.\"\"\"\n",
    "    input_dim = train_data.shape[1]  # 784, assuming MNIST-like data\n",
    "    \n",
    "    # Define encoder architecture\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded1 = Dense(512, activation='relu')(input_layer)  # 784 -> 512\n",
    "    encoded2 = Dense(256, activation='relu')(encoded1)     # 512 -> 256\n",
    "    encoded3 = Dense(128, activation='relu')(encoded2)     # 256 -> 128\n",
    "    bottleneck = Dense(num_components, activation='relu')(encoded3)  # 128 -> num_components (default 64)\n",
    "    \n",
    "    # Define decoder architecture\n",
    "    decoded1 = Dense(128, activation='relu')(bottleneck)   # num_components -> 128\n",
    "    decoded2 = Dense(256, activation='relu')(decoded1)     # 128 -> 256\n",
    "    decoded3 = Dense(512, activation='relu')(decoded2)     # 256 -> 512\n",
    "    output_layer = Dense(input_dim, activation='sigmoid')(decoded3)  # 512 -> 784\n",
    "    \n",
    "    # Build and compile autoencoder\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Build encoder for feature extraction\n",
    "    encoder = Model(inputs=input_layer, outputs=bottleneck)\n",
    "    \n",
    "    # Train the autoencoder\n",
    "    autoencoder.fit(train_data, train_data,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_data, test_data),\n",
    "                    verbose=1)\n",
    "    \n",
    "    # Extract features\n",
    "    train_ae_features = encoder.predict(train_data)\n",
    "    test_ae_features = encoder.predict(test_data)\n",
    "    \n",
    "    return train_ae_features, test_ae_features, encoder, autoencoder\n",
    "\n",
    "# Extract autoencoder features\n",
    "train_ae_features, test_ae_features, ae_encoder, ae_model = extract_autoencoder_features(\n",
    "    train_images_normalized, test_images_normalized, epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MLP Model Training and Evaluation\n",
    "\n",
    "We train MLP models with 1, 2, and 3 hidden layers on each feature set (PCA, DCT, Autoencoder) and evaluate their performance based on accuracy, training time, evaluation time, and inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "----- MLP With 1 Hidden Layer (PCA) -----\n",
      "Training Time: 20240.2 s\n",
      "Evaluation Time: 209.6 s\n",
      "Inference Time (single sample): 65.9 ms\n",
      "Total Time: 20449.8 s\n",
      "Test Accuracy: 96.2 %\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "----- MLP With 3 Hidden Layers (PCA) -----\n",
      "Training Time: 30213.7 s\n",
      "Evaluation Time: 286.3 s\n",
      "Inference Time (single sample): 77.3 ms\n",
      "Total Time: 30499.9 s\n",
      "Test Accuracy: 95.5 %\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "----- MLP With 5 Hidden Layers (PCA) -----\n",
      "Training Time: 33127.4 s\n",
      "Evaluation Time: 353.5 s\n",
      "Inference Time (single sample): 98.4 ms\n",
      "Total Time: 33480.9 s\n",
      "Test Accuracy: 95.95 %\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 68 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ccbcbf1c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "----- MLP With 1 Hidden Layer (DCT) -----\n",
      "Training Time: 18224.4 s\n",
      "Evaluation Time: 212.4 s\n",
      "Inference Time (single sample): 72.7 ms\n",
      "Total Time: 18436.8 s\n",
      "Test Accuracy: 97.3 %\n",
      "\n",
      "WARNING:tensorflow:6 out of the last 69 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ccbcab1a560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "----- MLP With 3 Hidden Layers (DCT) -----\n",
      "Training Time: 30026.0 s\n",
      "Evaluation Time: 322.3 s\n",
      "Inference Time (single sample): 97.8 ms\n",
      "Total Time: 30348.3 s\n",
      "Test Accuracy: 97.55 %\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "----- MLP With 5 Hidden Layers (DCT) -----\n",
      "Training Time: 31431.5 s\n",
      "Evaluation Time: 319.1 s\n",
      "Inference Time (single sample): 93.1 ms\n",
      "Total Time: 31750.6 s\n",
      "Test Accuracy: 97.2 %\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "----- MLP With 1 Hidden Layer (Autoencoder) -----\n",
      "Training Time: 12710.5 s\n",
      "Evaluation Time: 234.1 s\n",
      "Inference Time (single sample): 85.3 ms\n",
      "Total Time: 12944.7 s\n",
      "Test Accuracy: 96.1 %\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "----- MLP With 3 Hidden Layers (Autoencoder) -----\n",
      "Training Time: 24727.7 s\n",
      "Evaluation Time: 611.9 s\n",
      "Inference Time (single sample): 76.9 ms\n",
      "Total Time: 25339.7 s\n",
      "Test Accuracy: 95.15 %\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "----- MLP With 5 Hidden Layers (Autoencoder) -----\n",
      "Training Time: 28342.9 s\n",
      "Evaluation Time: 267.0 s\n",
      "Inference Time (single sample): 94.4 ms\n",
      "Total Time: 28609.9 s\n",
      "Test Accuracy: 95.65 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_mlp(features_train, labels_train, features_test, labels_test, \n",
    "                          hidden_layer_configs, input_dim, epochs, batch_size, method_name):\n",
    "    \"\"\"Train and evaluate MLP models with varying hidden layers.\"\"\"\n",
    "    results = {}\n",
    "    # Convert labels to one-hot encoding\n",
    "    labels_train_encoded = to_categorical(labels_train)\n",
    "    labels_test_encoded = to_categorical(labels_test)\n",
    "    \n",
    "    for layer_sizes in hidden_layer_configs:\n",
    "        # Define model using Functional API\n",
    "        inputs = keras.Input(shape=(input_dim,))\n",
    "        x = inputs\n",
    "        for size in layer_sizes:\n",
    "            x = Dense(size, activation='relu')(x)\n",
    "        outputs = Dense(10, activation='softmax')(x)\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Train model and measure time\n",
    "        start_time = time.time()\n",
    "        model.fit(features_train, labels_train_encoded, epochs=epochs, \n",
    "                  batch_size=batch_size, shuffle=True, verbose=0)\n",
    "        training_time = (time.time() - start_time)* 1000  # Convert to ms\n",
    "        \n",
    "        # Evaluate model\n",
    "        eval_start = time.time()\n",
    "        loss, accuracy = model.evaluate(features_test, labels_test_encoded, verbose=0)\n",
    "        eval_time = (time.time() - eval_start)* 1000  # Convert to ms\n",
    "        \n",
    "        # Measure inference time for a single sample\n",
    "        pred_start = time.time()\n",
    "        model.predict(features_test[0].reshape(1, input_dim))\n",
    "        inference_time = (time.time() - pred_start) * 1000  # Convert to ms\n",
    "        \n",
    "        # Store results\n",
    "        model_key = f\"MLP With {len(layer_sizes)} Hidden Layer{'s' if len(layer_sizes) > 1 else ''} ({method_name})\"\n",
    "        results[model_key] = {\n",
    "            'training_time': round(training_time, 1),\n",
    "            'evaluation_time': round(eval_time, 1),\n",
    "            'inference_time': round(inference_time, 1),\n",
    "            'total_time': round(training_time + eval_time, 1),\n",
    "            'accuracy': round(accuracy * 100, 2)\n",
    "        }\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"----- {model_key} -----\")\n",
    "        print(f\"Training Time: {results[model_key]['training_time']} s\")\n",
    "        print(f\"Evaluation Time: {results[model_key]['evaluation_time']} s\")\n",
    "        print(f\"Inference Time: {results[model_key]['inference_time']} ms\")\n",
    "        print(f\"Total Time: {results[model_key]['total_time']} s\")\n",
    "        print(f\"Test Accuracy: {results[model_key]['accuracy']} %\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Define MLP architectures\n",
    "hidden_layer_configs = [\n",
    "    [512],          # 1 hidden layer\n",
    "    [512, 256, 128], # 3 hidden layers\n",
    "    [512, 256, 128, 64, 32]  # 5 hidden layers\n",
    "]\n",
    "\n",
    "# Train and evaluate MLPs for each feature set\n",
    "pca_results = train_and_evaluate_mlp(train_pca_features, train_labels, test_pca_features, test_labels,\n",
    "                                    hidden_layer_configs, train_pca_features.shape[1], epochs=40, batch_size=64, method_name=\"PCA\")\n",
    "dct_results = train_and_evaluate_mlp(train_dct_features, train_labels, test_dct_features, test_labels,\n",
    "                                    hidden_layer_configs, train_dct_features.shape[1], epochs=40, batch_size=64, method_name=\"DCT\")\n",
    "ae_results = train_and_evaluate_mlp(train_ae_features, train_labels, test_ae_features, test_labels,\n",
    "                                   hidden_layer_configs, train_ae_features.shape[1], epochs=40, batch_size=64, method_name=\"Autoencoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Comparison\n",
    "\n",
    "Here, we compare the performance of PCA, DCT, and Autoencoder features across the three MLP architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Comparison of Feature Extraction Methods ---\n",
      "\n",
      "MLP With 1 Hidden Layer Comparison:\n",
      "PCA - Accuracy: 96.2%, Training: 20240.2ms, Eval: 209.6ms, Inference: 65.9ms, Total: 20449.8ms\n",
      "DCT - Accuracy: 97.3%, Training: 18224.4ms, Eval: 212.4ms, Inference: 72.7ms, Total: 18436.8ms\n",
      "AE  - Accuracy: 96.1%, Training: 12710.5ms, Eval: 234.1ms, Inference: 85.3ms, Total: 12944.7ms\n",
      "\n",
      "MLP With 3 Hidden Layers Comparison:\n",
      "PCA - Accuracy: 95.5%, Training: 30213.7ms, Eval: 286.3ms, Inference: 77.3ms, Total: 30499.9ms\n",
      "DCT - Accuracy: 97.55%, Training: 30026.0ms, Eval: 322.3ms, Inference: 97.8ms, Total: 30348.3ms\n",
      "AE  - Accuracy: 95.15%, Training: 24727.7ms, Eval: 611.9ms, Inference: 76.9ms, Total: 25339.7ms\n",
      "\n",
      "MLP With 5 Hidden Layers Comparison:\n",
      "PCA - Accuracy: 95.95%, Training: 33127.4ms, Eval: 353.5ms, Inference: 98.4ms, Total: 33480.9ms\n",
      "DCT - Accuracy: 97.2%, Training: 31431.5ms, Eval: 319.1ms, Inference: 93.1ms, Total: 31750.6ms\n",
      "AE  - Accuracy: 95.65%, Training: 28342.9ms, Eval: 267.0ms, Inference: 94.4ms, Total: 28609.9ms\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Comparison of Feature Extraction Methods ---\")\n",
    "for layers in hidden_layer_configs:\n",
    "    layer_name = f\"MLP With {len(layers)} Hidden Layer{'s' if len(layers) > 1 else ''}\"\n",
    "    pca_key = f\"{layer_name} (PCA)\"\n",
    "    dct_key = f\"{layer_name} (DCT)\"\n",
    "    ae_key = f\"{layer_name} (Autoencoder)\"\n",
    "    \n",
    "    print(f\"\\n{layer_name} Comparison:\")\n",
    "    print(f\"PCA - Accuracy: {pca_results[pca_key]['accuracy']}%, \"\n",
    "          f\"Training: {pca_results[pca_key]['training_time']}ms, \"\n",
    "          f\"Eval: {pca_results[pca_key]['evaluation_time']}ms, \"\n",
    "          f\"Inference: {pca_results[pca_key]['inference_time']}ms, \"\n",
    "          f\"Total: {pca_results[pca_key]['total_time']}ms\")\n",
    "    print(f\"DCT - Accuracy: {dct_results[dct_key]['accuracy']}%, \"\n",
    "          f\"Training: {dct_results[dct_key]['training_time']}ms, \"\n",
    "          f\"Eval: {dct_results[dct_key]['evaluation_time']}ms, \"\n",
    "          f\"Inference: {dct_results[dct_key]['inference_time']}ms, \"\n",
    "          f\"Total: {dct_results[dct_key]['total_time']}ms\")\n",
    "    print(f\"AE  - Accuracy: {ae_results[ae_key]['accuracy']}%, \"\n",
    "          f\"Training: {ae_results[ae_key]['training_time']}ms, \"\n",
    "          f\"Eval: {ae_results[ae_key]['evaluation_time']}ms, \"\n",
    "          f\"Inference: {ae_results[ae_key]['inference_time']}ms, \"\n",
    "          f\"Total: {ae_results[ae_key]['total_time']}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the application of PCA, DCT, and Autoencoders for feature extraction on the Reduced MNIST dataset, followed by classification using MLPs. The comparison highlights trade-offs between accuracy, training time, and inference speed, allowing us to assess the suitability of each method for digit classification tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
